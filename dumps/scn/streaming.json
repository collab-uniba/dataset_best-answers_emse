[{"date_time": "2015-09-25 18:29:00", "resolve": false, "uid": "1", "title": "Inviting participants to pilot HANA SDS in HCP", "url": "http://scn.sap.com/thread/3804322", "text": "We plan to soon begin pilots of HANA smart data streaming in HCP (HANA Cloud Platform). If you are interested in participating in the pilot, please let me know. You can reply here or contact me directly. Thanks. - Jeff", "views": "35", "answers": 0, "author": "Jeff Wootton", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2012-10-09 06:44:00", "resolve": false, "uid": "2", "title": "Generic Database Input Adapter question", "url": "http://scn.sap.com/thread/3248440", "text": "Hi ESP CommunityFirst post. Woo!Down to business  Im new to ESP development and have a question regarding the behaviour of Generic Database Input Adapters.I have observed that, when a polling cycle executes, the adaptor publishes Update OPCODE messages for all records that already exist in an attached input window. This occurs for all records including those that havent been updated in the database since the last polling cycle.My question is, what is the best way to identify records that have actually been updated in the input database table since the last polling cycle? How do I separate the wheat from the chaff, so to speak? Is this something that is configurable using ESP studio or do I need to implement some logic using a flex operator?If my question is unclear in any way please let me know.Furthermore, is there any documentation that describes the lifecycle of an ESP project. That is, what happens and in what order when a project is deployed and when it is stopped?Thanks in advance,Chris Sutter (DHS Australia)", "views": "413", "answers": 2, "author": "Chris Sutter", "upvotes": 0, "type": "question", "tags": "esp_developer.database_input"},
{"date_time": "2012-10-09 18:09:00", "resolve": "", "uid": "2.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3248440", "text": "Hi Chris,There is no adapter in ESP to do this directly. The ESP DB adpater just executes the query and retrieves all the rows in the database table. As you have already guessed you should be able to workaround this using flex.Here is the code sample to only retrieve newly inserted rows based on id field in the table assuming that the id field is a constantly increasing value.  DECLARE long lastid:=0; END; CREATE INPUT stream triggerStream SCHEMA (trigger_val long) ; CREATE Flex poll IN triggerStream OUT OUTPUT STREAM polldata SCHEMA(id long,symbol string,volume long,price float) BEGIN DECLARE // The typedef must be the // same as the database // table schema typedef[long id;|string symbol;long volume; float price;] datarec; // The vector asedata stores // the result of the getData // function and has to be of // type datarec which is the // type definition for the // schema of the database // table vector(datarec) asedata; END; ON triggerStream { }; EVERY 15 seconds { if(isnull(asedata)) asedata :=new vector(datarec); getData(asedata,'ASE_DATA','select id,symbol,volume,price from stock where id > ? order by id asc',lastid); for(rec in asedata) { output setOpcode(rec,insert); lastid:=rec.id; } resize(asedata,0); }; END; Note: here the triggere stream is just a dummy stream. Every 15 seconds the flex stream polls the database and gets only the newly inserted rows. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Generic Database Input Adapter question", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "2.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3248440", "text": "You might also want to consider SAP Sybase Replication Server - which does change capture and can stream DB changes into ESP as real-time events. (a word of caution re the link: this material mostly talks about using Replication Server to synchronize content between databases, but because it monitors the transaction log of a source database to do real-time change capture, it can stream those changes in real-time into ESP via the ESP Replication Server adapter).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Generic Database Input Adapter question", "type": "answer", "tags": "N/A"},
{"date_time": "2012-10-22 03:56:00", "resolve": false, "uid": "3", "title": "Binding & Project availability question", "url": "http://scn.sap.com/thread/3254939", "text": "Hi there,I have a question to do with the idea of Binding in ESP, and how data is managed across different ESP projects (running on the same server cluster) when they bind to the same output stream from another project. Please see the attached image for a better explanation of my question:Thanks very much,Jason Kelly (DHS, Australia).", "views": "328", "answers": 1, "author": "Jason Kelly", "upvotes": 0, "type": "question", "tags": "event.binding.processing.esp.stream.esp_developer.processor"},
{"date_time": "2012-10-23 17:17:00", "resolve": "", "uid": "3.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3254939", "text": "Hi,The answer to your question depends on what you are binding to in your project A. If you are binding to a stream in project A from your porject B and C then the data will be lost. If you are binding to a window in project A then when you start up project B and C then project B and C will be able to resubscribe to the content of project A and get all the data that was sent out as window keeps data in memory.Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Binding & Project availability question", "type": "answer", "tags": "N/A"},
{"date_time": "2012-10-31 02:55:00", "resolve": false, "uid": "4", "title": "Capturing Websphere MQ Input Adapter errors", "url": "http://scn.sap.com/thread/3259422", "text": "Hi everyoneI was hoping someone might have some ideas regarding capturing errors caused by Websphere MQ Input Adapters.I have tested placing a badly formed message on the queue which results in the below error appearing on the testing console:WSMQ In Adapter: Column size in the received message and the schema do not match. Ignoring this message.I would like to know if there is a way to capture and publish the error details when a message on a Websphere MQ queue doesn't match the schema? So far I have been unable to achieve this.Any tips or pointers would be much appreciated.Thanks,Chris Sutter", "views": "355", "answers": 3, "author": "Chris Sutter", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2012-10-31 21:36:00", "resolve": "", "uid": "4.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3259422", "text": "Hi Chris,I'm not very clearn on where you are seeing this error. In the future, if you could provide the error log, it helps us put things into context (understand what version you are running, what platform, if there were any other issues leading up to this error, etc.).Are you running a local cluster which is started automatically by Studio? If so, errors are normally logged to a directory of this format: %USERPROFILE%\\Documents\\SybaseESP\\5.1\\workspace\\<workspace_name>.<project_name>.<instance>Or have you started a cluster manually with the \"esp_server\" command? If so, errors are normally logged into a directory below the \"base-directory\" defined in the cluster configuration file. For example, if you look at %ESP_HOME%\\cluster\\nodes\\node1\\node1.xml this would point to: ${ESP_HOME}/cluster/projects/test-name-1And the log files would be found in this directory: ${ESP_HOME}/cluster/projects/test-name-1/<workspace_name>.<project_name>.<instance>If you are not seeing these errors in the log files, you may consider bumping up the \"debug-level\" of the project to 4 by editing the project's runtime configuration file (.ccr): http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01613.0510/doc/html/eli1307139168745.html( I have seen some issues I would consider an error (level 3) are actually coded as warnings (level 4) ).If you are looking to capture the reason why a message did not flow from one stream to the next, ESP 5.0 introduced a new feature called \"Error Streams\":http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01612.0510/doc/html/lar1320541857195.htmlHowever, in this case, it looks like it is the WSMQ adapter rejecting the message so \"Error Streams\" won't help because the message never makes it into the server.If this is an important feature for you, I would recommend logging a case so that we can log a feature request, tie the business usage case to it and get it prioritized with engineering.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Capturing Websphere MQ Input Adapter errors", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "4.2", "author": "Chris Sutter", "url": "http://scn.sap.com/thread/3259422", "text": "Hi NealThanks for your reply. I was just testing in ESP Studio using the default workspace. I will log a feature request. We're concerned that if a message were to be ignored in production we wouldn't have sufficient information to trace the source of the problem.Thanks,Chris", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Capturing Websphere MQ Input Adapter errors", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "4.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3259422", "text": "Hello,One thought...Could you define a more accomodating schema for the input stream and feed that to a stream with a more restrictive schema? Then you might be able to capture the information you want.ESP 5.1 has a new \"SPLITTER\" syntax for CCL. You might be able to split the good rows into one stream and the bad rows into another. Or make use of the \"error streams\"?But I do think a feature request is in order.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Capturing Websphere MQ Input Adapter errors", "type": "answer", "tags": "N/A"},
{"date_time": "2012-11-22 17:50:00", "resolve": true, "uid": "5", "title": "Publish Objects via API in C or JAVA", "url": "http://scn.sap.com/thread/3270425", "text": "Hi guys,I have yet another interesting issue I would like to get your knowledge and opinions on. We are using the PubSub Api to publish our data into our ESP server. Currently we are using the C-API for this, and since this is not fast enough, I was wondering if anybody can provide some examples of usage for the envelop and transaction functions. In the example C publisher there is a line saying\" // Publish data - one row at a time // Use esp_message_writer_start_envelope()  // or esp_message_writer_start_transaction() for high throughput\"However, I cannot find an example of envelope or transaction usage, nor get it to work without this. Also I was wondering about the sentence in the api documentation: EspRawMessageWriter EspRawMessageWriter provides a mechanism to publish data buffers formatted with data in ESP binary format. Can anybody explain this message writer and espacially the \"ESP binary format\" to me? Best regards,Dave", "views": "307", "answers": 2, "author": "Dave Schikora", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2012-11-26 23:04:00", "resolve": "solution", "uid": "5.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3270425", "text": "Hi Dave,Here is a simple/rough example I cooked up. The logic for the publisher is very much the same whether it chooses to publish via envelopes or transactions. The main difference between evelopes and transactions is how the server processes the batch once it has arrived. A good desciption of the difference can be found here: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01612.0510/doc/html/tbi1343349013183.htmlI could not find any additional information about the \"raw\" messages. It looks like the documentation totally missed the boat on this one. If you search the \"esp_publisher.h\" header file, you will see a bunch of \"raw\" related APIs such as esp_rawwriter_add_buffer(). None of them are documented, so I can't really provide guidance on them.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Publish Objects via API in C or JAVA", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "5.2", "author": "Dave Schikora", "url": "http://scn.sap.com/thread/3270425", "text": "Hey Neal!Thanks for the example and the fast response. We have been playing around with the Java API and there we have seen pretty decent results with the blocked sending (I think its called block in java api). speeds up the sending by an enourmus factor. Best regards,Dave", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Publish Objects via API in C or JAVA", "type": "answer", "tags": "N/A"},
{"date_time": "2012-10-25 18:41:00", "resolve": false, "uid": "6", "title": "How to sync DB table with ESP stream", "url": "http://scn.sap.com/thread/3257209", "text": "Hi fellow event processors! I have a question regarding ODBC input and output adapters and a DB.I have the following setup:Theoretically I want to replicate the behaviour that a local memory store for a flex stream would create. But the storage should not be in a file, but instead on a database table. So i have the table with the persistent data. Then I have an input stream reading from this table and being insert stream for the flex. On the event of this stream i simply output the entry, so that i have them in my stream. Then there comes the \"normal\" data in the flex stream, changing data and inserting new rows. The flex stream then has an output adapter to the same database table so that both stay in sync. The setup runs fine and I have nothing to complain about - except for one little thing that annoys me: since I have a primary key defined in the table and all the entries in the server startup when it reads from the table have opcode INSERT -> i get tons of sql integrity exceptions when starting the server because it wants to insert all the fields again into the table. Is there a nicer way to accomplish the wanted behaviour? If not, is there a way to surpress those messages in the server log? Thanks for your help and best regards,Dave", "views": "479", "answers": 5, "author": "Dave Schikora", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2012-10-26 17:34:00", "resolve": "", "uid": "6.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3257209", "text": "Hi Dave,You can do something like this... I am not sure how much this will be useful for your usecase.You can set the db_out adapter in a GROUP and add the CCL to say do not start the adapter at the start of the projectADAPTER START GROUPS RunGroup2 NOSTART;After you start the project then when the data completes its propagation through your flexstream then start up the adapter using esp_client command. C:\\TestOpen\\ESP-5_1\\bin>esp_client -p localhost:9786/default/testdboutput -c studio:geethaesp_client> start adapter RunGroup2Since you start the adapter after the completion of the data propagation you will not see the integrity erros in your log file and only the new values that you put in to the flexstream will be processed by the adapter. Hope this helps you.Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to sync DB table with ESP stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "6.2", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3257209", "text": "Hi ,I forgot to mention in my previous email that for that solution to work the db_out adapter outputBase=falseHere is another solution..I was trying out the same scenario you had described in you email and this seems to produce what you are asking for ATTACH INPUT ADAPTER Adapter2 TYPE db_inTO S1GROUP RunGroup1PROPERTIES service = 'ASEService' ,table = 'emptable' ;ATTACH OUTPUT ADAPTER Adapter1 TYPE db_out TO W1GROUP RunGroup2PROPERTIES service = 'ASEService' ,table = 'emptable' , outputBase=true,truncateTable = true ; /* delete the content of the table and reinsert the data */ADAPTER START GROUPS RunGroup1,RunGroup2;This doesn't need you to start the adapter from esp_client and it seems to work in the correct sequence. When the output adapter starts up it will delete the content of the table and reinserts it and by adding the start groups we are ensuring that the input adapter is always started before the output adapter. I am really not sure whether with large data there will be some type of threading issues with this setup. Maybe more testing is required with large data for this solution..Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to sync DB table with ESP stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "6.3", "author": "Dave Schikora", "url": "http://scn.sap.com/thread/3257209", "text": "Hi Geetha,Well thank you for the interesting approaches. I guess I may go ahead and try to automize the first approach. The second seems a little bit too unsafe for my understanding. As you said, I dont know how this will behave with huge data loads and threading. What I was hoping for was some kind of sync-with-table-feature just like the log store memory. Maybe this is something that will come in one of the next releases. Thanks a lot and best regards,Dave", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to sync DB table with ESP stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "6.4", "author": "Ashok Gopal Rao", "url": "http://scn.sap.com/thread/3257209", "text": "Hi Dave,You can try the following:1. Input stream to read data from db_in2. Send data from Input stream to Flex3. In Flex, have an additional \"flag\" column (create a schema and use it). This column will have null for data read from the table during startup.4. For all records that get inserted from within the model or other sources, insert a non-null value for the additional \"flag\" column5. Send all output to a Delta Stream (same schema minus the flag column) with a filter where \"flag\" is not null (or some value)6. Connect the delta stream to db_out.This should work fine for inserts & deletes coming into the Flex from other streams. For updates, it might require a workaround (delete original record in flex which will delete in db table & insert new record in Flex with \"flag\" set). Please be wary of changing opcodes in delta streams with filters.Let me know how this goes (i havent tried this but had done something similar).Regds,Ashok", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to sync DB table with ESP stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "6.5", "author": "Dave Schikora", "url": "http://scn.sap.com/thread/3257209", "text": "Hey Ashok,sorry for the delayed response. Your approach sounds feasible and I will go ahead and try this workaround as soon as I find time for this. At the moment we have tasks of higher priority. Nevertheless, this issue will come back to prio some time soon. I will keep you updated about how it worked out.Best regards and thanks for the help,Dave", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to sync DB table with ESP stream", "type": "answer", "tags": "N/A"},
{"date_time": "2013-01-20 12:07:00", "resolve": false, "uid": "7", "title": "ESP Studio: connecting to a project on a remote server.", "url": "http://scn.sap.com/thread/3295308", "text": "I have an esp_server that runs on a Linux machine and I try to reach it from an ESP Studio that runs on an another Windows machine.After the ESP Studio connects to the esp_server it tries to connect to the project and at this point the Studio flooded me with newer endingpop up messages:\"Failed call to:http://localhost:<port number>/RPC2 (Failed to read server's response: Connection refused: connect)\".I can stop it only if I kill esp_studio task on the Windows machine or if I stop the project by issuing the command from esp_cluster_admin on the Linux machine. What and where I miss or what and where is wrong in the configurations at the ESP Studio site or at the esp_server site?Thanks in advanceKB", "views": "503", "answers": 1, "author": "Konstantin Brotzmann", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-01-20 17:05:00", "resolve": "", "uid": "7.1", "author": "Konstantin Brotzmann", "url": "http://scn.sap.com/thread/3295308", "text": "I've got it! The cluster was not properly configured. In the node1.xml configuration file the 'localhost' value was assigned to the $ESP_HOSTNAME property.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Studio: connecting to a project on a remote server.", "type": "answer", "tags": "N/A"},
{"date_time": "2013-02-01 07:30:00", "resolve": true, "uid": "8", "title": "ESP - Flex operator - SPLASH code", "url": "http://scn.sap.com/thread/3301732", "text": "Hi all,Really quick question before I leave for the weekend!I'm considering options for how to handle future-dated events in our system, and was just wondering if there's any SPLASH variable that will give me the current date (i.e. today's date)?I can't seem to find anything in the documentation, so thought I would ask.Thanks in advance,Jason (DHS, Australia)", "views": "404", "answers": 3, "author": "Jason Kelly", "upvotes": 0, "type": "question", "tags": "date.flex.esp.splash"},
{"date_time": "2013-02-01 10:48:00", "resolve": "solution", "uid": "8.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3301732", "text": "Hi,Ok, maybe a quick answer,You could check the CCL functions now(), sysdate(0 or systimestamp() in \"Date and Time Functions\" if there is anything appropriate for you,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP - Flex operator - SPLASH code", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "8.2", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3301732", "text": "Hi Jason,Please also see sysbigdatetime().Thanks,AliceBen Pluijm wrote:Hi,Ok, maybe a quick answer,You could check the CCL functions now(), sysdate(0 or systimestamp() in \"Date and Time Functions\" if there is anything appropriate for you,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP - Flex operator - SPLASH code", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "8.3", "author": "Jason Kelly", "url": "http://scn.sap.com/thread/3301732", "text": "Thanks to you both Ben & Alice - exactly what I needed (and probably should've thought of!).Much appreciated", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP - Flex operator - SPLASH code", "type": "answer", "tags": "N/A"},
{"date_time": "2013-02-05 23:47:00", "resolve": false, "uid": "9", "title": "Log Store not found when renaming Window it is attached too", "url": "http://scn.sap.com/thread/3303915", "text": "Hi all,We have had a project running for some time now using a output window that has a log store on it. We are now looking at simply changing the name of the output window (keeping the log store name the same) and keeping everything else including the schema the same. When the output window rename has been done and the code deployed again the log store does not seem to be picked up so we are losing everything currently in the store.The error in the logs is below (with WAM_Intervention_Window being the old name of the output window, new name is WAM_Selection_Window)2013-02-05 03:42:58.859 | 1 | container | [SP-2-120037] (1.007) sp(29396) LogStore(WAM_Store)::checkSignature( WAM_Intervention_Window ) -- could not find stream in the ccx file. Is there a way around this so the log store stays attached to the newly named output window or is this intended behaviour?Cheers,Mark (DHS, Australia)", "views": "314", "answers": 1, "author": "Mark Wyatt", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-02-06 14:57:00", "resolve": "", "uid": "9.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3303915", "text": "Hello,Based on the description from the error message guide, this is expected behavior:http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01720.0511/doc/html/err120000.html\"Probably the Log Store file is used with a mismatched project ccx file. Make sure that it matches. If any LogStore stream has been changed in the model, the old LogStore file can not be used with this model any more. Start with a fresh file.\"Since you can assign more than one window to a store, I think the store uses the window name internally as identification.So I think you would have to do something like stop the incoming data of your model (you can use Studio to stop any input adapters), use esp_subscribe to get all of the data out of the window and then stop the project. Then change logstore to point to a new file and restart the project. Finally, use esp_convert and esp_upload to put the data back to a window.An alternative would be to attach file input/output adapters to the window instead of using esp_subscribe/esp_upload.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Log Store not found when renaming Window it is attached too", "type": "answer", "tags": "N/A"},
{"date_time": "2012-11-26 20:01:00", "resolve": false, "uid": "10", "title": "ESP Studio on Solaris?", "url": "http://scn.sap.com/thread/3271682", "text": "I'm interested in knowing if anyone runs the ESP Studio on Solaris? Or for that matter, the Aleri studio? While I know we have many users that run Aleri and ESP servers on Solaris, from what I can tell, it seems that pretty much everyone runs the ESP Studio on Windows, and then deploys projects on their servers running on various operating systems. If anyone uses ESP Studio on Solaris, speak up - I'd like to hear from you.", "views": "283", "answers": 2, "author": "Jeff Wootton", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-02-13 11:56:00", "resolve": "", "uid": "10.1", "author": "Vladislav Usenko", "url": "http://scn.sap.com/thread/3271682", "text": "Hi. We are using Aleri CEP servers on Solaris now and are interested in switching to ESP.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Studio on Solaris?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "10.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3271682", "text": "That's fine. The ESP Server is available on Solaris. We haven't found anyone, however, that uses or requires the ESP Studio to run on Solaris. Most users run the Studio on Windows and connect from there to an ESP Server that may be running on Solaris, Linux or Windows Server.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Studio on Solaris?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-02-18 03:56:00", "resolve": false, "uid": "11", "title": "Error writing String fields to Teradata Database", "url": "http://scn.sap.com/thread/3309682", "text": "Hi all,Im trying to read everything from a window and dump it out to a Teradata table. When I just have integer fields in the window there is no problem with this and the window contents are written out correctly. When there is a string field in the window I get the following error2013-02-15 04:56:17.626 | 55 | container | [SP-6-132004] (5428.942) sp(14571) StreamExport(OutputStream)::put() max(size(all seen blocks)) now: 22013-02-15 04:56:17.626 | 74 | container | [SP-7-150008] (5428.942) sp(14571) Connection(TeradataOut/OutputStream):: DBOutput_Adapter::putNext() Entered2013-02-15 04:56:17.627 | 74 | container | [SP-7-150008] (5428.943) sp(14571) Connection(TeradataOut/OutputStream):: DBOutput_Adapter::constructInsertSQL() Entered2013-02-15 04:56:17.628 | 74 | container | [SP-7-150008] (5428.944) sp(14571) Connection(TeradataOut/OutputStream):: DBOutput_Adapter::constructInsertSQL() Exited2013-02-15 04:56:17.628 | 74 | container | [SP-7-150008] (5428.944) sp(14571) Connection(TeradataOut/OutputStream):: DBOutput_Adapter::putNext() Insert Statement:insert into BIIS_TST_DB.ESP_BACKUP values( 'string2','tst')2013-02-15 04:56:17.629 | 74 | container | [SP-7-150008] (5428.945) sp(14571) Connection(TeradataOut/OutputStream):: DBOutput_Adapter::resetBatch() Entered2013-02-15 04:56:17.648 | 102 | container | [SP-4-108008] (5428.964) sp(14571) GatewayClient(102:138)::execute() Client closed/dropped connection.2013-02-15 04:56:17.650 | 74 | container | [SP-7-150008] (5428.966) sp(14571) Connection(TeradataOut/OutputStream):: DBOutput_Adapter::resetBatch() Exited2013-02-15 04:56:17.651 | 74 | container | [SP-7-150008] (5428.967) sp(14571) Connection(TeradataOut/OutputStream):: DBOutput_Adapter::executeUpdateSQL() Entered2013-02-15 04:56:17.657 | 74 | container | [SP-3-100005] (5428.973) sp(14571) Error executing SQL statement insert into BIIS_TST_DB.ESP_BACKUP values( ? , ? ). ODBC state: HY104ODBC error: 0ODBC message: [Teradata][ODBC Teradata Driver] Invalid precision2013-02-15 04:56:17.658 | 74 | container | [SP-3-150004] (5428.974) sp(14571) Connection(TeradataOut/OutputStream):: DBOutput_Adapter::executeUpdateSQL() executeUpdate not successful for [insert into BIIS_TST_DB.ESP_BACKUP values( ? , ? )] update count of: 02013-02-15 04:56:17.658 | 74 | container | [SP-7-150008] (5428.974) sp(14571) Connection(TeradataOut/OutputStream):: DDBOutput_Adapter::rollbackTransaction() Entered2013-02-15 04:56:17.659 | 102 | container | [SP-7-108012] (5428.975) sp(14571) GatewayClient(102:138)::execute() Exiting.  The teradata table definition isSET TABLE BIIS_TST_DB.ESP_BACKUP ( person_id VARCHAR(100) CHARACTER SET LATIN NOT CASESPECIFIC, status VARCHAR(100) CHARACTER SET LATIN NOT CASESPECIFIC)PRIMARY INDEX ( person_id );  If I just try to run this query insert into BIIS_TST_DB.ESP_BACKUP values( 'string2','tst')manually in Teradata (via the Unix Teradata-ODBC sample program, which is provided with the ODBC drivers and uses exactly the same connection as that which we define in ESP) it inserts correctly.Do you know what the issue here could be?Cheers,Mark (DHS, Australia)", "views": "856", "answers": 7, "author": "Mark Wyatt", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-02-18 21:46:00", "resolve": "", "uid": "11.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3309682", "text": "Hi Mark,From the logs it appears that ESP is sending the data to the driver properly.. We may need to see if there is anything coming up in the ODBC trace log. Can you try enabling odbc trace and posting the trace log ? If you are using windows, you can enable ODBC tracing by clicking on the Tracing tab in the ODBC Administrator and clicking on Start Tracing Now button -> start the project -> send data ->stop the project.In Unix you may need to add this [ODBC]Trace = yesTraceFile = /tmp/sql.login you /usr/local/etc/odbcinst.iniThanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error writing String fields to Teradata Database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "11.2", "author": "Mark Wyatt", "url": "http://scn.sap.com/thread/3309682", "text": "Hi Geetha,I have changed the project slightly so it is trying to first insert a integer and then a string so can see in the logs the integer seems to be ok but the string seems to get blocked with the error. Attached is the full ODBC log for when trying to insertinsert into BIIS_TST_DB.ESP_BACKUP values( 1,'tst') The teradata table definition isSET TABLE BIIS_TST_DB.ESP_BACKUP  ( person_id INTEGER, status VARCHAR(64000) CHARACTER SET LATIN NOT CASESPECIFIC )PRIMARY INDEX ( person_id );  In the ODBC log I can see it binds the integer ok ENTER SQLBindParameter  HSTMT 0x02010090 UWORD 1  SWORD 1 <SQL_PARAM_INPUT> SWORD -16 <SQL_C_SLONG> SWORD 4 <SQL_INTEGER> UDWORD 10 SWORD 0  PTR 0x03881b50 SDWORD 25 SQLLEN * 0x034ece08 EXIT SQLBindParameter with return code 0 (SQL_SUCCESS) HSTMT 0x02010090 UWORD 1  SWORD 1 <SQL_PARAM_INPUT> SWORD -16 <SQL_C_SLONG> SWORD 4 <SQL_INTEGER> UDWORD 10 SWORD 0  PTR 0x03881b50 SDWORD 25 SQLLEN * 0x034ece08 (0)but then when it trys to bind the string it seems to be erroring outENTER SQLBindParameter  HSTMT 0x02010090 UWORD 2  SWORD 1 <SQL_PARAM_INPUT> SWORD 1 <SQL_C_CHAR> SWORD 12 <SQL_VARCHAR> UDWORD 0 SWORD 0  PTR 0x038816d0 SDWORD 5 SQLLEN * 0x03497848 EXIT SQLBindParameter with return code -1 (SQL_ERROR) HSTMT 0x02010090 UWORD 2  SWORD 1 <SQL_PARAM_INPUT> SWORD 1 <SQL_C_CHAR> SWORD 12 <SQL_VARCHAR> UDWORD 0 SWORD 0  PTR 0x038816d0 SDWORD 5 SQLLEN * 0x03497848  ENTER SQLGetDiagRec  SQLSMALLINT 3  SQLHANDLE 0x02010090 SQLSMALLINT 1  SQLCHAR * 0x035dad90 (NYI)  SQLINTEGER * 0x03521218 SQLCHAR * 0x035dd390 (NYI)  SQLSMALLINT 513  SQLSMALLINT * 0x6873eebe EXIT SQLGetDiagRec with return code 0 (SQL_SUCCESS) SQLSMALLINT 3  SQLHANDLE 0x02010090 SQLSMALLINT 1  SQLCHAR * 0x035dad90 [ 5] \"HY104\" SQLINTEGER * 0x03521218 (0) SQLCHAR * 0x035dd390 [ 50] \"[Teradata][ODBC Teradata Driver] Invalid precision\" SQLSMALLINT 513  SQLSMALLINT * 0x6873eebe (50)  The only description I can find for the error reads The value specified for ParameterType is either SQL_DECIMAL or SQL_NUMERIC, and the value specified for ParamDef is less than one. Which also makes no real sense at all to me based on the parameter type we are using here is not SQL_DECIMAL or SQL_NUMERIC so not sure what its about.Any help would be greatly appreciated!Cheers Mark", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error writing String fields to Teradata Database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "11.3", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3309682", "text": "Hi Mark,As per the trace logs it seems that the ColumnSize is wrong. Are you using the esp_db_odbc64_lib or esp_db_odbc_lib in your service.xml file ?Please see the *Note* here http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01611.0511/doc/html/cgo1352748898500.htmlYou should be able to check the SQLLEN size of the ODBC driver manager by running ESP-5_1/bin> odbcinst -junixODBC 2.3.1DRIVERS............: /usr/local/etc/odbcinst.iniSYSTEM DATA SOURCES: /usr/local/etc/odbc.iniFILE DATA SOURCES..: /usr/local/etc/ODBCDataSourcesUSER DATA SOURCES..: /usr/u/vchittar/.odbc.iniSQLULEN Size.......: 8SQLLEN Size........: 8SQLSETPOSIROW Size.: 8Can you please verify whether you are using the correct odbc library in your service.xml file ? Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error writing String fields to Teradata Database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "11.4", "author": "Mark Wyatt", "url": "http://scn.sap.com/thread/3309682", "text": "Hi Geetha,We are using a 64-bit manager and have it set to esp_db_odbc64_lib in service.xml. However I have tried pretty much every variable combination of 32 and 64 bit over the past few days in the config files and have still been unable to get this to work. I have changed it so the program is writing out to a file instead as this will suffice for now but we would like to get this sorted at some point.Do you have anymore ideas on what I could try?Cheers, Mark", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error writing String fields to Teradata Database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "11.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3309682", "text": "Hello,Can you provide the output from \"odbcinst -j\" so that we can see what version of unixODBC you have installed and what it is using for SQLLEN, SQLULEN, etc.?If you are using a very old version of unixODBC, you will likely need to update it to 2.3.0 or 2.3.1.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error writing String fields to Teradata Database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "11.6", "author": "Mark Wyatt", "url": "http://scn.sap.com/thread/3309682", "text": "Hi Neal,Looks like we are using unixODBC 2.2.12 (which is a very old version!)odbcinst -j returns the below info but because its so old it doesn't include the SQLLEN, SQLULEN infoespadm@dcvsuz1435 $ cd /opt/sybase/ESP-5_1/binespadm@dcvsuz1435 $ odbcinst -junixODBC 2.2.12DRIVERS............: /opt/csw/etc/odbcinst.iniSYSTEM DATA SOURCES: /opt/csw/etc/odbc.iniUSER DATA SOURCES..: /home/espadm/.odbc.iniI'll get in contact with our infrastructure guys to see if they can update it. Will let you know if that resolves it.Cheers,Mark", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error writing String fields to Teradata Database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "11.7", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3309682", "text": "Hello,Thank you for getting this information.The reason this information is so important is that it tells us the length of the variables SQLLEN, SQLULEN and SQLSETPOSIROW. According to the unixODBC change log (http://www.unixodbc.org/ ), the unixODBC driver manager changed the default length of these variables in the 2.2.13 release from 4 to 8.Both of the ESP ODBC Driver interface libraries are 64bit:% file libesp_db_odbc_lib.solibesp_db_odbc_lib.so: ELF 64-bit MSB dynamic lib SPARCV9 Version 1, dynamically linked, not stripped% file libesp_db_odbc64_lib.solibesp_db_odbc64_lib.so: ELF 64-bit MSB dynamic lib SPARCV9 Version 1, dynamically linked, not strippedHowever, the difference between the two libraries is that \"libesp_db_odbc64\" uses a length of 8 for these variables and \"libesp_db_odbc\" uses a length of 4.There are three pieces in this ODBC puzzle that have to match (that have to use the same SQLLEN):* The ESP ODBC Driver interface ( libesp_db_odbc or libesp_db_odbc64 )* The ODBC driver manager (unixODBC or other third party driver managers like DataDirect)* The ODBC driver itself (Teradata, ASE, Oracle, etc.)If any one piece of this puzzle uses different length variables than the other pieces, you will see random crashes (some simple queries might succeed but other queries might not) because of memory overwrites.Finally, since both of the ESP ODBC driver interface libraries are 64bit, you will always need to use a 64bit ODBC driver (whether it be Teradata, Sybase, etc.).Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error writing String fields to Teradata Database", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-01 16:03:00", "resolve": false, "uid": "12", "title": "Problems with Sybase ESP 5.1 - JMS XML input adapter", "url": "http://scn.sap.com/thread/3317415", "text": "I trying to read a xml message from a jms queue using the JMS XML Input Adapter, but only the first line of the message is returned to me. Can anyone help me with this question?", "views": "421", "answers": 2, "author": "Camila Alves", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-01 17:27:00", "resolve": "", "uid": "12.1", "author": "Mike Weadley", "url": "http://scn.sap.com/thread/3317415", "text": "Hi Camilla,Would you please provide more detail about your input message contents/format, and also about where/how you are reading the first line?Mike", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problems with Sybase ESP 5.1 - JMS XML input adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "12.2", "author": "Camila Alves", "url": "http://scn.sap.com/thread/3317415", "text": "Hi Mike,I am trying to read the following message of a jms queue(activemq) using the JMS XML Input adapter:<?xml version=\"1.0\" encoding=\"UTF-8\"?><?opentarget version=\"1.0\"?><opentarget><txn id=\"285088426\" /><tbl name=\"DATABASE.DEMO_SRC\" utcOffset=\"-3:00\"><cmd ops=\"schema\"><schema><col name=\"NAME\" xmlType=\"string\" key=\"true\" nullable=\"true\" length=\"30\" /><col name=\"ADDRESS\" xmlType=\"string\" key=\"true\" nullable=\"true\" length=\"60\" /><col name=\"PHONE#\" xmlType=\"string\" key=\"true\" nullable=\"true\" length=\"12\" /></schema></cmd></tbl></opentarget>Configuration file:I can only read the line \"<txn id=\"285088426\" />\". I tried to add more fields to the schema, to get the other lines of the message, but it simply ignores it, and show them as null values.Camila.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problems with Sybase ESP 5.1 - JMS XML input adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-04 15:26:00", "resolve": false, "uid": "13", "title": "Sybase ESP 5.1 - Using the JMS XML Input Adapter", "url": "http://scn.sap.com/thread/3318619", "text": "Hi, I would like to know if the JMS XML Input Adapter can reads a message in the format below:<?xml version=\"1.0\" encoding=\"UTF-8\"?><?opentarget version=\"1.0\"?><opentarget><txn id=\"135198375\" /><tbl name=\"SCHEMA.DEMO_SRC\"><cmd ops=\"del\"><row id=\"AAASUnAAEAAAFOkAAF\"><lkup><col name=\"NAME\">TESTED</col><col name=\"ADDRESS\">8008 Irvine Center Drive</col><col name=\"PHONE#\">949-754-8000</col></lkup></row></cmd></tbl></opentarget>or it should be converted to a message format like this:<W1 ESP_OPS=\"i\" Id=\"1\" Symbol=\"SAP\" c_integer=\"3000\" c_string=\"test\" c_float=\"1.2\" c_long=\"300000\" c_date=\"2011-02-10T13:31:46\" c_timestamp=\"2011-02-10T13:31:46.123\" c_bigdatetime=\"2011-02-10T13:31:46.123456\" c_binary=\"5468697320697320535942415345204553502054657374696e67\" c_boolean=\"true\" c_interval=\"123456789\"/>Can anyone help me with this question?", "views": "328", "answers": 0, "author": "Camila Alves", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-05 09:50:00", "resolve": false, "uid": "14", "title": "subquery in a FROM clause", "url": "http://scn.sap.com/thread/3319310", "text": "Hi,Can someone please tell me if it is possible to use a sub-query in a FROM clause in Sybase ESP?What I am trying to achieve is the aggregation of UNION of streams in a SINGLE query.For instanceSelect  SUM(subquery.Value) SUM_Value From  ( Select  A.Value  from  StreamA A   Union   Select  B.Value  from  StreamB B ) As subquery", "views": "278", "answers": 0, "author": "Rahim Makhani", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-05 09:51:00", "resolve": false, "uid": "15", "title": "subquery in a FROM clause", "url": "http://scn.sap.com/thread/3319311", "text": "Hi,Can someone please tell me if it is possible to use a sub-query in a FROM clause in Sybase ESP?What I am trying to achieve is the aggregation of UNION of streams in a SINGLE query.For instanceSelect  SUM(subquery.Value) SUM_Value From  ( Select  A.Value  from  StreamA A   Union   Select  B.Value  from  StreamB B ) As subquery", "views": "285", "answers": 0, "author": "Rahim Makhani", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-04 17:03:00", "resolve": true, "uid": "16", "title": "Generic DB Input Adapter for SAP HANA with Query statement", "url": "http://scn.sap.com/thread/3318784", "text": "Hi colleagues,I am trying to have a SAP HANA Table serving as input for my ESP stream. Therefore I am using generic db_in adapter with query parameter. So far this is no problem, I only have one question regarding schema and notation. The following ccl code works fine:CREATE INPUT STREAM DataStream1 SCHEMA ( time long );ATTACH INPUT ADAPTER Statapter TYPE db_in TO DataStream1 PROPERTIES service = 'HANAService' ,query = 'SELECT max(TEST) as time FROM EVELYN_STREAMS.TEST',pollperiod = 0,dateFormat = '%Y-%m-%dT%H:%M:%S' ,timestampFormat = '%Y-%m-%dT%H:%M:%S' ;ATTACH OUTPUT ADAPTER Adapter1 TYPE dsv_out TO DataStream1 PROPERTIES dir = '/usr/sap/P01/home' ,file = 'testout.csv' ;However, this works only if the field TEST in the hana table is created as TEST in upper case. test in lower case does not work. In this case I get an SQL interpretation error. Now I have tried different escapings and stuff but nothing seems to work. Here are two examples that cause runtime errors: 'SELECT max(\"test\") as time FROM EVELYN_STREAMS.TEST''SELECT max(\\\"test\\\") as time FROM EVELYN_STREAMS.TEST'any ideas /experiences on that? Those case sensitive HANA schemata have been a trouble in some cases now. Best practise is to only use upper case for HANA schemas, but I'm just curious about this now. Best regards,Dave", "views": "625", "answers": 2, "author": "Dave Schikora", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-04 18:39:00", "resolve": "solution", "uid": "16.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3318784", "text": "Hi Dave,The CCL is compiled into an XML file so you may have to use the XML \"&quot;\" to surround the column names so that the resultant XML file does not have syntax errors.If you rename your \"esp_server.ccx\" to \"esp_server.xml\" and edit this file with an editor capable of checking the XML grammer you will likely see an error on the quoted column: <ConnectionParam name=\"query\" value=\"select count(\"domain_id\") from CE_OUT\" />I wrote up a change request some time ago for this issue: 717195 - ESP does not properly support quoted identifiers in database queriesSo if a table is created in HANA (or ASE) with quoted identifiers, you will have to use this funky little workaround if your ESP query needs to reference the quoted identifiers:CREATE INPUT STREAM ROLES_stream1 SCHEMA ( ROLE_NAME string , ROLE_ID long , ROLE_MODE string) ;ATTACH INPUT ADAPTER Adapter1 TYPE db_in TO ROLES_stream1 PROPERTIES service = 'HANAODBCService' ,// The following two queries do not work against quoted identifiers// query = 'select \"role_name\", \"role_id\", \"role_mode\" from esp_roles' ,//query = 'select \\\"role_name\\\", \\\"role_id\\\", \\\"role_mode\\\" from esp_roles' ,// The following query works on tables with quoted identifiersquery = 'select &quot;role_name&quot;, &quot;role_id&quot;, &quot;role_mode&quot; from esp_roles' ,pollperiod = 30 ;", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Generic DB Input Adapter for SAP HANA with Query statement", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "16.2", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3318784", "text": "Hi Dave,Can you try using &quot; ? This is a known limitation in the polling query for the db adapter. There should be a resolution for this in the future release of ESP. As a workaround replace the double quotes by &quot;.. This worked for me in my internal testing create input window test schema(volume integer)primary key (volume);ATTACH INPUT ADAPTER Statapter TYPE db_in TO testPROPERTIES service = 'HANAODBCService' ,query = 'SELECT avg(&quot;VOLUME&quot;) FROM GEETHA.STOCK',pollperiod = 0;However there was issues with max and min. Maybe this is due to my lack of knowledge in HANA.Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Generic DB Input Adapter for SAP HANA with Query statement", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "16.3", "author": "Dave Schikora", "url": "http://scn.sap.com/thread/3318784", "text": "Thanks a lot, that solved the issue", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Generic DB Input Adapter for SAP HANA with Query statement", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-01 12:53:00", "resolve": false, "uid": "17", "title": ".Net client API subscription get events from other stream", "url": "http://scn.sap.com/thread/3317231", "text": "Hi.We have been using Aleri CEP for a while and not are considering moving to SybaseESP.When building proof of concep using ESP .Net API, we have faced strange issue, that subscription handlers can receive events from streams, which they didn't subscribed to.Please, see code, based on the standard examples attached:using System;\nusing System.Collections.Generic;\nusing System.Threading;\nusing SYBASE.Esp.SDK;\nnamespace Sybase.Esp.SDK.examples\n{\n internal class SubScriberExample\n {\n private static NetEspSdk s_sdk;\n private const int WAIT_TIME_60000_MS = 60000;\n private static void print_error_and_exit(NetEspError espError)\n {\n Console.Out.WriteLine(\"An error was encountered\\n\");\n Console.Out.WriteLine(espError.get_message());\n Console.Out.WriteLine(\"\\nExiting\\n\");\n Console.ReadLine();\n Environment.Exit(1);\n }\n private static void Main(string[] args)\n {\n int rc = 0;\n int intcol;\n string stringcol;\n string host = \"testhost.ru.db.com\";\n int espport = 19011;\n string workspace = \"test\";\n string pname = \"test2\";\n string uristring = \"esp://\" + host + \":\" + Convert.ToString(espport);\n var espError = new NetEspError();\n s_sdk = NetEspSdk.get_sdk();\n s_sdk.start(espError);\n try\n {\n var creds =\n new NetEspCredentials(NetEspCredentials.NET_ESP_CREDENTIALS_T.NET_ESP_CREDENTIALS_USER_PASSWORD);\n creds.set_user(\"sybase\");\n creds.set_password(\"sybase\");\n var soptions = new NetEspServerOptions();\n // change to uri\n var uri = new NetEspUri();\n uri.set_uri(uristring, espError);\n //NetEspServer server = s_sdk.get_server(host, 22000, creds, soptions, espError);\n NetEspServer server = s_sdk.get_server(uri, creds, soptions, espError);\n rc = server.connect(espError);\n if (rc != 0)\n {\n print_error_and_exit(espError);\n }\n var projoptions = new NetEspProjectOptions();\n NetEspProject project;\n project = server.get_project(workspace, pname, projoptions, espError);\n rc = project.connect(espError);\n if (rc != 0)\n {\n print_error_and_exit(espError);\n }\n var suboptions = new NetEspSubscriberOptions();\n suboptions.set_mode(NetEspSubscriberOptions.NET_ESP_ACCESS_MODE_T.NET_CALLBACK_ACCESS);\n suboptions.set_pulse_interval(0);\n for (int i = 1; i <= 2; i++)\n {\n NetEspSubscriber subscriber = project.create_subscriber(suboptions, espError);\n var item = new SubscriptionItem(subscriber, i);\n List.Add(item);\n item.Start();\n }\n Thread.Sleep(-1);\n //subscriber.disconnect(espError);\n server.disconnect(espError);\n Console.Out.WriteLine(\"Messages Received successfully\\n\");\n }\n finally\n {\n rc = s_sdk.stop(espError);\n }\n }\n private static readonly List<SubscriptionItem> List = new List<SubscriptionItem>();\n }\n public class SubscriptionItem\n {\n private readonly NetEspSubscriber _subscriber;\n private readonly int _subId;\n public SubscriptionItem(NetEspSubscriber subscriber, Int32 subId)\n {\n _subscriber = subscriber;\n _subId = subId;\n }\n public void Start()\n {\n var espError = new NetEspError();\n if (_subId == 1)\n {\n _subscriber.subscribe_sql(\"Select * From Stream1\", espError);\n _subscriber.set_callback((uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_ALL,\n SubscriberEventCallback1, new IntPtr(_subId), espError);\n }\n else\n {\n _subscriber.subscribe_sql(\"Select * From Stream2\", espError);\n _subscriber.set_callback((uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_ALL,\n SubscriberEventCallback2, new IntPtr(_subId), espError);\n }\n _subscriber.connect(espError);\n }\n //public void Stop()\n //{\n // var espError = new NetEspError();\n // _subscriber.remove_callback(SubscriberEventCallback, espError);\n // _subscriber.disconnect(espError);\n //}\n public void SubscriberEventCallback1(NetEspSubscriberEvent event1, ValueType userData)\n {\n int intcol;\n string stringcol;\n var espError = new NetEspError();\n if (int.Parse(userData.ToString()) != _subId)\n {\n Console.Out.WriteLine(\"Unknown subscriber\");\n }\n switch (event1.getType())\n {\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_SYNC_START:\n Console.Out.WriteLine(\"<Sync-Start>\");\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_SYNC_END:\n // if you want to exit after reading data set done = true here\n Console.Out.WriteLine(\"<Sync-End>\");\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_DATA:\n NetEspMessageReader reader = event1.getMessageReader();\n NetEspRowReader rows = reader.next_row(espError);\n while (rows != null)\n {\n intcol = rows.get_integer(0, espError);\n Console.Out.Write(intcol);\n stringcol = rows.get_string(1, espError);\n Console.Out.WriteLine(\" \" + stringcol);\n Console.Out.WriteLine(DateTime.Now.ToLocalTime().ToLongTimeString());\n rows = reader.next_row(espError);\n }\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_CLOSED:\n Console.Out.WriteLine(\"<closed/>\");\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_DISCONNECTED:\n Console.Out.WriteLine(\"<disconnected/>\");\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_ERROR:\n Console.Out.WriteLine(\"<error> \" + event1.getError().get_message());\n break;\n case (uint) (NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_CONNECTED):\n Console.WriteLine(\"<connected>\");\n break;\n case (uint) (NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_SUBSCRIBED):\n Console.WriteLine(\"<connected>\");\n break;\n default:\n Console.Out.WriteLine(\"Event: \" + event1.getType().ToString());\n break;\n }\n }\n public void SubscriberEventCallback2(NetEspSubscriberEvent event1, ValueType userData)\n {\n int intcol;\n string stringcol;\n var espError = new NetEspError();\n if (int.Parse(userData.ToString()) != _subId)\n {\n Console.Out.WriteLine(\"Invalid subscriber\");\n }\n switch (event1.getType())\n {\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_SYNC_START:\n Console.Out.WriteLine(\"<Sync-Start>\");\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_SYNC_END:\n // if you want to exit after reading data set done = true here\n Console.Out.WriteLine(\"<Sync-End>\");\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_DATA:\n NetEspMessageReader reader = event1.getMessageReader();\n NetEspRowReader rows = reader.next_row(espError);\n while (rows != null)\n {\n intcol = rows.get_integer(0, espError);\n Console.Out.Write(intcol);\n stringcol = rows.get_string(1, espError);\n Console.Out.WriteLine(\" \" + stringcol);\n Console.Out.WriteLine(DateTime.Now.ToLocalTime().ToLongTimeString());\n rows = reader.next_row(espError);\n }\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_CLOSED:\n Console.Out.WriteLine(\"<closed/>\");\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_DISCONNECTED:\n Console.Out.WriteLine(\"<disconnected/>\");\n break;\n case (uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_ERROR:\n Console.Out.WriteLine(\"<error> \" + event1.getError().get_message());\n break;\n case (uint) (NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_CONNECTED):\n Console.WriteLine(\"<connected>\");\n break;\n case (uint) (NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_SUBSCRIBED):\n Console.WriteLine(\"<connected>\");\n break;\n default:\n Console.Out.WriteLine(\"Event: \" + event1.getType().ToString());\n break;\n }\n }\n }\n}Using this code we expect to get in  SubscriberEventCallback1 events from Stream1 and in SubscriberEventCallback2 events from Stream2.On practice, sometimes (especially on high event rate) SubscriberEventCallbacks receive events from oposite streams.Is there any solution, which allows to split events and direct them only to the proper CallbackHandler?Thank you in advance.", "views": "471", "answers": 5, "author": "Vladislav Usenko", "upvotes": 0, "type": "question", "tags": "esp_5.1"},
{"date_time": "2013-03-01 14:01:00", "resolve": "", "uid": "17.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3317231", "text": "Hi Vladislav,At what event rate do you see the problem happening?Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "17.2", "author": "Vladislav Usenko", "url": "http://scn.sap.com/thread/3317231", "text": "Hi Alice, Actually the problem is general - it might happen even on small update rate - ~10-50 rec/s.  High load (we have tested ~100-200rec/s and 10 subscription per app) increases probability of event missing its original CallbackHandler.  Also there is the case when your streams (Stream1 and Stream2 in my example) has couple of thousands of records, and you try to get BASE simultaniously with different subscriptions. This way some of the events can also be directed to the wrong CallbackHandler. Thank you.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "17.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3317231", "text": "Hello,Can you post your code as an attachment? I can't seem to find a way to copy and test it without getting all of the line numbers.If you click on the \"Use advanced editor\" when replying, you can post the your code as a \".txt\" file.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "17.4", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3317231", "text": "Hello,I edited out all of the line numbers and ran your program. This is the output I get:Invalid subscriber<connected>Invalid subscriber<subscribed><connected><subscribed><Sync-Start><Sync-End>Invalid subscriber<Sync-Start>Invalid subscriber<Sync-End>Do you also get these \"Invalid subscriber\" messages?I don't see in your code where you differentiate what was received in SubscriberEventCallback1 versus SubscriberEventCallback2. Am I looking at the correct code?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "17.5", "author": "Vladislav Usenko", "url": "http://scn.sap.com/thread/3317231", "text": "Hello. Yes, this is code that we were trying to run. This code creates separate subscriprions depnding on _subIdif (_subId == 1) \n { \n _subscriber.subscribe_sql(\"Select * From Stream1\", espError); \n _subscriber.set_callback((uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_ALL, \n SubscriberEventCallback1, new IntPtr(_subId), espError); \n } \n else \n { \n _subscriber.subscribe_sql(\"Select * From Stream2\", espError); \n _subscriber.set_callback((uint) NetEspSubscriber.NET_ESP_SUBSCRIBER_EVENT.NET_ESP_SUBSCRIBER_EVENT_ALL, \n SubscriberEventCallback2, new IntPtr(_subId), espError); \n } If i'm not mistaking, according to .Net API, value, provided when registering CallbackHandler, will return in events. It is checked using this code:public void SubscriberEventCallback2(NetEspSubscriberEvent event1, ValueType userData) \n { \n int intcol; \n string stringcol; \n var espError = new NetEspError(); \n \n \n if (int.Parse(userData.ToString()) != _subId) \n { \n Console.Out.WriteLine(\"Invalid subscriber\"); \n } \n....If you have an example of subsription to a number of streams at the same time, which does not mix events, can you, please, sent it to us?Thank you.Best regards, Vladislav Usenko", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "17.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3317231", "text": "Hello,If you get the \"Invalid Subscriber\" messages as I do, this would seem to indicate that the wrong callback is being raised even when no data is flowing.Is the subscribe_sql() required for your project? There are other techniques such as subscribe_stream().Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "17.7", "author": "Vladislav Usenko", "url": "http://scn.sap.com/thread/3317231", "text": "Hi. This is very frustrating that such \"Enterprise\" product has got this kind of bugs in its core functionality... We are aware about different ways how to subscribe to streams in Callback mode and tryed each of them - bug can be reprodused no matter how you subscribe. We have been using Aleri CEP for about three years and our app contains more than 10 preety big Aleri models, number of java, C++ adapters and .Net rich GUI, which operates through SQL projection subscriptions. So we are preety sure that sql subscription is our use case.  First of all we were considering upgrading Aleri to ESP, rather moving to another CEP because of \"out of the box\" .Net support. Is there any hope that this problem will be fixed in near future?  Does Sybase ESP have any open bugtracker, where this problem can be registered?Thank you.Best regards, Vladislav Usenko.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "17.8", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3317231", "text": "Hello,I would recommend opening a case with SAP/Sybase techincal support. Sybase customers will be renewing their support agreements on SAP paper this year. I don't know if you have done this yet so you will need to open a technical support case with the company under which you currently have support.The SAP Community is not the ideal place for reporting bugs. Bugs that are reported via a technical support case automatically get a higher priority than something mentioned in a community post. If there is a technical support case open, we can attach your business case to the bug and give it an even higher priority.You asked us to write you an example program that subscribes to multiple streams. I asked about subscribe_sql() to better understand your use case. It would be a waste of time to write up an example without thoroughly understanding your goals.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "17.9", "author": "Vladislav Usenko", "url": "http://scn.sap.com/thread/3317231", "text": "Hi. We are currently waiting for support aggreement renewing and right after that we will open technical support case. Thank you for the advise.Best regards,Vladislav Usenko.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net client API subscription get events from other stream", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-05 09:53:00", "resolve": false, "uid": "18", "title": "subquery in a FROM clause", "url": "http://scn.sap.com/thread/3319312", "text": "Hi,Can someone please tell me if it is possible to use a sub-query in a FROM clause in Sybase ESP?What I am trying to achieve is the aggregation of UNION of streams in a SINGLE query.For instanceSelect SUM(subquery.Value) SUM_ValueFrom ( Select A.Value from StreamA A  Union  Select B.Value from StreamB B ) As subquery", "views": "965", "answers": 5, "author": "Rahim Makhani", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-05 20:10:00", "resolve": "", "uid": "18.1", "author": "Vladislav Usenko", "url": "http://scn.sap.com/thread/3319312", "text": "Hi. I would suggest to create separate union stream and use it as a source for your aggregation.Thanks.Best regardsVladislav Usenko", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:subquery in a FROM clause", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "18.2", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3319312", "text": "Hi Rahim,You need to split them and use them as 2 queries. Subqueries are not supported . This is not SQL and you will find not all SQL constructs supported in CCL. You can use a local stream for your union and make that as a input for your aggregation. Streams are stateless entities and they don't occupy any memory. Here is a example showing the code CREATE INPUT STREAM S1 SCHEMA (symbol string, volume integer,price float);CREATE INPUT STREAM S2 SCHEMA (symbol string, volume integer,price float);CREATE LOCAL STREAM S3 SCHEMA (symbol string, volume integer,price float)as select * from S1unionselect * from S2;CREATE OUTPUT WINDOW W1 SCHEMA(symbol string, sum_volume integer)PRIMARY KEY DEDUCEDas select A.symbol as symbol,sum(A.volume) as sum_volumefrom S3 A GROUP BY A.symbol;Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:subquery in a FROM clause", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "18.3", "author": "Rahim Makhani", "url": "http://scn.sap.com/thread/3319312", "text": "Hi,Thanks for your response.As an alternative, I am trying to use a full join based on timestamp. However, I am not sure about the repercussions/issues using a full join.CREATE OUTPUT WINDOW W1 PRIMARY KEY DEDUCEDSELECT firstnonnull(S1.Time, S2.Time) Sys_Time ,coalesce(S.volume,0)+coalesce(S.volume,0) SUM_VolumeFROM S1FULL JOIN S2ON S1.Time = S2.Time", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:subquery in a FROM clause", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "18.4", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3319312", "text": "Hi,See here http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01612.0511/doc/html/eli1306526175574.html it is not possible to join 2 streams. You can have a stream -window join or a window-window join a stream-stream join is not possible. Moreover the full join query you have doesn't show what is the time granularity you are using. ESP has microsecond granularity and that join can never have 2 same values if it has a bigdatetime field. What is the problem you are trying to solve ? Can you give us some sample input data and the expected output ? Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:subquery in a FROM clause", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "18.5", "author": "Rahim Makhani", "url": "http://scn.sap.com/thread/3319312", "text": "Thanks for your response Geetha. I did not realize that in the last example, you used input streams rather than windows.Yes, I am using bigdatetime field.Here is the sample input data, and the expected output.Input_Window1Time Value 2013-03-06 19:19:11.034477 5 2013-03-06 19:19:12.554477 5Input_Window2Time Value 2013-03-06 19:19:11.134477 4 2013-03-06 19:19:12.034477 4 Output_Window1Time Value 2013-03-06 19:19:11.034477 5 2013-03-06 19:19:11.134477 9 2013-03-06 19:19:12.034477 9 2013-03-06 19:19:12.554477 9Note the difference in the microseconds granularity for each input. The result should sum up the latest (last seen) values from each input window... Ideally I would like to achieve this with a single query.Regards,Rahim", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:subquery in a FROM clause", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "18.6", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3319312", "text": "Hi Rahim,I ran a couple of simple test cases and your query is good. I don't see any issues with your query. The only point is that the Input_Window1.Time should be a key field and Input_Window2.Time should also be a key field. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:subquery in a FROM clause", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "18.7", "author": "Rahim Makhani", "url": "http://scn.sap.com/thread/3319312", "text": "Hi Geetha,Thank you for your prompt response. Taking the same example that I mentioned in my last post, I am using the following queryCREATE OUTPUT WINDOW Ouput_Window1 PRIMARY KEY DEDUCEDASSELECT firstnonnull(W1.Time, W2.Time) Sys_Time ,coalesce(W1.Value,0)+coalesce(W2.Value,0) SUM_ValueFROM W1 FULL JOIN W2 ON W1.Time = W2.TimeGROUP BY firstnonnull(W1.Time, W2.Time);The problem I am facing is that for every second, the group by clause is considering only one value from one of the input windows. And it is discarding the second valueFor instanceInstead of getting an output likeOutput_Window1Time 2013-03-06 19:19:11.034477 2013-03-06 19:19:11.134477 2013-03-06 19:19:12.034477 2013-03-06 19:19:12.554477 I am getting the outputOutput_Window1Time 2013-03-06 19:19:11.034477 2013-03-06 19:19:12.034477 I thought that with full join, and group by clause based on bigdatetime, I should have got four rows, instead of two.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:subquery in a FROM clause", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "18.8", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3319312", "text": "Hi Rahim,You are correct it should have resulted in 4 rows. But I don't think there is any value addition to the groupby clause here. If you can open a support case with us we can open a change request for this. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:subquery in a FROM clause", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-12 10:53:00", "resolve": false, "uid": "19", "title": "preventing reverse engineering of ccx file", "url": "http://scn.sap.com/thread/3323809", "text": "I would like to know that there is a way to encrypt the ccx file (I mean the compiled file of the project). I want to prevent revese engineering from ccx and ccl files which are deployed to the server. Is there anyway to do this? Is there a way to use just run-time executable or anything else?", "views": "356", "answers": 5, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-12 13:50:00", "resolve": "", "uid": "19.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3323809", "text": "Hello,Currently, there is no way to encrypt the CCX file. There is an outstanding feature request: 678941.This feature request has a very low priority. If it is important to you, I would recommend logging a case and have CR 678941 associated to it because that will help raise the priority.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:preventing reverse engineering of ccx file", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "19.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3323809", "text": "I would be interested in hearing more about your requirements and why you need this. As Neal indicated - this is on our backlog of enhancement requests but currently isn't a high priority. That could change with input from users like you.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:preventing reverse engineering of ccx file", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "19.3", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3323809", "text": "Hi Jeff,One of our partner in telecom sector is trying to develop a key solution with ESP for the telecom providers. On this kind of the solution, the partner don't want to share the know-how, just want to provide executable or encrypted compiled files (ccx). That's why I openned this discussion. Jeff, I have also one more question for you. How can I find documents for ESP which is about the anatomy and the general architecture of the ESP projects? Documents, I can reached, are generally about the usage of the ESP or basic concepts of the CEP. The partner and I need more comprehensive document to develop a big scale ESP project. Do you have any suggestion?", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:preventing reverse engineering of ccx file", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "19.4", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3323809", "text": "It might be best to discuss. Give me a call or send me an email.The full set of ESP docs is online: http://infocenter.sybase.com/help/index.jsp;jsessionid=1nmebxm2yoriw?docset=/com.sybase.infocenter.help.esp.5.1.1/doc/html/title.html&docSetID=1930", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:preventing reverse engineering of ccx file", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "19.5", "author": "Muzaffer Yontem", "url": "http://scn.sap.com/thread/3323809", "text": "Hi Jeff, Is there any way to discuss this specific case over Skype or conference call. Your inputs will be valuable while creating final architecture..rgs", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:preventing reverse engineering of ccx file", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "19.6", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3323809", "text": "Sure - just send me an email (jeff.wootton at sap.com) and we can set something up.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:preventing reverse engineering of ccx file", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-01 04:20:00", "resolve": false, "uid": "20", "title": "ESP5.1 - Using a Window in CCL modules - memory use?", "url": "http://scn.sap.com/thread/3316921", "text": "Hi again,Just a quick question about how memory is used when we use an INPUT window within a module.In one of our projects, we are using a module in order to keep the project's code more modular & simple. The module itself contains an INPUT window:CREATE MODULE cuphIN ISIS_CUPH_InputStream, WAM_InputWindowOUT OutputStream... CREATE INPUT STREAM ISIS_CUPH_InputStream SCHEMA ISIS_CUPH;CREATE LOCAL STREAM ISIS_CUPH_MOBFilteredStream AS SELECT * FROM ISIS_CUPH_InputStream WHEREISIS_CUPH_InputStream.ISIS_CUPH_TYPE_CODE = 'MOB' ;CREATE INPUT WINDOW WAM_InputWindow SCHEMA WAM_selection PRIMARY KEY(WAM_PERSON_ID, WAM_BICE_SOURCE_TYPE_CODE,  WAM_BICE_SOURCE_ID, WAM_BIIS_MATCH_LIST_ID, WAM_BIIS_MATCH_DATA_ID);And, as per the following screenshot, this INPUT window in the module essentially points to a Window that exists in the project itself:Now, in this case, both the: - WAM_Selection_Window (an OUTPUT window in the project) - WAM_InputWindow (an INPUT window in the module)...have a KEEP ALL policy.By using a module in this way, are we effectively doubling up on the total amount of memory used to store the contents of the windows? Or does the module's window basically just point to the contents of the project's window (i.e. are there smarts built into ESP that basically just use the module's window as a reference to the contents of the parent's window itself)?Basically I just want to check to see if we are using additional memory due to the definition of the INPUT window within the module. If we weren't using a module, and just had similar code within the project itself, would we be using less memory (as, in this case, there wouldn't be any INPUT window at all)?Hope that makes sense!Thanks,Jason.", "views": "410", "answers": 4, "author": "Jason Kelly", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-04 08:16:00", "resolve": "", "uid": "20.1", "author": "Vladislav Usenko", "url": "http://scn.sap.com/thread/3316921", "text": "Hi, Jason. Have you tried looking through compiled xml for your project?  Does it contain two instances of mentioned streams (windows) or just one? Thank you.Best regards, Vladislav Usenko.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP5.1 - Using a Window in CCL modules - memory use?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "20.2", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3316921", "text": "Hi Jason,In this case as your are declaring another window WAM_InputWindow there will be duplication of data. Modules are more for code reusability and they do not save you memory when you create a window and bind to another window. The answer as to whether you want to use a separate module versus make the code as one whole ccl file basically depends on how much data at the max there will be in the window. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP5.1 - Using a Window in CCL modules - memory use?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "20.3", "author": "Jason Kelly", "url": "http://scn.sap.com/thread/3316921", "text": "Hi Vladislav,Thanks for your reply - that's a good suggestion.I've checked the complied XML of the project, and it does look like there are the WAM_InputWindow's defined separately from the WAM_Selection_Window.For example, there's this reference in the \"cudd_module.WAM_InputWindow\" CompliedStream ID:<Window name=\"cudd_module.WAM_InputWindow\" recordType=\"cudd_module.WAM_InputWindow_rec\" result=\"true\" collect=\"true\" coalesce=\"true\" />Hi Geetha,Thanks for your response too. That's not what we were hoping to hear! I was hoping that perhaps there was something in ESP that would just point the module's Window to the contents of the project's Window..A further question for you then, the following page on the Sybase InfoCentre mentions this:http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01611.0510/doc/html/emc1303418584729.html\"To maximize performance, the project server ensures that only one copy of a record can exist.\"and\"However, the project server does count records in the system, to ensure that only one copy of a record exists in different streams\"In our case, the Windows within each of the modules would contain the same data (records) that are in the Window defined in the project itself. So, given the above comments, is it still the case that we'd be using twice the memory in our case?Cheers,Jason.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP5.1 - Using a Window in CCL modules - memory use?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "20.4", "author": "Jason Kelly", "url": "http://scn.sap.com/thread/3316921", "text": "Hi Geetha,Just wondering if you've had a chance to consider my question above - Re: the project server ensuring that only one copy of a record can exist?Does this have any impact on the amount of memory used in situations such as the one I described above (i.e. how we are essentially storing the same records across more than 1 window, by using these code modules).Thanks again,Jason.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP5.1 - Using a Window in CCL modules - memory use?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "20.5", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3316921", "text": "Hi Jason,This is the small check I did which is very similar to the projects you haveIMPORT 'module1.ccl';create input WINDOW W1 schema(symbol string,volume integer,price float)primary key(symbol);LOAD MODULE Module1 AS Module1_instance_01  IN module_window_input = W1 OUT module_window_output = out1;  create output window W2 schema(symbol string,max_volume integer) primary key(symbol) as select * from out1;module1.ccl==========CREATE MODULE Module1IN module_window_inputOUT module_window_outputBEGINCREATE INPUT WINDOW module_window_input SCHEMA (symbol string,volume integer,price float)PRIMARY KEY(symbol);CREATE OUTPUT WINDOW module_window_output SCHEMA(symbol string,max_volume integer)PRIMARY KEY (symbol)asselect S1.symbol as symbol,S1.volume+100 as max_volumefrom module_window_input S1 ; END;I inserted 3 rows and when I stop the project with debug level 7 I can get a dump of memory usage and I see 2013-03-13 07:39:36.907 | 7084 | container | [SP-6-131040] (49.223) sp(8072) CompiledSourceStream(W1): Memory usage: 469 bytes in 3 records.2013-03-13 07:39:36.907 | 7084 | container | [SP-6-114012] (49.223) sp(8072) Platform(localhost)::run() -- cleaning up CompiledStream(Module1_instance_01.module_window_output).2013-03-13 07:39:36.907 | 7084 | container | [SP-6-131039] (49.223) sp(8072) CompiledStream(Module1_instance_01.module_window_output): Collecting statistics (this could take awhile).2013-03-13 07:39:36.907 | 7084 | container | [SP-6-131040] (49.223) sp(8072) CompiledStream(Module1_instance_01.module_window_output): Memory usage: 433 bytes in 3 records.2013-03-13 07:39:36.907 | 7084 | container | [SP-6-114012] (49.223) sp(8072) Platform(localhost)::run() -- cleaning up CompiledStream(Module1_instance_01.module_window_input).2013-03-13 07:39:36.907 | 7084 | container | [SP-6-131039] (49.223) sp(8072) CompiledStream(Module1_instance_01.module_window_input): Collecting statistics (this could take awhile).2013-03-13 07:39:36.907 | 7084 | container | [SP-6-131040] (49.223) sp(8072) CompiledStream(Module1_instance_01.module_window_input): Memory usage: 469 bytes in 3 records.2013-03-13 07:39:36.907 | 7084 | container | [SP-6-114012] (49.223) sp(8072) Platform(localhost)::run() -- cleaning up CompiledStream(W2).2013-03-13 07:39:36.907 | 7084 | container | [SP-6-131039] (49.223) sp(8072) CompiledStream(W2): Collecting statistics (this could take awhile).2013-03-13 07:39:36.907 | 7084 | container | [SP-6-131040] (49.223) sp(8072) CompiledStream(W2): Memory usage: 433 bytes in 3 records.Which tells me that all four windows occupy memory. As per http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01612.0511/doc/html/doa1343226200181.html the amount of memory consumed by every stream is reported in the memory usage statistics. There may be internal reference counts as the document points out but I do not know the details on where the reference count is done whether when data passes through a stream/local stream(not window) or when it is used in splash stream I am not sure on where reference count is done.  May be you can open a support case for this and we can talk with engineering and get you more specific details. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP5.1 - Using a Window in CCL modules - memory use?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "20.6", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3316921", "text": "I just checked with engineering and learned that the input window(s) in the module need to maintain their own index, and thus they consume memory, but they don't maintain copies of the records. So while the use of modules within input windows will increase memory use, it's not as bad as keeping multiple copies of the events.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP5.1 - Using a Window in CCL modules - memory use?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-19 07:41:00", "resolve": false, "uid": "21", "title": "Best way of creating a Sybase-Android Native application", "url": "http://scn.sap.com/thread/3329000", "text": "Hi,I have developed a native PO Approval application for Android using SUP 2.1.3. When I synchronize the application it takes hell lot of time to complete the action. So can any one tell me the important steps when creating such applications to improve the performance?Thank You.", "views": "305", "answers": 1, "author": "Anu G", "upvotes": 0, "type": "question", "tags": "native_applications.sybase_support"},
{"date_time": "2013-03-19 13:54:00", "resolve": "", "uid": "21.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3329000", "text": "Hi Anu,I think that you need to bring your question to a different community, namely, to the Mobility Platform community: http://scn.sap.com/community/developer-center/mobility-platformThank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best way of creating a Sybase-Android Native application", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-19 07:39:00", "resolve": false, "uid": "22", "title": "Best way of creating a Sybase-Android Native application", "url": "http://scn.sap.com/thread/3328999", "text": "Hi,I have developed a native PO Approval application for Android using SUP 2.1.3. When I synchronize the application it takes hell lot of time to complete the action. So can any one tell me the important steps when creating such applications to improve the performance?Thank You.", "views": "255", "answers": 1, "author": "Anu G", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-19 19:04:00", "resolve": "", "uid": "22.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3328999", "text": "I believe you want to post this question in the SUP community; this does not appear to be an ESP question", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best way of creating a Sybase-Android Native application", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-07 11:12:00", "resolve": false, "uid": "23", "title": "Error in running the projects from ESP Studio", "url": "http://scn.sap.com/thread/3321059", "text": "Hi,Today when I tried running my projects from ESP studio, I got the following error:The Cluster has encountered a project error:Check the Cluster policies for this project.Cluster error message:Invalid action:[FAILURE: Application wait for status is started, but application current status is not started]Interesting point is that all the projects were running until yesterday, and I did not change anything today!Can someone help me out?Thanks,Rahim", "views": "1008", "answers": 4, "author": "Rahim Makhani", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-07 15:02:00", "resolve": "", "uid": "23.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3321059", "text": "Hi Rahim,No need to post in both ESP communities, rest assured we will respond to your question.I see you are an SAP employee. SAP has been changing our Windows domains. This change in conjunction with some stricter security policies on the following files will cause the error:* All of the files in %ESP_HOME%\\security* %ESP_HOME%\\bin\\service.xml* %ESP_HOME%\\cluster\\nodes\\node1\\node1.xml* %ESP_HOME%\\lib\\adapters\\*.cnxmlBasically, you will have to change the ownership of the folders and files to your new SAP domain ID and also grant full permission to these files to this same ID.We have posted a step-by-step document in the internal ESP community which I will forward to you offline.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error in running the projects from ESP Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "23.2", "author": "Stefan Dimov", "url": "http://scn.sap.com/thread/3321059", "text": "Hi Neal,I have the same problem. Can you please send me the document?Regards,S.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error in running the projects from ESP Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "23.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3321059", "text": "Hello,In this particular instance, the ESP license had expired so Studio was unable to start the cluster.If you try to run a project in Studio's local cluster and you get the folloing error:Invalid action:[FAILURE: Application wait for status is started, but application current status is not started]The first thing I would recommend to check is the \"stdstreams.log\" file to see if the license has expired.1) Edit Studio's \"localnode.xml\" file (located in %ESP_HOME%\\studio\\clustercfg).2) Refer to the \"base-directory\" property. This is the directory where Studio will save projects and log files. For example:<Property name=\"base-directory\">C:\\Users\\jsmith\\My Documents\\SybaseESP\\5.1\\workspace</Property>3) Look in the directory of the format <workspace_name>.<project_name>.<instance>. For example \"default.my_first_project.0\" and you should see the \"stdstreams.log\" file which will tell you if there are license issues.If there are no license related errors in \"stdstreams.log\" check the \"esp_server.log\" in the same directory for further information about why the project was unable to start.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Error in running the projects from ESP Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "23.4", "author": "Stefan Dimov", "url": "http://scn.sap.com/thread/3321059", "text": "Thanks for the help, Neal !", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error in running the projects from ESP Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-04 21:57:00", "resolve": false, "uid": "24", "title": "Database migration using Sybase ESP 5.1", "url": "http://scn.sap.com/thread/3318928", "text": "I would like to know if it is possible to migrate a database using the Sybase ESP 5.1, I meancopy the tables from a schema to an empty one.Could anyone help me with this question?", "views": "642", "answers": 6, "author": "Camila Alves", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-03-04 22:00:00", "resolve": "", "uid": "24.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3318928", "text": "Hello,I don't really understand your question. Some adapters have a discovery button (look for a little magnifying glass on the adapter when in Visual Authoring mode). You can discover the schema from the database and save it to a new schema, stream or window.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.2", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3318928", "text": "Hi Camila,See here you can use the powerdesigner extension for ESP http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01616.0511/doc/html/wso1334867430966.htmlThanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.3", "author": "Camila Alves", "url": "http://scn.sap.com/thread/3318928", "text": "Ok, I will ask in another way: the problem is that I should migrate a database schema composed of 200 tables. Should I use the discovery schema tool 200 times? Or it's possible to discover everything at once?Sorry for the stupid question, I am just starting on ESP.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.4", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3318928", "text": "Hello,Did you explore the PowerDesigner extension that Geetha suggested?What database are your trying to model?Can you describe what the big picture looks like for your project? Do you want to use ESP to update 200 database tables in a single project (this would raise some red flags with me)?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.5", "author": "Camila Alves", "url": "http://scn.sap.com/thread/3318928", "text": "That's the point Neal. The PowerDesigner extension doesn't work to me.What I'am supposed to do at this moment is to migrate data from a database to another, for example, from Oracle to Sybase. The problem is that, acording to the documentation, using ESP studio, I needto create a different schema for each table, what is totally impossible to me, due to the number of tables (200, at least). Is there any way to turn the schema discovery dynamic? Using the ESP SDK, for example?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3318928", "text": "Hi Camila,The ESP discovery tool is only able to get the schema of one table at a time. The PowerDesigner product is designed more with the intention of managing and reverse engineering database schemas.I have seen other users write SQL stored procedures that query a given database's system tables and write out the \"CREATE SCHEMA\" CCL language. I have a set of stored procedures that were created to read the Sybase IQ system tables and generate CCL. I have been given permission to send this to you if you are interested, just let me know.Others have used various database's DDL schema export tools (like DDLGEN.EXE for Sybase ASE) to export the \"CREATE TABLE\" SQL to a file and then used an editor's global search and replace to alter the syntax and the columns to match the available data types in ESP.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.7", "author": "Camila Alves", "url": "http://scn.sap.com/thread/3318928", "text": "Hi Neal,I would appreciate it if you sent me the stored procedures.Thank you very much!Camila.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.8", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3318928", "text": "Hi Camila,My 2 cents here ESP is a CEP engine and should not used for database migration purposes. It is not a ETL tool.Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.9", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3318928", "text": "Hi Camila,You will need to email me (neal . stack @ sap . com <- Just remove the spaces) so I can send them to you. The SAP Community doesn't allow me to attach large zip files.They are very custom to Sybase IQ and won't work for Oracle but may give you some ideas.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "24.10", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3318928", "text": "Hello,I don't know if you have seen the Oracle to Sybase ASE Migration Guide or not: http://www.sybase.com/files/White_Papers/ASE-Oracle-Migration-Guide-wp.pdfSection 4 talks about database schema migration.Section 6 talks about moving the data.While I think you could use ESP to help migrate data from Oracle to ASE, it might not be the best choice. As Geetha suggests, an ETL tool would probably make the job easier.You will have to consider the data types that map from Oracle to ESP to ASE. For example Oracle TIMESTAMP supports a much higher granularity than either ESP or ASE.ESP supports small binary columns (Maximum length of value is platform-dependent, but can be no more than 65535 bytes.) so if your source database contains large binary columns, you will need to use another tool.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Database migration using Sybase ESP 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2013-02-26 10:40:00", "resolve": false, "uid": "25", "title": "error when connect to localhost server", "url": "http://scn.sap.com/thread/3314426", "text": "Hi all,After upgrade ESP 5.1 to ESP 5.1 SP01, i can not connect to the localhost server. The error message is:'Failed to connect to server \"esp://localhost:9786\". Reason :\"Failed to login server\"'. Anyone have experience to solve this problem? Thank you for your help!Regards,Jacky", "views": "683", "answers": 7, "author": "Jacky Gui", "upvotes": 1, "type": "question", "tags": ""},
{"date_time": "2013-02-26 19:45:00", "resolve": "", "uid": "25.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3314426", "text": "Hi Jacky,Are you trying to connect to the localhost server from a different PC (or a remote server)? If so, this is impossible. You will need to edit the %ESP_HOME%\\studio\\clustercfg\\localnode.xml file and change the ESP_HOSTNAME configuration parameter to the PC's (or server's) actual host name (or IP address) so that it is known to remote machines.If you are just trying to do this locally on your PC, were you able to start your project?Did you make a backup copy of the files described in the ESP 5.1 SP01 Cover Letter and then restore them after the upgrade?With Studio's default cluster configuration, look for log files in this directory: %USERPROFILE%\\Documents\\SybaseESP\\5.1\\workspace\\<workspace_name>.<project_name>.<project_instance>For example:%USERPROFILE%\\Documents\\SybaseESP\\5.1\\workspace\\default.project1.0There are two log files. \"stdstreams.log\" will tell us if there is a license issue (maybe your license has expired). \"esp_server.log\" will tell us if there are any errors in the project itself.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:error when connect to localhost server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "25.2", "author": "Jacky Gui", "url": "http://scn.sap.com/thread/3314426", "text": "Hi Neal,Thank you for your great help! I did this test on my local PC with WIN7 64bit OS. I have update from 5.1 to 5.1 SP01 according to the install guide and backed up the specified files and restored them after the upgrade.In the %USERPROFILE%\\Documents\\SybaseESP\\5.1\\workspace\\ path, i can not see any log files named \"stdstreams.log\" and \"esp_server.log\".when i run project a error occured like below:", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:error when connect to localhost server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "25.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3314426", "text": "Hello,I finally reproduced your error. I suppose there are other reasons as to why this error is raised but in my case it was raised because of this:* Studio reports this error when connecting to a server and there is an SSL mismatch. Either SSL has been enabled in the server and Studio's connection definition for the server does not use SSL or vice-versa.So in addition to my above questions, check your %ESP_HOME%\\studio\\clustercfg\\localnode.xml file and see if you have ssl=\"true\" in it. If so, your connection in Studio should have the SSL box checked.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:error when connect to localhost server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "25.4", "author": "Jacky Gui", "url": "http://scn.sap.com/thread/3314426", "text": "Hi Neal,In %ESP_HOME%\\studio\\clustercfg\\localnode.xml file. thereis no property named 'ssl'. So how should i add this property in my XML file, thank you!Regards,Jacky", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:error when connect to localhost server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "25.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3314426", "text": "Hi Jacky,Based on your screen shot your ESP URL is \"esp://localhost:9786\" which is not SSL and therefore matches your localnode.xml. You do not need to change this.It appears that you are an SAP employee. SAP employees have been experiencing a problem with ESP caused by a change to our user IDs by SAP IT. SAP IT changed our user IDs from one domain to another and this created some file ownership problems. In particular, you may see that you no longer have permission to read any of the files in the %ESP_HOME%\\security folder and the %ESP_HOME%\\bin\\service.xml file.I'll check with a colleague and see if we have a writeup on the problem.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:error when connect to localhost server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "25.6", "author": "Ruediger Fritz", "url": "http://scn.sap.com/thread/3314426", "text": "Hi Neal,any update on this issue? I am struggling with the same issue just after having done the same upgrade to SP01 tonight.Or any idea for a workaround?Thanks a ton for your help and kind regards,Ruediger", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:error when connect to localhost server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "25.7", "author": "Ruediger Fritz", "url": "http://scn.sap.com/thread/3314426", "text": "Hello Jacky and Nealthanks a million for pointing me to https://community.wdf.sap.corp/sbs/message/384028#384028 .I did not think abaout scanning our internal sources after having found this thread.Now I can proceed.Thanks again and very best regards,Ruediger", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:error when connect to localhost server", "type": "answer", "tags": "N/A"},
{"date_time": "2013-03-31 11:32:00", "resolve": false, "uid": "26", "title": "Does Sybase ESP support BO Dashboards", "url": "http://scn.sap.com/thread/3335641", "text": "I am just new in ESP world, Does Sybase ESP support BO Dashboards and read from SAP HANA database for pattern detection?Thanks in advanceKhaled Idriss", "views": "409", "answers": 1, "author": "Khaled Idriss", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-04-02 19:37:00", "resolve": "", "uid": "26.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3335641", "text": "We are working on a sample plug-in for BO Dashboards that will connect to ESP - but it's not available yet. Should be soon - I'll try to get an update on the schedule. As for ability of ESP to read data from HANA: that's in place today as a standard ESP feature. Note, however, that ESP pattern detection is normally used to look for patterns in real-time event streams. While it could be used to look for patterns in databases, there are some limitations (you won't be able to use the MATCHING feature of CCL) and in some cases you may be better off just running a SQL query against the DB.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Does Sybase ESP support BO Dashboards", "type": "answer", "tags": "N/A"},
{"date_time": "2013-04-02 06:47:00", "resolve": false, "uid": "27", "title": "CCL Module use for different schemas", "url": "http://scn.sap.com/thread/3336347", "text": "Hi,I have a module which contains an input stream, and an output window. I would like to use the module with several other projects, however the problem I am facing is how can the input stream and output window created in the module use the same schema that is defined in the project?The schema has been created within a separate CCL file, and imported into both the project and module. One solution that I have tried was creating a parameter that allows the project to pass the name of the schema into the module. The name would then be used to define the schema in the modules input stream.  i.e. CREATE INPUT STREAM InputStream SCHEMA SchemaName;This solution does not compile and returns the error Schema SchemaName does not exist.Basically, we are after the ability to create the one module that can be used in multiple projects, where the schema of the incoming & outgoing events is different in every project. The module is not checking any of the event parameters, so we dont require the ability to access the actual event data.Any suggestions as to how we can achieve this?Thanks very much,Jason Kelly (DHS Australia).", "views": "392", "answers": 2, "author": "Jason Kelly", "upvotes": 0, "type": "question", "tags": "sybase.module.module_programming.esp.esp_5.1"},
{"date_time": "2013-04-02 15:15:00", "resolve": "", "uid": "27.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3336347", "text": "Jason - I'm afraid I don't know of a way of doing this. I'd be interested to learn more about your use case, however. Support for modules with some sort of assignable schema is something that has been discussed, but one design question is how to handle individual fields in the module, if the module designer doesn't know what they are. Do you just pass them through? What if the module includes an aggregation? etc. You say the module doesn't acess the actual event data: I'd love to see an example of that (feel free to send via email if that's more appropriate).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:CCL Module use for different schemas", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "27.2", "author": "Jason Kelly", "url": "http://scn.sap.com/thread/3336347", "text": "Hi Jeff,Thanks for getting back to me.Basically, we are thinking of doing something very similar to your How to get pulsed output from ESP example that you posted on the blog. We essentially want to delay the processing of certain event types by a fixed amount of time.We were thinking of using a FLEX operator in a very similar manner to what you did in that pulsed output example. Except, wed use a DICTIONARY instead of a VECTOR as the cache & wed store the date-timestamp of when the event is inserted into the DICTIONARY along with the event itself.Then wed use an EVERY xx SECONDS clause to check if any events that are currently in the DICTIONARY were inserted more than 30 seconds ago (simple date-timestamp arithmetic to achieve this). If so, output the record & remove it from the dictionary, otherwise keep it in the dictionary.We were wanting to delay the processing of many different types of events (approx 150 different types) in exactly this way. Each event type has a different schema, but we were hoping that wed be able to have just the one CCL module that would be able to handle this (so that if we wanted to change the amount of delay, for instance, we would only need to make the code change in one spot & recompile the projects). This is why we dont need to actually interrogate the contents/payload of the event itself within the module. However, we do require to pass the event payload onto some downstream processing, so we can't throw it away altogether!Perhaps we just have to use separate CCL for each event type?Can send you an example via email if that helps to explain it more.Cheers, Jason.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:CCL Module use for different schemas", "type": "answer", "tags": "N/A"},
{"date_time": "2013-04-22 11:49:00", "resolve": true, "uid": "28", "title": "How to do column mapping within ESP Studio 5.1SP01?", "url": "http://scn.sap.com/thread/3347244", "text": "Dear SAP Sybase ESP community,I am pretty much new to ESP and try to solve the following use case: I have records within table A of database A. Certain values of those records (and the ones that are coming up in the future) need to be stored within table B of database B. I successfully created the input and output adapters within ESP Studio. I also understood that I can use the \"compute\" shape to build the sub-set of columns of table A. The key issue I have right now is that the target table B has a different naming of the columns and sometimes a different data type format (e.g. timestamp). I have seen that on the output adapter advanced properties view, a \"field mapping\" can be spcified. Is the only way or can I do the mapping already within or before the output stream to which the output adapter is connected to?Therefore, I need to solve the 2 problems: (1) How do I model that the column \"mapping\" within ESP Studio? I want to express that the value of column 1 of table A should be stored into column X of table B. (2) How do I write an user defined function that transforms a string into the right timestamp format of the HANA database, which is my target database B - ideally in JAVA?I would be really great if someone can provide me some best practise, help, hints, .. I really would like to use the ESP Studio with the visual authoring perspective and no manual XML coding. Is this possible?Thanks so much for your help.Markus", "views": "549", "answers": 4, "author": "Markus Richter", "upvotes": 0, "type": "question", "tags": "output.adapter.mapping.esp.datatype"},
{"date_time": "2013-04-22 19:45:00", "resolve": "", "uid": "28.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3347244", "text": "Hi Markus,You can use field mapping as you have already found out or you can modify the output stream columns to match table B and make sure the column expressions in the stream match with the values. Here is the CCL code  CREATE INPUT STREAM S1 SCHEMA (symbol string,time string, volume integer,price float);create output stream S2 SCHEMA(ss_symbol string, tt_time timestamp,ss_volume integer, ss_price float)asselectS1.symbol as ss_symbol,to_timestamp(S1.time,'MM/DD/YYYY HH:MI TZH:TZM') as tt_time,S1.volume as ss_volume,S1.price as ss_pricefrom S1;The output stream column names can be made to match the HANA table and you can move the data from one column to another. If you save this CCL and view it in the visual mode and you will understand how to use this in visual mode.Converting a string to timestamp can be easily performed using in built function there is no need for a UDF here. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to do column mapping within ESP Studio 5.1SP01?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "28.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3347244", "text": "You can set up transformations - and define column mappings, very easily within the Studio, using either the visual editor or CCL. You can use any of the built in functions, including the date/time functions to get the incoming data into the output format you need. One word of caution, however: ESP is a tool designed to operate on streams of live data. It's generally not the right tool to be using for ETL tasks where you are better off using Data Services. But with that said, doing the transformations is relatively simple.Here's a simple example:Here's the CCL:CREATE INPUT STREAM InputStream1  SCHEMA ( Column1 integer , Column2 string , Column3 timestamp , Column4 string ) ;/**@SIMPLEQUERY=COMPUTE*/CREATE OUTPUT STREAM OutputStream1  AS  SELECT  cast ( float , InputStream1.Column1 ) TargCol1 ,  InputStream1.Column2 TargCol2 ,  InputStream1.Column3 TargCol3 ,  to_timestamp ( InputStream1.Column4 , '%m/%d/%Y %H:%M' ) TargCol4 ,  left ( InputStream1.Column2 , 15 ) TargCol5 FROM  InputStream1 ;ATTACH INPUT ADAPTER InFromDB TYPE db_in TO InputStream1 PROPERTIES service = 'SQAESPdemos' ;ATTACH OUTPUT ADAPTER Out2Hana TYPE hana_out TO OutputStream1 PROPERTIES service = 'hanaservice' ;", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to do column mapping within ESP Studio 5.1SP01?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "28.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3347244", "text": "Hello Markus,You don't need to use a \"compute\" shape for this. And you don't need to write any Java functions, you should be able to use any of our built-in functions for this conversion.You can formulate your \"SELECT\" statement from an INPUT window/stream that matches your OUTPUT window (which may have a different schema that matches your target table in HANA).I hit the \"F4\" key to toggle to text authoring mode because it is easier to illustrate:CREATE INPUT Stream SourceStream1 SCHEMA (Column1 integer , Column2 integer , Column3 integer , Column4 string );CREATE OUTPUT STREAM OutStream1 SCHEMA ( C1 integer , C2 integer , C3 integer , C4 string , C5 bigdatetime ) AS SELECT SW.Column1, SW.Column2, SW.Column3, SW.Column4, to_bigdatetime(SW.Column4, '%m/%d/%Y %H:%M') as C5 FROM SourceStream1 SW;Another option is to use the \"Field Mapping\" (shows as the \"permutation\" property in CCL): http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01615.0511/doc/html/cgo1347651414221.htmlCREATE INPUT WINDOW INWINDOW1SCHEMA ( TRADE_ID LONG, LANGUAGE_STR STRING)PRIMARY KEY (TRADE_ID);ATTACH OUTPUT ADAPTER Adapter2 TYPE hana_out TO INWINDOW1PROPERTIESservice = 'HANAODBCService',table ='SYSTEM.TEST_TABLE1',permutation='TRADE_ID=TRADE_ID:LANGUAGE_STR=LANGUAGE',bulkBatchSize=10000,bulkInsertArraySize=1000,idleBufferWriteDelayMSec=1000,bufferAgeLimitMSec=10000,dataWarehouseMode='OFF',timestampColumnName='',onlyBase=false,outputBase=false,threadCount=0;You may need to use the permutation technique especially if your HANA table uses ESP reserved words: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01621.0511/doc/h tml/emc1301424073282.html I'm attaching a screen shot showing how to do the filed mapping in Studio.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to do column mapping within ESP Studio 5.1SP01?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "28.4", "author": "Markus Richter", "url": "http://scn.sap.com/thread/3347244", "text": "Hi All,thanks so much for the valuable information! It really helped me to solve my problem and get an understanding of certain aspects within the visual modeling perspective ;-)I know that the scenario might look like ETL, but I just described a subset of what shall be realized with ESP.Thanks again!Markus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to do column mapping within ESP Studio 5.1SP01?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-04-24 14:06:00", "resolve": false, "uid": "29", "title": "Assign fixed values to a field", "url": "http://scn.sap.com/thread/3348522", "text": "Hi,in my example I am using a \"compute\" shape where I have attached an input adapter to take over some fields. However, I also want to add one more field and assign it with a fixed value. But my current approach causes an compile error. What am I doing wrong? Here my current CCL extract: /**@SIMPLEQUERY=COMPUTE*/CREATE LOCAL STREAM StopLog AS SELECT to_string ( \"completed\" ) EVENT_NAME , InputStream.CASE_ID CASE_ID,InputStream.END_DATE \"DATE\" FROM InputStream ;Is it in general possible to assign fixed values to fields e.g. with the built-in function \"to_string(string)\"? Is is possible to add further fields that are not derived from an input stream, but will be used later on for the output adapter?Thanks and Best Regards.Markus", "views": "310", "answers": 2, "author": "Markus Richter", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-04-24 15:30:00", "resolve": "", "uid": "29.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3348522", "text": "You can absolutely do this. You don't need to use the to_string function; the key is single quotes. For a numeric value, just type in the number for a constant.CREATE LOCAL STREAM StopLog AS SELECT  'completed' EVENT_NAME ,  InputStream.CASE_ID CASE_ID, InputStream.END_DATE \"DATE\" FROM  InputStream ;", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Assign fixed values to a field", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "29.2", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3348522", "text": "Looking throught the ESP docs, it seems that there is a gap in that it could use better description of literals available in CCL. We will get this gap addressed.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Assign fixed values to a field", "type": "answer", "tags": "N/A"},
{"date_time": "2013-04-26 16:31:00", "resolve": true, "uid": "30", "title": "Best Practise for own functions", "url": "http://scn.sap.com/thread/3349912", "text": "Hi,I need to write my own function that converts a timestamp into the right format that is supported by HANA or is of right format of built-in functions. In an earlier discussion, the usage of built-in function like \"to_bigdatetime('02/19/2010 10:15', '%m/%d/%Y %H:%M') returns 2010-02-19 10:15:00.000000\" has been recommended. But in my case this does not work. I have log entries that are of format \"9.3.10 8:05\". The issue is that some dates and months are of single digit, which causes the problem to use the built-in function. I double checked the supported date/time formats as documented within the CCL Programmers Guide. Hence, I have to write my own function ;-( I have done this already in JAVA. Can I somehow re-use this?Ideally I would write this function and make it also available in other projects.Thanks for your help.Markus", "views": "522", "answers": 8, "author": "Markus Richter", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-04-26 17:06:00", "resolve": "", "uid": "30.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3349912", "text": "Hello,What you have described is what we call a User Defined Function or UDF. The instructions on how to do this are located here: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01621.0511/doc/html/skh1299785153401.htmlOne thing to note is that the documentation states that you can tell ESP the location of the JAR or class file by \"If running outside of Studio, set the Java-classpath option in the project configuration file.\". This in fact does not work, if you use the \"java-classpath\" option in the CCR file, ESP won't find the file.I have found that you need to either:a) Set your CLASSPATH to the location of the file prior to starting ESP.orb) Copy the file to your $ESP_HOME/libj directory. If you choose this option, you have to be careful because everytime you upgrade or reinstall ESP, the installer attempts to uninstall the product first. Typically the uninstaller does not remove files that it did not place there but you never know.Thanks, NealThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practise for own functions", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "30.2", "author": "Markus Richter", "url": "http://scn.sap.com/thread/3349912", "text": "Hi Neal,I still struggling with the user-defined functions in JAVA.First I had some trouble with the declaration of the function.There seems to be some confusion within the documentation on how to declare a library. I found the following example: CREATE LIBRARY DistanceLib LANGUAGE JAVA FROM 'Distance' (double distance(double arg1, double arg2, double arg3);); This causes a compile error. Looking into the \"CREATE LIBRARY\" description, it shows the following example:CREATE LIBRARY SC1 LANGUAGE java FROM 'Functions' ( integer intdiffj(integer, integer); string stringaddj (string, string); ); OK, using the latter version works for compiling. However, while executing the project I am getting an internal \"class not found\" error ( An internal error has occurred. Program::assemble() in section '$#Global/' library 'TimestampConversionJava' function 'TimestampConversionJava.convertHanaTimestamp' : Could not find class hana.db.TimestampConversion;). I followed your advice to copy my JAR file into $ESP_HOME/libj and ESP console output shows me that it does found the JAR file. Do I need to do any other steps? The documentation is not clear on that point. Here a summary of what I did:1. Write JAVA file2. Compile, create and store the JAR file into $ESP_HOME/libj3. Start ESP4. Put the \"CREATE LIBRARY\" statement into my CCL project -> CREATE LIBRARY TimestampConversionJava LANGUAGE JAVA FROM 'TimestampConversion' (long convertHanaTimestamp (string););5. Call my JAVA function like to_bigdatetime (TimestampConversionJava.convertHanaTimestamp(Union1.\"DATE\"))6. Compiled my project successfully7. Run the project, which gives me the above described runtime error.Any hints to figure out what am I doing wrong? I am using ESP on a Windows machine.Thanks and Best Regards.Markus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practise for own functions", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "30.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3349912", "text": "Hello,I'll search to see if there are some known documentation bugs for the Java UDFs. ESP 5.1 SP02 is about to be released and I will see if corrections have been added to those documents as well.Are you compiling with JDK 1.6 or 1.7? ESP normally requires JDK 1.7: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01620.0510/doc/html/lar1345237560759.htmlBut if you require JDK 1.6, you should be able to set the \"ESP_JAVA_HOME\" environment variable prior to starting your ESP cluster. For example: ESP_JAVA_HOME=/user/bin/java_1_6/jre/lib/libjvm.so Is your ESP installation 32bit or 64bit? There is a separate JDK for Windows x86 and x64 and it should match the bitness of your ESP installation.Thanks, NealMessage was edited by: Neal Stack", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practise for own functions", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "30.4", "author": "Markus Richter", "url": "http://scn.sap.com/thread/3349912", "text": "Hi Neil,I double checked my JAVA class file. It was compiled with JDK1.7.21 and Windows64bit - same as my ESP installation. From that perspective, it should be ok. The full output while running my project is:2013-04-29 16:16:55.522 | 8976 | container | [SP-3-160000] (0.440) sp(8480) An internal error has occurred. Program::assemble() in section '$#Global/' library 'TimestampConversionJAVA' function 'TimestampConversionJAVA.convertHanaTimestamp' : Could not find TimestampConversion.convertHanaTimestamp..2013-04-29 16:16:55.523 | 8976 | container | [SP-3-156016] (0.441) sp(8480) An internal error has occurred. In section '$~HANA_Outputstream' opcode 'APPLYJAVA' arg1 'TimestampConversionJAVA.convertHanaTimestamp' is not a known library function2013-04-29 16:16:55.525 | 8976 | container | [SP-2-135010] (0.443) sp(8480) Platform::main() -- Configuration file 'esp_server.ccx' is invalid, see the preceding messages for details.Not sure whether this helps to determine the root cause for my error. My assumption is that ESP does not find the jar file.Thanks fro your help.Markus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practise for own functions", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "30.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3349912", "text": "Hello,If the JAR file is in %ESP_HOME%\\libj and the server was properly restarted, I would expect it to be found. There can be other reasons for the JAR file not to be loaded like the ones I pointed out.Can you email me your Java program's source code or attach it to this thread or open a technical support case?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practise for own functions", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "30.6", "author": "Markus Richter", "url": "http://scn.sap.com/thread/3349912", "text": "Hi,sure. I attached the source file and the jar to this thread. Please remove the *.txt extension of the attached files, as .java and .jar files could not be directly attached.Thanks and Best Regards.Markus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practise for own functions", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "30.7", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3349912", "text": "Hi Markus,I have filed a documentation bug to have the Java User Defined Function section worked on:738521 - ESP Java User Defined Function ( UDF ) documentation has several mistakesTry declaring your function as \"static\" as follows: public static long convertHanaTimestamp(String value)This worked for me. There is a complete example which illustrates this better than the documentation in %ESP_HOME%\\examples\\ccl\\CreateLibraryThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practise for own functions", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "30.8", "author": "Markus Richter", "url": "http://scn.sap.com/thread/3349912", "text": "Hi Neal,thanks so much for your help ;-) I really appreciate it! Declarig the function as \"static\" was the solution and it works now also for me. Thanks so much!Markus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practise for own functions", "type": "answer", "tags": "N/A"},
{"date_time": "2013-04-29 21:20:00", "resolve": false, "uid": "31", "title": "Problem with SAP_RFC_input adapter", "url": "http://scn.sap.com/thread/3351114", "text": "Hi All,i need to connect my ESP studio to SAP ERP through SAP_RFC_Input adapter.I created adapter's configuration and mapping files but ESP could not establish connection with SAP system.Schema discovery also is not working.SAP_RFC_Input adapter always has status DEAD and at the same time Generic_DB_Input adapter is working fine.May be anybody met similar problem with SAP_RFC_input adapter?Best regards,Igor", "views": "376", "answers": 1, "author": "Igor Evstratov", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-05-03 19:04:00", "resolve": "", "uid": "31.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3351114", "text": "Hello,I logged the following documentation change request for this issue: 738878 - Move adapter configuration information from Install Guide to Adapters GuideI'm including the instructions here in case others need them for quick reference:1.) Point your browser to https://websmp101.sap-ag.de/~form/sapnet?_SHORTKEY=01100035870000719293 SMP displays the RFC Library home page.2.) In the pane on the left, expand SAP Java Connector > Tools & Services. SMP displays the SAP Java Connector Download page.3.) Under Quick Links, click on Download SAP JCo Release 3.0.4.) Scroll down to the operating system you are running and select the zip file for the type of processors in your system.5.) Select or create a folder, and extract the zip file to it.6.) Navigate to that folder, and copy the sapjco3.jar file to $ESP_HOME/adapters/rfc/libj.7.) Then copy the sapjco3.jar file to $ESP_HOME/studio/plugins/com.sybase.cep.studio.libs_5.1.0.v(date).8.) From that same folder, copy the libsapjco3.so file to $ESP_HOME/adapters/rfc/lib.9.) Follow the installation instructions included with SAP JCo.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with SAP_RFC_input adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2013-05-14 23:12:00", "resolve": false, "uid": "32", "title": "Unable to insert into varbinary and image columns using ESP", "url": "http://scn.sap.com/thread/3358767", "text": "I have been trying to insert into Sybase ASE tables that have columns of varbinary and image types using the Sybase ASE Output Adapter from ESP,but it doesn't work. When doing this, an error message is shown, which says that these types column types are not supported. However, the Generic DB Input Adapter can retrieve the data and send it to a Window. Could anyone help me to solve this problem?", "views": "873", "answers": 5, "author": "Camila Alves", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-05-15 20:01:00", "resolve": "", "uid": "32.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3358767", "text": "Hello,It appears that you have created two technical support cases related to this issue. Please provide the information being requested in the support cases so that they can work on your question.The Sybase ASE Output Adapter does not support \"text\" or \"image\" columns: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01615.0512/doc/html/cgo1333570667599.htmlThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unable to insert into varbinary and image columns using ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "32.2", "author": "Camila Alves", "url": "http://scn.sap.com/thread/3358767", "text": "Thanks for your answer Neal. But what could I do in order to insert into ASE 'varbinary' and 'image' columns using ESP? Which output adapter should I use?Camila.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unable to insert into varbinary and image columns using ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "32.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3358767", "text": "Hi Camila,Please provide the answers we asked in the technical support cases. This topic is too complex to address via back and forth through the newsgroups.As I said, \" image\" is not supported. So if you could directly answer the questions we posed in your technical support cases we would have a better understanding of the problem and could better advise you.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unable to insert into varbinary and image columns using ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "32.4", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3358767", "text": "Hello Camila,Just to let you know, I was able to insert varbinary data into ASE using the Generic DB Input Adapter. However, due to the following bug, a maximum of 254 characters can be inserted:738784 - Database Input Adapter doesn't set the ColumnSize parameter for SQLBindParameterThe Database Input Adapter does not set the ColumnSize parameter for the ODBC SQLBindParameter API. This can cause various issues such as:* Getting invalid precision error when inserting to MSSQL.* String or binary data greater than 254 characters being truncated when inserting to other databases such as Sybase ASE or Oracle.Currently, this issue has a very low priority with engineering. If this issue is important to you, I would recommend you open a support case so we can associate the bug with your case. Bugs that are associated with cases get a higher priority and are addressed much quicker than those without a technical support case.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unable to insert into varbinary and image columns using ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "32.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3358767", "text": "Hello Camila,I did some further experimentation today and produced a matrix of which adapters support binary data:imagevarbinary(1000)Generic DB InputSupportedSupportedGeneric DB OutputTruncated (CR 738784)Truncated (CR 738784)ASE OutputNot SupportedSupportedHere is the SQL for the tables I created (NOTE: I just altered the \"pic\" column from varbinary(1000) to image for these tests):create table au_pix2 (au_id varchar(1000) not null ,pic varbinary(1000) null ,format_type char(11) null ,bytesize int null ,pixwidth_hor char(14) null ,pixwidth_vert char(14) null )create table au_pix (au_id varchar(1000) not null ,pic varbinary(1000) null ,format_type char(11) null ,bytesize int null ,pixwidth_hor char(14) null ,pixwidth_vert char(14) null )declare @insert varchar(1000)select @insert = '0x'declare @counter intselect @counter = 1while (@counter < 597)begin select @insert = @insert + convert(varchar, @counter) select @counter = @counter + 1endselect datalength(@insert)select convert(binary, @insert)insert into au_pix values ('1', @insert, 'DEF', 600, \"Y\", \"N\")NOTE: I had a small C program to insert some larger JPG files into the \"pic\" column when it was of the type \"image\". Here is the CCL I used to test. I would just uncomment the output adapter I wanted to test:CREATE SCHEMA au_pix_schema ( au_id string , pic binary , format_type string , bytesize integer , pixwidth_hor string , pixwidth_vert string ) ;CREATE INPUT WINDOW au_pix_input_window1 SCHEMA au_pix_schema PRIMARY KEY ( au_id ) ;// Use the length() function to determine the size of the data read in by ESPCREATE OUTPUT WINDOW Window2 SCHEMA au_pix_schema PRIMARY KEY ( au_id ) AS SELECT AW.au_id, AW.pic, AW.format_type, length(AW.pic) as piclength,AW.pixwidth_hor, AW.pixwidth_vert FROM au_pix_input_window1 AW ;ATTACH INPUT ADAPTER Generic_DB_Input1 TYPE db_in TO au_pix_input_window1 PROPERTIES service = 'nstacksunASEODBC' , table = 'au_pix' ;ATTACH OUTPUT ADAPTER Generic_DB_Output1 TYPE db_out TO Window2 PROPERTIES service = 'nstacksunASEODBC' , table = 'au_pix2' ;/*ATTACH OUTPUT ADAPTER Sybase_ASE_Output1 TYPE sybase_ase_out TO Window2 PROPERTIES service = 'nstackOCSService' ,table = 'au_pix2' ,bulkBatchSize = 1 ,bulkInsertArraySize = 1 ,dataWarehouseMode = 'ON' ;*/Here is my \".odbc.ini\" DSN entry (NOTE: I had to use the \"textsize\" configuration parameter to override ASE's default textsize of 32768 bytes):[nstacksun155]Description = Sybase ODBC Data SourceUserID = my_userPassword = my_passwordDriver = /work/nstack/ocs157/DataAccess64/ODBC/lib/libsybdrvodb.soServer = nstack-sunPort = 5055Database = openswitchUseCursor = 0DynamicPrepare = 0Autocommit = 0TextSize = 1000000I hope this helps.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unable to insert into varbinary and image columns using ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2013-05-08 08:54:00", "resolve": false, "uid": "33", "title": "Update opcode rolling back all records in bulk", "url": "http://scn.sap.com/thread/3355190", "text": "Hi,In our project we are reading in events on a stream called PRF_Result_Linkstream then putting them through a flex window and trying to update a record if it is in the window with the code below. Not all records coming in on the stream are in the window though. OUTPUT setOpcode(PRF_Result_Linkstream,update); Unfortunately in seems with the update opcode that if the record is not in the window it forces the roll back of that event plus any events that came in around the same time as the message below shows.2013-05-08 04:47:18.232 | 453 | container | [SP-4-123006] (3366.905) sp(2488) StoreIndex(Master_Window)::put() -- roll back transaction of size 102013-05-08 04:47:18.960 | 453 | container | [SP-4-123002] (3367.633) sp(2488) StoreIndex(Master_Window)::put() bad update, tid=9061We had the same issue with the delete and managed to get around this using the safedelete opcode. Is there something similar for update? (note we do not wish to upsert, if the record is not in the window we would like to ignore it). Is there a way to stop the records being batched up, so they can be treated individually?Thanks very much,Mark Wyatt (DHS Australia).", "views": "488", "answers": 7, "author": "Mark Wyatt", "upvotes": 1, "type": "question", "tags": ""},
{"date_time": "2013-05-15 23:01:00", "resolve": "", "uid": "33.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3355190", "text": "Hi Mark,Here is a way to do it===================================/*Updates coming through this stream */CREATE INPUT STREAM s1 schema (symbol string,volume integer,price float); /*break the batching using a flex stream and a dictionary this will output 1 row at a time */CREATE FLEX flex1 IN s1 OUT OUTPUT STREAM break_batch SCHEMA(symbol string,volume integer, price float)BEGINDECLAREdictionary(long,typeof(s1)) dict;typeof(s1) record;long id:=1; long fill_id:=1; END;on s1{ dict[s1.ROWID]:=s1; print('inside dictionary',s1.symbol); fill_id++; };every 1 second{ if(fill_id=id) { exit; } else { record:=dict[id]; print('inside every 1 second',record.symbol); output setOpcode(record,insert);  remove(dict,id); id++;  } };END;/*Initial value of the window gets filled up through this stream */CREATE INPUT STREAM fill_window schema(symbol string,volume integer,price float); CREATE FLEX flex2 in break_batch,fill_window out output window W1 SCHEMA(symbol string,volume integer, price float)primary key(symbol)BEGINon break_batch{ output setOpcode(break_batch,update);};on fill_window{ output setOpcode(fill_window,insert); };END;====================================Send in rows in to fill_window stream first using Manual Input->Transaction mode AAA,10,10BBB,10,10CCC,10,10DDD,10,10Send in rows in to s1 using Manul Input->Transaction modeAAA,1,1BBB,1,1EEE,1,1You will see 2 transactions getting updated and 1 getting thrown out. Please note, this can slow down the system as I am breaking it and sending 1 row at a time every 1 second. Also I have just run some simple test cases with it and have never implemented this in a large project. I have a message from Jason and I understand your system to be quite complicated. I am not sure how this will work with heavy load. If you would like to ask more questions on this and would like more information on this then please open a new message so I can work with you on your issue.Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Update opcode rolling back all records in bulk", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "33.2", "author": "Jason Kelly", "url": "http://scn.sap.com/thread/3355190", "text": "Hi Geetha,Many thanks for your suggestion. Mark & I have had a look at your suggestion.I've also replied separately in the support message to say that I can see how your solution would solve the issue, however, the performance would not be satisfactory as we are planning on receiving more than 4million input events on the input stream that gets passed into the FLEX module.I'm happy to pursue this message via the support case I raised with you on the SAP support portal, as we can provide you with specific examples & data there.However, there are still a few questions that we have about this issue generally, that don't relate to these specific example here, so I'll posted these here as well (again duplicated in the support message assigned to you), in case anyone else from SAP/Sybase is able to reply...These are:I'm wondering why the events get batched together in the first place as well - my thinking is that an events processor should treat incoming events individually? However I have no visibility as to how the ESP engine really works.Is there any way to tell the ESP server to just ignore any attempted updates where the key doesn't exist, instead of rolling back any transactions that are part of the same batch (i.e. to have the same behaviour as \"safedelete\", but for updates)? In our case, transactions end up becoming part of the same internal batch do not necessarily relate to each other - so I think it's pretty dangerous that ESP considers them as the one batch & then fails all of the \"batched\" updates if only one is invalid!Cheers,Jason.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Update opcode rolling back all records in bulk", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "33.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3355190", "text": "Jason - are these events being loaded into ESP as part of a transaction block? That's what it looks like, and if that's the case then yes, it's all or nothing - i.e. if any events in the transaction block can't be processed, none will be processed. But if they aren't published as part of a transaction block, then they should be completely independent of each other. Is there a reason you are loading them as transaction blocks? As long as they aren't loaded into the input stream in transaction blocks, you should see the behavior you are looking for, where the update will fail but it won't affect other events. (or have I misunderstood something?)", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Update opcode rolling back all records in bulk", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "33.4", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3355190", "text": "Hi Jeff,A transaction block will also be created as a result of a join. I had a chance to go through Jason's code and that is what is happening in their case. There are two workarounds I have suggested. 1. The same as the previous one I suggested earlier except that the timer can be changed to 1 milliseconds. In my small setup I am seeing the blocks getting spread out without any issues. I have asked Jason to test this. 2. Use a dictionary and store all the rows that is in the SPLASH ouput windows as a dictionary entry and use the SetOpcode(.., update) only if data is present in the dictionary. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Update opcode rolling back all records in bulk", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "33.5", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3355190", "text": "Thanks for clarifying where the transaction blocks are getting created Geetha.So Jason, in answer to your questions:1. Why did the events get batched together in the first place? An event processor should treat incoming events individually? Answer: In a CCL Join in ESP, where one incoming event produces two or more output events (i.e. a one-to-many join), the all the events emitted by the join that were produced by a single input event will be bound together in a transaction block. This will also be true with a Flex operator: all output events emitted as a result of a single \"trigger\" event will be grouped in a transaction block. So the event processor does treat incoming events individually (as long as they don't arrive in a transaction block), but derived events end up linked together in a transaction block when they result from the same trigger event.2. Is there any way to tell the ESP server to just ignore any attempted updates where the key doesn't exist, instead of rolling back any transactions that are part of the same batch (i.e. to have the same behaviour as \"safedelete\", but for updates)? Answer: no, afraid not. There are potentially work arounds, for example rather than using a Flex to set the opcode to update, knowing that it will fail, can you do an inner join to effect the update? or rather than apply the updates directly to the window, use a flex to match new records to the window and produce a new window? A \"safeupdate\" opcode isn't a bad idea though.3. Transactions end up becoming part of the same internal batch do not necessarily relate to each other - so I think it's pretty dangerous that ESP considers them as the one batch & then fails all of the \"batched\" updates if only one is invalid! Comment: I guess the thing is, they are related in that they were all produced by the same Join event. Understanding that is key to not having unexpected results. This isn't well documented (or widely understood) - we need to fix that. Sorry it tripped you up. And beyond making it clearer: it's an interesting use case. Maybe we need a way to \"untie\" records in a transaction block - or an option to prevent a join (or flex) from producing a transaction block in the first place when it's not desired.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Update opcode rolling back all records in bulk", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "33.6", "author": "Jason Kelly", "url": "http://scn.sap.com/thread/3355190", "text": "Hi Jeff,Thanks for your detailed responses (and Geetha, thanks for providing the supporting info). I understand the \"batching\" behaviour now.Regarding the last point:3. Transactions end up becoming part of the same internal batch do not necessarily relate to each other - so I think it's pretty dangerous that ESP considers them as the one batch & then fails all of the \"batched\" updates if only one is invalid!  Comment: I guess the thing is, they are related in that they were all produced by the same Join event. Understanding that is key to not having unexpected results. This isn't well documented (or widely understood) - we need to fix that. Sorry it tripped you up. And beyond making it clearer: it's an interesting use case. Maybe we need a way to \"untie\" records in a transaction block - or an option to prevent a join (or flex) from producing a transaction block in the first place when it's not desired.Makes sense how you say they are related in a way, because they were produced by the same Join event. This is not how we assumed the product would work, but at least we know now for any future development.However, if possible, it would be great if this behaviour was optional, or if there was some kind of provided-way of \"unbatching\" the records - as you mention yourself. Geetha's solution for \"unbatching\" the records works fine in our current case, but it does limit performance as the minimum interval for a FLEX stage is 1 millisecond. So, can I log a enhancement request for this functionality?And yes, we weren't able to find anything in the documentation to suggest how this \"batching\" of events can occur in scenarios such as the JOIN here. Would be great if this could be included in the documentation somewhere too.Thanks again for your support and help on this one.Cheers,Jason.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Update opcode rolling back all records in bulk", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "33.7", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3355190", "text": "Good feedback - thanks. I've logged it as an enhancement request. Not sure how soon we'll get to it - drop me a note if you see it becoming a pressing need. And I've also put in a request to get an explanation of this added ot the documentation (I think I'll also post a little write up explaining this here in the community).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Update opcode rolling back all records in bulk", "type": "answer", "tags": "N/A"},
{"date_time": "2013-05-22 23:48:00", "resolve": true, "uid": "34", "title": "Atom Feed Input Adapter", "url": "http://scn.sap.com/thread/3363175", "text": "Folks,Could someone please point to some actual examples, or provide guidance leading me in the right direction,pertaining to a functional ESP project using the Atom Feed Input Adapter? I'm new to ESP and would liketo play with news/social-oriented sources to get my feet wet.The documentation on this adapter (Adapters Guide (PDF)) is 1 page in length and less than useful.Any advice would be wonderful.Thanks in advance,Michael", "views": "561", "answers": 9, "author": "Michael Scharber", "upvotes": 0, "type": "question", "tags": "adapter.atom.esp.stream_processing.esp_developer"},
{"date_time": "2013-05-23 13:29:00", "resolve": "", "uid": "34.1", "author": "Mike Koleosho", "url": "http://scn.sap.com/thread/3363175", "text": "ESP SP02 (latest) - http://scn.sap.com/docs/DOC-41193 - docs are found here:http://infocenter.sybase.com/help/index.jsp;jsessionid=1qaw6sd6mwaeh?docset=/com.sybase.infocenter.help.esp.5.1.2/doc/html/title.html&docSetID=1959As you are getting started, most important docs will be:1. getting started PDF2. adapter guide and 3. the examples PDF.Did you check the following?http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01615.0510/doc/html/cgo1284748170405.html?resultof=%22%41%74%6f%6d%22%20%22%61%74%6f%6d%22%20%22%46%65%65%64%22%20%22%66%65%65%64%22%20%22%49%6e%70%75%74%22%20%22%69%6e%70%75%74%22%20%22%41%64%61%70%74%65%72%22%20%22%61%64%61%70%74%22%20and also:If you are not already familiar with the specific XML format ATOM uses, see: http://www.atomenabled.org/Hope this helps....Mike", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "34.2", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3363175", "text": "Thanks Mike. I have all of these docs in hand and have also established a server on a remote Linux host so I am scratching away.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "34.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3363175", "text": "Hi Michael,Here is a short example that works.CREATE INPUT WINDOW inWindow1 SCHEMA (feed_title STRING,feed_link STRING,feed_author_name STRING,entry_title STRING,entry_link STRING,entry_content STRING) PRIMARY KEY (entry_title);ATTACH INPUT ADAPTER Atom_Feed_Input1 TYPE atomreader_in TO inWindow1 PROPERTIESURL = 'http://www.atomenabled.org/atom.php' ,refreshInterval = '30000' ;NOTE: I had to be connected directly to the internet. In other words, I don't think the adapter works if there is a proxy server between you and the internet.Let me know if you have problems getting it to run.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "34.4", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3363175", "text": "Neal,This is helpful. Thank you. Though I doubt there are many corporate networks publicly-facing where developers would be playing around like this. I am 100% certain I will need to configure a proxy route in order to reach http content. I see (from the Adapters Guide documentation) that the Web Services (SOAP) Input and Output Adapter has proxy awareness and allows for these settings to be made.What are the chances that Atom Feed Input Adapter can adapted to accept and leverage proxy settings? Seems like a crucial thing to mention in the documentation would be \"does not work behind a firewall\".Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "34.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3363175", "text": "Hi Michael,It appears that there is an outstanding bug for the AtomFeed Input adapter not working behind proxy server:728847 - AtomReader Input Adatper does not work behind proxy serversThis was discovered internally so it does not have much priority with engineering right now. If this is an important issue for you, I would recommend logging a technical support case so we can associate the bug with the case.Bugs reported by customers get a higher priority than ones discovered internally and are likely to get fixed sooner.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "34.6", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3363175", "text": "Thanks Neal.Good to know. I will do precisely that, and that too will be a first for me.Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "34.7", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3363175", "text": "Hi Michael,I'd be interested in knowing how you want to use the Atom adapter. I was under the impression that there hadn't been strong adoption of ATOM; we haven't seen much (any?) interest. So to be honest, we haven't planned on enhancing it and are not likely to unless there's a real need.Feel free to reply to me directly if you'd rather not describe your intended use in a public post (I'm the product manager for ESP).Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "34.8", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3363175", "text": "Hi Jeff,I don't mind at all. It's the connectivity to streaming, near-time text/news/social content I'm interested in pulling into ESP...not specifically Atom. If you (\"ESP\") have other ways of getting stuff in, like RSS, I'm game. What do you have in mind?Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "34.9", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3363175", "text": "Based on what I've seen to date, I'm more inclined to try to make RSS and Twitter adapters available rather than enhancing our Atom adapter - for which there just doesn't seem to be much demand.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "34.10", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3363175", "text": "That would be great Jeff, and I would gladly be the first in line to test such adapters.Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Atom Feed Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2013-05-27 12:39:00", "resolve": false, "uid": "35", "title": "Best Practice for keeping track of former event", "url": "http://scn.sap.com/thread/3365235", "text": "Hi,in my scenario I am dealing with database events on HANA: If a database record is insert some logic shall be applied on that row and shall be written to another database table within HANA. The tricky thing is that the applied logic is based on what has already been inserted (e.g. insert the new record only if this has not been done before). This is somehow a replication task. But on last SAP TechEd, ESP has been named as one of the replication tools for HANA!!Right now, I do not know how to solve this problem in a very efficient way. Using streams will not work as anytime the ESP will be re-started all data gets replicated again and duplicates the data on the target HANA tables ;-( Using windows (in combination with file store) does also not solve the issue, as the HANA tables are containing too much data. Therefore I created an additional HANA table to maintain a status flag of the records which have been replicated and wrote a JDBC library that looks for replicated rows and insert a flag to the ones that been replicated. My JAVA code works fine in a standalone program, but crashes the ESP server... Before looking deeper into the crashing problem, I thought I would post a discussion and see whether there are other (better) approaches of keeping track on previously handled events. Any examples or suggestions?Thanks and Best Regards.Markus", "views": "405", "answers": 6, "author": "Markus Richter", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-05-28 16:38:00", "resolve": "", "uid": "35.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3365235", "text": "From what you describe - unless I've misunderstood - I don't think ESP is the right tool for you. ESP is not a replication tool for SAP HANA and is not recommended for such. It is one of the \"data provisioning\" tools available for HANA, and is recommended for use in capturing data from real-time event streams - but is not recommended for use in replicating data between databases. With that said, ESP can be used with SAP Sybase Replication Server: RepServer performs realtime change capture on a source database and turns those DB events into a real-time event stream that can be fed into ESP (ESP has support for RepServer) where the events can be processed or analyzed - e.g. you can monitor trends, patterns, etc. But even here - if you just want to replicate the data from the source into a destination DB, then RepServer doesn't need to go through ESP.But if you're looking to replicate data from one HANA table to another, then I don't think ESP is probably your best option.Now if you are working with an incoming stream of events (and yes, they could be database \"events\" - i.e. DB transactions), then it is possible to stream them through ESP and have ESP keep track of what's been stored in the target table. i.e. if there really is a need for ESP here, you can design your ESP data model to avoid duplicating data after a re-start.And again, maybe I've misunderstood the use case...", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practice for keeping track of former event", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "35.2", "author": "Markus Richter", "url": "http://scn.sap.com/thread/3365235", "text": "Hi Jeff,thanks for the explanation. Now, I understand the main purpose of ESP. Nevertheless, my use case is not a really 100% replication use case: I have database table A. Anytime a record gets insert into A, I need to do some complex data maniplulation before storing the data into the target table B. This data manipulation includes generation of additional values and split the record into different records. For those data maniplulation ESP does quite a nice job. I am not aware those extensive data manipulation is available within Rep Server or SAP SLT. Having said this, I actually was able to write such an ESP script and run it successfully. My problem is that anytime I re-start the ESP server, all records of table A will ge processed again, which leads to duplicates within the target table B. How do I overcome the problem of re-processsing former events of database table? Due to the large number of events, I am not able to use the file store. I think this is generic problem and not limited to my use case.I appreciate any help.Thanks and Regards.Markus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practice for keeping track of former event", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "35.3", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3365235", "text": "Hi Markus,It is difficult to give good suggestions without understanding the complete project. Here is a couple of ideas.. 1. You can use the getData() function rather than the DB input adpater and pass a parameter to the query which will read rows that were not processed yet. For example if there is a key column in your table like 1,2,3,4,5.. You had already processed 1,2,3 in your previous run and in the next run you can modify the query to process the next id by changing the parameter value(parameters can be passed through ccr files and we need not touch the project itself). Please see  http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01621.0512/doc/html/vge1312573080739.html2.You can read the content of table B only at the start of the project store it in a window. Read the content of table A, check to see with the key values whether the data has already been processed and then proceed with your logic. The adapters can be started in sequence and stopped using esp_client command and by placing the adapters in ADAPTER start groups.Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practice for keeping track of former event", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "35.4", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3365235", "text": "Markus,Thanks for clarifying - and in that case, yes, it does make sense to use ESP. Longer term we plan to make this easier for you - we've seen others wanting to do the same. For now, your best bet is one of the approaches Geetha has suggested: if there's a way to poll \"Table A\" to just get new records rather than everything, you can do that. You can even set this up in a flex to fire getdata() at regular intervals, and you can use a variable to keep track of the last record received so that next time getdata() fires you can only get later ones. Otherwise, per Geetha's second option, set up some type of filter in ESP to filter out the rows already received.Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practice for keeping track of former event", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "35.5", "author": "Markus Richter", "url": "http://scn.sap.com/thread/3365235", "text": "Hi All,thanks for the hints. It is good to know that I am not the only one who is asking for such an option ;-)The \"window\" option will not work for me as the amount of data that needs to be kept is way too big over time (daily growing). The getData () option could be a promosing solution. But I need to find out the best way of storing the last used value for narrowing the select statement. Because the issue occures after a re-start of the ESP server. So I just need to store (and override) the value of the select paramter after each execution of the getData () fucntion.Thanks and Best Regards.Markus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practice for keeping track of former event", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "35.6", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3365235", "text": "Hi Markus,I would suggest that you use a log store to keep the last used value.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Best Practice for keeping track of former event", "type": "answer", "tags": "N/A"},
{"date_time": "2013-06-06 15:00:00", "resolve": false, "uid": "36", "title": "ESP install", "url": "http://scn.sap.com/thread/3371148", "text": "Cannot get InstallAnywhere to install the ESP. After a re-image of my laptop and a restore of all my files I could start the ESP Studio and display all my files in the workspace, however I could not compile any files so I thought a re-install would solve the problem.At first the installer just hung during the JRE7 stage with no messages. I did a complete un-install via Control Panel --> Programs and Features. Still no luck so did another un-install.This morning I shutdown my laptop before re-attempting an install. This time the JRE7 stage completed but the next stage the SCC installed with JAVA errors. I can continue the install but without SCC not much use.I have installed java 32bit and 64bit in Program Files (x86) and Program Files respectively thinking that may be the problem but still get stuck on the SCC install stage.My email is laurence.martin@sap.com if you want me to sen the screen shots of the errors produced.", "views": "365", "answers": 2, "author": "Laurence Martin", "upvotes": 0, "type": "question", "tags": "cep"},
{"date_time": "2013-06-06 15:28:00", "resolve": "", "uid": "36.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3371148", "text": "Hello Laurence,The installer comes with and should be using it's own JRE.I don't know if you downloaded the installation from Sybase's software download site or SAP's. I know in the past couple of weeks there have been some instances where the download ended prematurely when downloading from Sybase's website. In my case, I was able to unzip the installation and run the installer but it did not complete.So:1) Double check the size of the zip file on your PC and make sure it is the exact same size as the one on the download site.2) Make sure that you are extracting all of the files from the ZIP file into a temporary directory and running the installer from that directory. Do not attempt to run the installer from within the ZIP file itself.3) If all of this does not help, zip up all of the installation log files (*.log and *.out) from a directory similar to this one: C:\\ESP51\\logPost the log files here or send them to me. I will be out of the office on Friday.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP install", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "36.2", "author": "Mike Weadley", "url": "http://scn.sap.com/thread/3371148", "text": "I encountered the same installation errors and experience you describe when the dowload size in bytes on the installation image was not an exact match for that listed on the download site. In my case the downloaded size was not off my much, but the difference left me with three incomplete installs, each of which failed at a different point. I followed Neal's recommendation and it worked for me.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP install", "type": "answer", "tags": "N/A"},
{"date_time": "2013-06-08 21:42:00", "resolve": true, "uid": "37", "title": "Querying the database based on the streaming data", "url": "http://scn.sap.com/thread/3372121", "text": "Hi,I am trying to query the database based on the streaming data. For example when a customerID come from my input adapter (streaming data with rate 10 per hour), I want to send a query to database to get a specific data of the customer such as customer's score etc. I don't want to hold the customer info in a window (in the memory), so I need to send queries each time when a customerID come from the input adapter. How can I do this? Thanks,Bulut", "views": "304", "answers": 2, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-06-10 16:09:00", "resolve": "solution", "uid": "37.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3372121", "text": "Use the getdata() function. You can use this in the context of a Flex operator or even in a column expression or within a custom SPLASH function. getdata() lets you make an event-driven query to an external DB.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Querying the database based on the streaming data", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "37.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3372121", "text": "Thank you very much Jeff. I miss getdata() function.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Querying the database based on the streaming data", "type": "answer", "tags": "N/A"},
{"date_time": "2013-07-04 22:33:00", "resolve": false, "uid": "38", "title": "How to make Sybase ESP appealing for business user ?", "url": "http://scn.sap.com/thread/3386125", "text": "There is no doubt that Sybase ESP is very powerful technology from several perspectives. Nevertheless, we have started to face more and more business cases sponsored by business people who lack of technical IT skills. These people are the sponsors and manage the projects most of time. Since ESP client project designer is relatively not user-friendly as they wish to be , we are having hard time to convience them. Additionally, we have been told that some competitors provide easier and simple front-end tools. We would like to see some new developments from pre-sales and business perspectives. Tighter PowerDesigner integration could be helpful..Any advise or strategic information are welcome..", "views": "340", "answers": 1, "author": "Muzaffer Yontem", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-07-08 16:00:00", "resolve": "", "uid": "38.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3386125", "text": "ESP is a tool for rapid application development. It's not designed today as a tool for use directly by non-technical business users. Such users would normally be using applications built on ESP. We do have examples of SAP and third party applications for business uers built on top of ESP - and there will be more to come.I would be very interested in hearing more about the specific use cases you are seeing where there is a need to put the power of stream processing that ESP provides in the hands of business users, and what that might look like. Please feel free to email me directly.As for competitors: we keep a close eye on our competitors and believe that one of the strenghts of ESP is the usability of our front-end tools. I suspect there is an apples-to-oranges comparison here, since we are comparing our product to other high-end event processing engines. Comparisons to domain-specific applications designed for business users will of course be a very different comparison.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to make Sybase ESP appealing for business user ?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-07-12 20:15:00", "resolve": false, "uid": "39", "title": "ESP studio playback feature", "url": "http://scn.sap.com/thread/3390228", "text": "Hello,I am new to this forum and is presently evaluating the ESP product.I am trying to use the playback feature of the ESP studio to simulate some streams.I chose the playback mode as Timestamp column and provided the column name(as 'TIME') holding the timestamp value.and the rate slider stayed as is 'At timestamp Rate'.I am also using the date mask '%m/%d/%Y %H:%M:%S' Input Sample===================== winTrades,i,AAPL,07/12/2013 15:21:09,Q,@FT,100,398.70,,00,6,N winTrades,i,AAPL,07/12/2013 15:22:09,Q,@FT,100,398.70,,00,7,N winTrades,i,AAPL,07/12/2013 15:23:09,Q,T,100,398.50,,00,25,N winTrades,i,AAPL,07/12/2013 15:24:09,Q,@FT,100,398.75,,00,33,N winTrades,i,AAPL,07/12/2013 15:25:09,Q,@FT,100,399.70,,00,40===== Begin ============winTradesEvent SYMB TIME EXCH SCND TRDV TRDP SIND CIND SEQU SRCE INSERT AAPL 2013-07-12 11:21:09 Q @FT 100 399 NULL_VALUE 00 6 N INSERT AAPL 2013-07-12 11:22:09 Q @FT 100 399 NULL_VALUE 00 7 N INSERT AAPL 2013-07-12 11:23:09 Q T 100 398 NULL_VALUE 00 25 N INSERT AAPL 2013-07-12 11:24:09 Q @FT 100 399 NULL_VALUE 00 33 N INSERT AAPL 2013-07-12 11:25:09 Q @FT 100 400 NULL_VALUE 00 40 N ===== End ============winTrades1) With the above sample set ,it should have ideally played back the entries a minute apart, but it played it back all at once without any delay 2) I can see that ESP assumes the input timestamps as UTC and in the window output I can see them adjusted for my localtimezone which is ESTand hence the 4 hour lag.Is this the expected behaviour,is there a configuration that controls the timezone.If someone has encountered similar issues before or can provide insights ,kindly assist.I am attaching the CCL file as well for your reference.Thanks,Suneeth.", "views": "447", "answers": 6, "author": "Suneeth John", "upvotes": 0, "type": "question", "tags": "studio.esp_playback"},
{"date_time": "2013-07-12 20:42:00", "resolve": "", "uid": "39.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3390228", "text": "Hi Suneeth,1. Try using the esp_playback command instead of studio. Make sure you are using ESP SP02 See these 2 post it will help you. https://community.wdf.sap.corp/message/361457. and https://community.wdf.sap.corp/message/409915#409915 you may need to pass the timestamp format ast the argument along with the command.2.As you have already found out ESP uses UTC for all internal processing and there are open enhancment request to show the timestamp in the corresponding timezone. I guess, if you use esp_subscribe utility instead of stream viewer it should show in UTC.Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP studio playback feature", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "39.2", "author": "Suneeth John", "url": "http://scn.sap.com/thread/3390228", "text": "Geetha,Many thanks for the suggestions.I will try out the esp_playback and esp_subscribe I was not able to navigate these links though,they are not resolvinghttps://community.wdf.sap.corp/message/361457#361457https://community.wdf.sap.corp/message/409915#409915Thanks,Suneeth.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP studio playback feature", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "39.3", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3390228", "text": "Hi Suneeth,Please ignore my previous email, those are internal forums which you may not have access to.I just mistook this forum to be the internal forum. Can you try using esp_playback command line tool ?This works for me..CREATE INPUT STREAM winTrades SCHEMA ( SYMB string , TIME timestamp , EXCH string , SCND string , TRDV integer , TRDP float , SIND string ,CIND string , SEQU integer , SRCE string ); C:\\ESP51SP02\\ESP-5_1\\bin>esp_subscribe -p localhost:9786/default/test -c studio:geetha -s winTradesC:\\ESP51SP02\\ESP-5_1\\bin>esp_playback -p localhost:9786/default/test -c studio:geetha -C \"espdlm:input.csv:,\" -L -R TIME -m \"%m/%d/%Y %H:%M:%S\"Please note the username and password may be something you need to pass depending on what you use. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP studio playback feature", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "39.4", "author": "Suneeth John", "url": "http://scn.sap.com/thread/3390228", "text": "Hi Geetha,Sorry about the delayed response.I just got to try this out using the esp_playback and esp_subscribe command line tools.Though the pub/sub works, the spaced playback wrt the timestamp is not happening.The records are getting played back all at once.We are not using SP02 - at our end I guess but ESP-5_1- as you said is this feature only rightly supported in the SP02 version ? Thanks,Suneeth.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP studio playback feature", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "39.5", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3390228", "text": "Hi Suneeth,With ESP 5.1 SP02 there were a couple of issues with respect to esp_playback with timestamp column and microsecond granularity that was fixed. I am not sure whether what you are seeing is related to the issues that got fixed with ESP SPO2. If you see the data coming up in esp_subscribe all at once without the timestamp delay then can you send us the csv file you are using to test this ?This works for me in ESP5.1 SP02 without any issues. Here is the code I used to test your issue and the data I used in ESP SP02.CREATE INPUT WINDOW winTrades SCHEMA ( SYMB string , TIME timestamp , EXCH string , SCND string , TRDV integer , TRDP float , SIND string ,CIND string , SEQU integer , SRCE string ) PRIMARY KEY ( SYMB , SEQU ) KEEP 1 minute;winTrades,i,AAPL,07/16/2013 14:42:00,Q,@FT,100,398.70,,00,6,NwinTrades,i,AAPL,07/16/2013 14:43:00,Q,@FT,100,398.70,,00,7,NwinTrades,i,AAPL,07/16/2013 14:44:00,Q,T,100,398.50,,00,25,NwinTrades,i,AAPL,07/16/2013 14:45:00,Q,@FT,100,398.75,,00,33,NwinTrades,i,AAPL,07/16/2013 14:46:00,Q,@FT,100,399.70,,00,40,NC:\\ESP51SP02\\ESP-5_1\\bin>esp_subscribe -p localhost:9786/default/test -c studio:geetha -s winTrades<winTrades ESP_OPS=\"i\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:42:00.000\" EXCH=\"Q\" SCND=\"@FT\" TRDV=\"100\" TRDP=\"398.700000\" CIND=\"00\" SEQU=\"6\" SRCE=\"N\"/><winTrades ESP_OPS=\"i\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:43:00.000\" EXCH=\"Q\" SCND=\"@FT\" TRDV=\"100\" TRDP=\"398.700000\" CIND=\"00\" SEQU=\"7\" SRCE=\"N\"/><winTrades ESP_OPS=\"d\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:42:00.000\" EXCH=\"Q\" SCND=\"@FT\" TRDV=\"100\" TRDP=\"398.700000\" CIND=\"00\" SEQU=\"6\" SRCE=\"N\"/><winTrades ESP_OPS=\"d\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:43:00.000\" EXCH=\"Q\" SCND=\"@FT\" TRDV=\"100\" TRDP=\"398.700000\" CIND=\"00\" SEQU=\"7\" SRCE=\"N\"/><winTrades ESP_OPS=\"i\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:44:00.000\" EXCH=\"Q\" SCND=\"T\" TRDV=\"100\" TRDP=\"398.500000\" CIND=\"00\" SEQU=\"25\" SRCE=\"N\"/><winTrades ESP_OPS=\"d\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:44:00.000\" EXCH=\"Q\" SCND=\"T\" TRDV=\"100\" TRDP=\"398.500000\" CIND=\"00\" SEQU=\"25\" SRCE=\"N\"/><winTrades ESP_OPS=\"i\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:45:00.000\" EXCH=\"Q\" SCND=\"@FT\" TRDV=\"100\" TRDP=\"398.750000\" CIND=\"00\" SEQU=\"33\" SRCE=\"N\"/><winTrades ESP_OPS=\"d\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:45:00.000\" EXCH=\"Q\" SCND=\"@FT\" TRDV=\"100\" TRDP=\"398.750000\" CIND=\"00\" SEQU=\"33\" SRCE=\"N\"/><winTrades ESP_OPS=\"i\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:46:00.000\" EXCH=\"Q\" SCND=\"@FT\" TRDV=\"100\" TRDP=\"399.700000\" CIND=\"00\" SEQU=\"40\" SRCE=\"N\"/><winTrades ESP_OPS=\"d\" SYMB=\"AAPL\" TIME=\"2013-07-16 14:46:00.000\" EXCH=\"Q\" SCND=\"@FT\" TRDV=\"100\" TRDP=\"399.700000\" CIND=\"00\" SEQU=\"40\" SRCE=\"N\"/>C:\\ESP51SP02\\ESP-5_1\\bin>esp_playback -p localhost:9786/default/test -c studio:geetha -C \"espdlm:input.csv\" -L -R TIME -m \"%m/%d/%Y %H:%M:%S\"[1374010922] started[1374010922] complete: 0 (success) 0 (errors) 0(%)[1374010982] complete: 2 (success) 0 (errors) 39.8734(%)[1374011042] complete: 3 (success) 0 (errors) 59.4937(%)[1374011102] complete: 4 (success) 0 (errors) 79.7468(%)[1374011162] complete: 5 (success) 0 (errors) 100(%)Since this is a KEEP 1 minute clause you see the data in esp_subscribe getting deleted from the window as the ESP_OPS=\"d\" and then the new data getting inserted as the ESP_OPS=\"i\"Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP studio playback feature", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "39.6", "author": "Suneeth John", "url": "http://scn.sap.com/thread/3390228", "text": "Geetha ,Was late to update this thread.The version we are evaluating is ESP5.1 and not ESP5.1 SP02So I am assuming that the issue is with the older version of esp_playback as I see that you use the very same file and is able to see the spaced playback.Anyways we wrote a server program to simulate the tick stream and publish to a socket and we are looking to use the csv/xml client input socket adapter to subscribe.will let you know if we are successful,we are trying to upgrade to SP02 as well.Thanks,Suneeth.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP studio playback feature", "type": "answer", "tags": "N/A"},
{"date_time": "2013-08-07 05:24:00", "resolve": false, "uid": "40", "title": "SAP Sybase ESP - 30 day evaluation for Linux?", "url": "http://scn.sap.com/thread/3403425", "text": "Hi Guys,When registering to download a 30 day evaluation copy of SAP Sybase ESP on ESP Developer Center, I only see two download options- 1) Download SAP Sybase ESP on Windows x86-64 2) Download SAP Sybase ESP on Windows x86-32How do I download a 30 Day Evaluation Copy of SAP Sybase ESP for Linux?Thanks,Sourabh", "views": "355", "answers": 1, "author": "Sourabh Mehta", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-08-13 18:31:00", "resolve": "", "uid": "40.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3403425", "text": "I just noticed that you had not received a reply - sorry for the delay. Unfortunately we currently only have ESP for Windows available for evaluation downloads from the ESP Developer Center. To get an evaluation copy of ESP for Linux, you will need to ask your SAP relationship manager to order a trial license.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP Sybase ESP - 30 day evaluation for Linux?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-09-12 09:52:00", "resolve": true, "uid": "41", "title": "connect control center to ESP server", "url": "http://scn.sap.com/thread/3421740", "text": "Hi all,I've installed a trial version of Sybase ESP 5.1 and also Sybase Control Center for ESP.Both servers are running but I can't create a connection from SCC to ESP Server.When using the suggested port 19011 message \"Connection parameters are invalid - please check the provided connection parameters and try again.\" appears. When using administrator port 19066 message \"Authentication credentials are invalid - please check the provided credentials and try again.\"Is it ok to use port 19066 ? Where to find user and password ?ESP Studio just uses user studio with any password.Thanks,Silvia", "views": "625", "answers": 4, "author": "Silvia Sander", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-09-12 14:25:00", "resolve": "", "uid": "41.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3421740", "text": "It sounds like you are doing this (if I've misunderstood, then please correct):1. You have installed ESP locally. You start Studio and from Studio start one or more projects2. You then try to connect to the ESP server that was started by the StudioIf that's correct, then let me explain how the credentials work:When you run a project from ESP Studio, you can either run it on a local ESP server that is under the control of the Studio or on a \"remote\" ESP server (this could actually be on the same machine, but is a server that is started via cluster command tools and not via the Studio itself). By default, when you are in Studio and run a project, the Studio will start a local ESP server and run the project. This server is actually sort of a \"special\" server that is under the control of the Studio and will be shut down when you shut down the Studio. What's more, this local server has a very limited security structure with a single defined user \"studio\". After starting ESP Studio, the first time you start a project locally, the Studio will start this local ESP server. At that time it will prompt you to create a password for user \"studio\". That is the password that any application connecting to a project on this server (such as SCC) will need to use.Does that solve the problem? If not, please provide more information about your environment.Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:connect control center to ESP server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "41.2", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3421740", "text": "Hi Silvia,Assuming you are starting the local cluster as Jeff has described and assuming you are trying to register this node to SCC you should be following the steps described here: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc60012.0327/doc/html/cgo1327372883855.htmlHost Name = localhost (SCC must be installed on the same PC as ESP when using localhost)Port Number = 9786 (9786 is the port used by the local Studio cluster)SSL Is Enabled = False (The local Studio cluster does not enable SSL by default)Authentication Type = Native OSIf you are not using the local Studio cluster, rather you have started a cluster by doing something like:cd %ESP_HOME%\\cluster\\nodes\\node1%ESP_HOME%\\bin\\esp_server --cluster-node=node1.xmlThen the parameters would be:Host Name = the host name of your PCPort Number = 19011 (19011 is the default port number by you may need to examine node1.xml RPC section to be sure)SSL Is Enabled = True or False (again check the node1.xml file's RPC section to see if you enabled SSL during the installation of ESP).If this doesn't help, provide us with a few more details as to where you are in the process:1) What version of ESP are you using? Go into Studio and Help/About to get the complete version string. ESP 5.1 SP03 was released recently and replaced the older ESP 5.1 SP02 evaluation download.2) Exactly what screen are you on when you get this error message? Can you capture a screen shot?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:connect control center to ESP server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "41.3", "author": "Silvia Sander", "url": "http://scn.sap.com/thread/3421740", "text": "Hi Neal,thank you very much. It works fine now !!(I do not know how to change Authentication Type to Native OS, so I used the studio user)Kind Regards, Silvia", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:connect control center to ESP server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "41.4", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3421740", "text": "Hello,Good to hear! As far as authentication types go, when using the local Studio cluster, external tools such as ESP Studio, SCC or any of the command line utilities will need to use the Native OS type of authentication. (As far as they know, they are just passing a user and a password to the cluster for authentication, they don't know that this special user \"studio\" is pre-configured).If you had started a cluster manually as described here: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01620.0513/doc/html/tbi1365171155698.htmlYou would have to make sure that the external tools or command line utlities used the same type of authentication specified in the cluster configuration file (node1.xml for example). The type of authentication for \"node1.xml\" is set during installation when you answer one of the prompts.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:connect control center to ESP server", "type": "answer", "tags": "N/A"},
{"date_time": "2013-09-30 09:56:00", "resolve": true, "uid": "42", "title": "A problem of File Json Input Adapter", "url": "http://scn.sap.com/thread/3430837", "text": "Hi, I have a JSON file(oData v2) that format as below: {\"d\":{\"results\":[{\"xxx\":{\"xx1\"}, {\"xxx\":{\"Xx2\"}] } } I want to use the JSON File Input Adapter to get data, and the property \"JSON Root Path\" ofInput Adapter how to set ?? I try \"d:results\" , \"d\\results\" or \"d/results\".. Unfortunately itcannot work. Does any experts help me? Thanks.", "views": "475", "answers": 6, "author": "Ango Tsai", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-10-01 19:36:00", "resolve": "", "uid": "42.1", "author": "Jacob Singer", "url": "http://scn.sap.com/thread/3430837", "text": "Hello Ango,I am currently looking into this for you; however, we noticed that the JSON format you sent over is invalid when plugging it into a validator. Could you check on that in the meantime to see if that has any affect on the issue?Thanks!Best wishes,Jacob SingerSAP Global Product Support", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:A problem of File Json Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "42.2", "author": "Ango Tsai", "url": "http://scn.sap.com/thread/3430837", "text": "Hi Jacob  Thank for your reply, the JSON content gets from OData of HANA , the JSON file be generated as below steps:1. through http://HANA_HOST/xx/yy.xsodata/bb/?$format=json 2. copy the JSON content to a fileso , is the JSON format invalid ??", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:A problem of File Json Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "42.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3430837", "text": "Is there a reason you are trying to pull data from HANA via ODATA? The ESP database input adapter supports HANA via the HANA ODBC driver. Or is there a reason you need to get the data via the ODATA interface?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:A problem of File Json Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "42.4", "author": "Ango Tsai", "url": "http://scn.sap.com/thread/3430837", "text": "Hi Jeff  I just want to try the function for JSON adapter , not for special reason. Thank for your reply !", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:A problem of File Json Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "42.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3430837", "text": "Hello,Try this: jsonRootpath = 'd.results' Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:A problem of File Json Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "42.6", "author": "Ango Tsai", "url": "http://scn.sap.com/thread/3430837", "text": "Hi Neal Oh , It's so simple. I totally forget that access format is the same with UI5 for JSONModel binding oData. Very thank for your answer !.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:A problem of File Json Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2013-10-11 09:55:00", "resolve": true, "uid": "43", "title": "JSON adapter Poll Period not work", "url": "http://scn.sap.com/thread/3436901", "text": "Hi experts, I met a property problem for \"Dynamic Loading Mode\" and \"Poll Period (seconds) \" on JSON Input Apapter.When I set value \"dynamicFile\" on \"Dynamic Loading Mode\" property and value \"5\" on \"Poll Period(seconds)\" property ,it should mean that the adapter gets json file one-time every five seconds.But it only get json file one time. Why !! Please help me , thanks.", "views": "348", "answers": 4, "author": "Ango Tsai", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-10-11 23:54:00", "resolve": "", "uid": "43.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3436901", "text": "Hello,It looks like this functionality is not working. I tried finding a workaround by using the dynamicPath loading instead of dynamicFile but neither works.I stepped through the issue with a debugger and I could see that it was in fact polling the file every five seconds. It was reading in the new data but then it is failing to send the data to ESP.The same works with the CSV File Input adapter so the problem appears to be limited to the JSON File Input Adapter.So I have logged a number of bugs:748735 - dynamicFile polling does not work for JSON File Input Adapter748732 - dynamicPath file polling does not work for JSON File Input Adapter(If a file matching the expression does not exist when the adapter starts, it goes to the DEAD state and never attempts to poll for another matching file again).748041 - File JSON Input Adapter throws JSONException on large JSON files(I'm not sure if this is a bug or a limitation on the size of JSON files or a configuration issue. Just wanted to mention this one as a heads up in case you run into it too).If you need a fix for this urgently, I would recommend opening a technical support case/message so that we can prioritize these issues with engineering.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON adapter Poll Period not work", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "43.2", "author": "Ango Tsai", "url": "http://scn.sap.com/thread/3436901", "text": "Hi Neal Thanks for your reply , I want to know how long to fix these bugs in general ? Thanks .", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON adapter Poll Period not work", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "43.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3436901", "text": "Hi Ango,I'm sorry that you have hit some bugs here - we will certainly get them resolved. How long it takes to deliver bug fixes depends on the nature of the fix and the situation. If there is no urgency, they will be fixed in a future release. For critical bugs that are affecting a production system or holding up deployment, we can look into an emergency fix.If this is urgent and important for you, let us know. If you are a customer, you should open a support ticket and be sure the support team understands the urgency.If you are internal to SAP and this is urgent for a project you are working on, please get in touch with me directly.Regards,Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON adapter Poll Period not work", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "43.4", "author": "Ango Tsai", "url": "http://scn.sap.com/thread/3436901", "text": "Hi Jeff I'm not urget for it. Okay, I'm waiting for SP4 and hope these bugs could be solved. Thank you for reply.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON adapter Poll Period not work", "type": "answer", "tags": "N/A"},
{"date_time": "2013-10-17 10:33:00", "resolve": false, "uid": "44", "title": "Idea for SMS(Short Message Service) sending ?", "url": "http://scn.sap.com/thread/3439668", "text": "Hi experts. If I want to send SMS through output adapter, which adapter is suitable ?use WebSerivce ? or Custom adapter ?Does any expert can provide me any ideas ? Thanks .", "views": "418", "answers": 1, "author": "Ango Tsai", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-10-17 11:55:00", "resolve": "", "uid": "44.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3439668", "text": "Hi,Maybe it is possible to use the smtp output adapter and send it to an email gateway for SMS of the provider.Found these links for example:http://en.wikipedia.org/wiki/List_of_SMS_gatewayshttp://www.notepage.net/smtp.htm http://www.codeproject.com/Articles/387567/How-to-send-an-SMS-message-from-an-applicationhttp://codeglobe.blogspot.com/2009/02/sending-sms-in-cnet-using-gsm-modem-and.htmlBen", "views": "N/A", "answers": "N/A", "upvotes": 2, "title": "Re:Idea for SMS(Short Message Service) sending ?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-10-17 12:20:00", "resolve": false, "uid": "45", "title": "Monitor status is incorrect ?", "url": "http://scn.sap.com/thread/3439739", "text": "Hi experts. It seems not correct of the row state that output adapter uses the \"File JSON Output\".I make sure the data be written in JSON File successful, and create many rows in it. But it always display zero on each row status. You can check the below picture.thanks.", "views": "325", "answers": 3, "author": "Ango Tsai", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-10-17 14:54:00", "resolve": "", "uid": "45.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3439739", "text": "Hello,Funny you should ask, I was looking into this yesterday for two of the other new adapters (File CSV Output and Socket CSV Output) and saw the same thing.Based on the documentation, I think this behavior is correct. You are looking at the \"_ESP_Connectors\" stream. The documentation states that this stream shows information about all internal adapters: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01611.0513/doc/html/skh1299701522362.htmlIn ESP 5.1 SP03 most of the old internal adapters (CSV, XML, etc.) were deprecated and replaced with new external ones. You can see here which are internal and which are external: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01615.0513/doc/html/cgo1313277363861.htmlI expect that we should see statistics for external adapters in the _ESP_Adapter_Statistics stream but I am not seeing them there either so I don't know if I have something misconfigured or not.I will be investigating further today and will update you with my findings.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Monitor status is incorrect ?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "45.2", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3439739", "text": "Hello,Thanks for reporting this issue. I have logged the following bug for our engineering department: 749085 - Toolkit output adapters do not report statistics to _ESP_Adapter_StatisticsThis issue appears to be limited to output adapters. If you use an input adapter and subscribe to the _ESP_Adapter_Statistics metadata stream, you will see the counts incremented.To subscribe to the _ESP_Adapter_Statistics metadata stream, click on the \"funnel\" icon while using the StreamViewer:This will expose the metadata streams and then you can double click on \"Adapter_Statistics\".A bit of good news...I tested the fix for the \"dynamicMode = dynamicPath/dynamicFile\" issue you reported today and it looks good so it should be available in ESP 5.1 SP04.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Monitor status is incorrect ?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "45.3", "author": "Ango Tsai", "url": "http://scn.sap.com/thread/3439739", "text": "Hi Neal Wow, the \"funnel\" is a good way to monitor statistics.It can appear more information to monitor. Thank your information.I'm looking forword to ESP 5.1 SP04 coming !Thanks.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Monitor status is incorrect ?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-10-24 00:11:00", "resolve": false, "uid": "46", "title": "Problem - creating Input-Adapter for CSV-Files", "url": "http://scn.sap.com/thread/3443254", "text": "Hello to all,i actually write my bachelor-thesis about CEP in the context of event driven architecture. Now ill evaluate SAP Sybase and try to bring my own experience into my thesis. Ive just download and installed the Free Trail ESP for evaluation. Ill try to become an overview with the Hans-on Tutorial (Building a simple SAP Sybase) but there are one little problem. At first i created a project like the tutorial, so far so good. At the second step it stoped. I should create an Input-Adapter for a CSV-File, but it doesnt work. I checked all pathes and Values and recognized that there are some differences between the picture at the tutorial an my picture on screen.The picture at the tutorial has some more fields like my own one, and if i try to save the directory-path like the tutorial, the system say always - Error: Values must be supplied for all required properties. But in my hands-on tutorial are no other pathes written. Where are my mistake? I hope someone can help me. Thank you.Regards, Peter", "views": "365", "answers": 1, "author": "Peter Kothe", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-10-24 18:07:00", "resolve": "", "uid": "46.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3443254", "text": "Hi Peter, and welcome to ESP. Sorry you hit this snag - not sure why it's happening, but here's what's happening: you need to enter a file name for the File property. The properties in red are the required properties. So just enter a file name there and you'll be good to go. I'll have to look into what changed between the last version and the latest version. In the last version (for which the tutorial was prepared), you could leave the File property blank - at this stage, and then when you use Schema Discovery, and select your source, it would fill in the file property for you. The file property must be set to compile successfully, since it is a required property. So not sure why that changed in this release - thanks for pointing it out, and sorry it led to some frustruation. We'll get the tutorial updated (unless we determine that it should be working like before - allowing you to leave the File property blank at this stage).Regards,Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem - creating Input-Adapter for CSV-Files", "type": "answer", "tags": "N/A"},
{"date_time": "2013-10-23 15:18:00", "resolve": false, "uid": "47", "title": "Sybase Replication Server Adapter and transactionnal consistency", "url": "http://scn.sap.com/thread/3442927", "text": "Hello,The doc says that transactional consistency is not guaranteed.Does it mean that if 100 rows are inserted in one transaction at the source, the ESP could display incorrect intermediate results while all the rows have not been consumed ?Thanks.Remi.", "views": "348", "answers": 1, "author": "Remi ASTIER", "upvotes": 0, "type": "question", "tags": "server.sybase.adapter.replication.esp"},
{"date_time": "2013-10-25 21:59:00", "resolve": "", "uid": "47.1", "author": "Mike Weadley", "url": "http://scn.sap.com/thread/3442927", "text": "Hi Remi,Yes, the warning is regarding display of intermediate results in ESP: there are cases where the intermediate results in ESP might differ from what would be seen if replicating to a relational database like HANA or Sybase ASE.If the source transaction is composed of 100 INSERTs on one table, and if Replication Server and the Replication Server Adapter are configured to pass transactions all the way through to ESP, then the corresponding ESP window will stay in sync with the source transaction, and will not display intermediate results. The possibility of display of intermediate results arises when replicating tables that appear within transactions that span multiple tables; or when Rep Server and ESP are configured to use batch loading into ESP. So whether an ESP application will display intermediate results depends on the configuration of Replication Server and the Replication Server Adapter, as well as the composition of the transactions on the source system. Not all ESP applications will display intermediate results when replication is used; and the display of intermediate results may or may not effect the ESP application logic. If intermediate results causes an issue or cannot be tolerated due to the business logic, a good alternative is to: a) replicate data to a database like SAP HANA (thus maintaining transactional consistency), and then b) have your ESP application read the data from the database.Hope this helps,Mike Weadley", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Sybase Replication Server Adapter and transactionnal consistency", "type": "answer", "tags": "N/A"},
{"date_time": "2013-10-31 14:50:00", "resolve": false, "uid": "48", "title": "Transporter in ESP Adapter Toolkit", "url": "http://scn.sap.com/thread/3447600", "text": "Dear ESP Experts,We are currently building an ESP Input Adapter for receiving JSON-encoded data using a REST service. In our scenario, the adapter is connected to multiple input streams with different schemas. So for we have implemented a new ESP Transporter for the JSON-REST part and we have successfully integrated the new adapter in ESP Studio. Upon receiving a JSON-encoded message, the transporter module discovers the schemas of the connected input streams and their name, after which it creates an Aep record with a specified target stream.While we have successfully run the new adapter using the command line, we did not find any way of using ESP Studio for connecting the adapter to multiple input streams. Is there a way of specifying in CCL that an input adapter is connected to multiple input streams?Best regards,Florian", "views": "343", "answers": 2, "author": "Alexandru-Florian Antonescu", "upvotes": 0, "type": "question", "tags": "multi_stream:publisher"},
{"date_time": "2013-10-31 15:34:00", "resolve": "", "uid": "48.1", "author": "Mike Weadley", "url": "http://scn.sap.com/thread/3447600", "text": "Hi Florian,My understanding is that the Visual Editor and CCL editor will only allow a defined link between an adapter and one input stream or window. I believe a multi-stream publisher can still run in managed mode (started and stopped by ESP server) and publish to multiple streams, but the link from the adapter to all the streams will not be captured in the CCL itself. I will try to test this later today.I am interested in your REST adapter use case and plans. Can you tell us more about it?Mike", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Transporter in ESP Adapter Toolkit", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "48.2", "author": "Mike Weadley", "url": "http://scn.sap.com/thread/3447600", "text": "Hi Florian,I was able to confirm that a toolkit-based adapter using a multi-stream publisher running in managed mode can publish to multiple streams. As you noted, the CCL and Visual Editor will show the adapter connected to just one stream or window:But at runtime I was able to publish to both isAllTypes and iwAllTypes:Best Regards,Mike Weadley", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Transporter in ESP Adapter Toolkit", "type": "answer", "tags": "N/A"},
{"date_time": "2013-11-05 22:42:00", "resolve": false, "uid": "49", "title": "Multibyte characters failing in SybaseCEP Studio Version 4.0.0", "url": "http://scn.sap.com/thread/3449578", "text": "Hello,I am running SybaseCEP Studio Version 4.0.0. I have several projects that are receiving customer entered data, and then it inserts that data to a SQL server. In the event stream the Japanese character data appears as boxes, and if I copy and paste Japanese characters from the site into the project work space it pastes in as characters. The SQL DB receives incorrect characters as well. The SQL columns are defined as nvarchar and the source that is feeding SybaseCEP appears to be passing along the Japanese characters faithfully, but SybaseCEP does not seem to be able to represent the characters correctly.Is there a setting somewhere in SybaseCEP that I have to set in order to enable multibyte characters in the studio / windows / event stream?", "views": "370", "answers": 2, "author": "Richard Houchin", "upvotes": 0, "type": "question", "tags": "cep.utf-8.multibyte"},
{"date_time": "2013-11-06 18:43:00", "resolve": "", "uid": "49.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3449578", "text": "Hello,It does not look like the Sybase CEP interface to remote databases via ODBC supports multibyte characters. I found an old outstanding Coral8 bug requesting the same functionality.Also, I know the manual input function of Sybase CEP Studio does not support multibyte: 629160 - Studio Send Rows dialog box does not support utf8Internally, Sybase CEP does support multibyte characters. As a test, I have a \"ReadFromCsvFileAdapterType\" read Japanese data from a file and then a \"WriteToCsvFileAdapterType\" write data to a second file. The data looks the same coming out as it went in.I was able to write to a database by attaching the JDBC Output Adapter:http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01030.0400/doc/html/asc1252676972735.html 1.) Set your environment variables as appropriate: D:\\CEP_R4>type sybase.bat set PATH=D:\\CEP_R4\\Sybasec8\\server\\bin;%PATH% set CLASSPATH=D:\\Sybase\\jConnect-7_0\\classes\\jconn4.jar;D:\\CEP_R4\\SybaseC8\\server\\sdk\\java5\\c8-sdk-java5.jar;D:\\CEP_R4\\SybaseC8\\server\\adapters\\c8-adapters.jar set SYBASE_C8=D:\\CEP_R4\\SybaseC8 2.) Create a SQL query to insert the data: C:\\temp>type insert.sql insert into t1 values (?ColumnName) 3.) Run the JDBC Output Adapter: C:\\temp>typet c8_jdbc_output.bat java com.sybase.c8.adapter.JDBCOutputAdapter --queryFile=insert.sql --db-username=RAP_USER --db-password=rap_pwd --databaseURL=jdbc:sybase:Tds:server.acme.com:5000 --streamUrl=ccl://localhost:6789/Stream/Default/Database_write_test/MyOutWindow --driver=com.sybase.jdbc4.jdbc.SybDriver", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Multibyte characters failing in SybaseCEP Studio Version 4.0.0", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "49.2", "author": "Richard Houchin", "url": "http://scn.sap.com/thread/3449578", "text": "Thank you! This looks reasonable and I'll give it a shot soon and let you know if it works out.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Multibyte characters failing in SybaseCEP Studio Version 4.0.0", "type": "answer", "tags": "N/A"},
{"date_time": "2013-11-25 13:10:00", "resolve": false, "uid": "50", "title": "How can I change default timezone of Studio?", "url": "http://scn.sap.com/thread/3460016", "text": "Hi,I guess I have a problem with the default timezone value of ESP studio. Let me explain my problem.I get data from a ASE database with generic database input adapter. There are 4 rows in the table. There are two datetime colums in the table.I am seeing wrong datetime values on the Stream View of Run-Test Perspective of Studio. When I select the window data from SQL Query, I can see the exact values. There are two hour difference between the time values. You can see the following pic.I am thinking that the reason of the display problem is timezone. My current time zone is GMT+2 (Europe/Istanbul). So, how can I change the default timezone of the Studio so that I can see the correct datetime values in Stream View?Thanks.Bulut", "views": "406", "answers": 3, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-11-25 17:06:00", "resolve": "", "uid": "50.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3460016", "text": "Hello,ESP stores dates internally as UTC: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01621.0513/doc/html/emc1299598311064.htmlBy default, Stream Viewer displays the time converted to your local time zone.There is an option for Studio's Manual Input and Stream Viewer feature to interpret/display UTC or local time zone: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01613.0513/doc/html/swa1301926290959.htmlIf you toggle this option, you should see the date/time display between Stream Viewer and SQL Query consistently. Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How can I change default timezone of Studio?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "50.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3460016", "text": "Hello Neal,Thanks for the reply. interpret/display UTC or local time zone toggle solved my problem. I can see date/time display between Stream Viewer and SQL Query consistently.But, still I have related problem. I am trying to use Generic DB input and RepServer adapter together. Generic DB Input loads data from my ASE into ESP Server and RS adapter collects transactions. Generic DB input adapter loads date/time correctly. But RS adapter loads date/time colums two hours before.The rows in the green box are from RS adapter. The rows from red box are from DB adapter. 14th rows are identical, but RS adapter 3rd and 4th colums (pgEnter, pgExit) are datetime columns and seem different. The select query of the table as below:I could not find the reason of the problem. Do you have any idea? How can I solve this problem.Thanks a lot.Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How can I change default timezone of Studio?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "50.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3460016", "text": "Hello,I am afraid I do not see the same behavior.After changing the configuration parameter in Studio, did you close the Stream Viewer and reopen it? It does not seem to take affect on data that is already in the Sream Viewer. It only applies to new data as it arrives.I inserted a row of data to ASE:1> insert into repserver_example values (1,'abc',current_bigdatetime(), 1.2345)2> select current_bigdatetime()3> go(1 row affected)  ----------------------------------  Nov 25 2013 12:55:58.171349PMIf you edit $ESP_HOME/adapters/repserver/config/log4j.properties and change all of the \"INFO\" to \"DEBUG\" logging levels, you can watch your project's \"repserveradapter.log\" and see the data as it arrives to the ESP Replication Server Adapter. You should see Replication Server send literal insert statements like this:11-25-2013 18:27:50.610 DEBUG [Thread-1] (TdsSrv.handleLanguage) Invoking SQL Parser for Lang command: begin transaction ; insert into repserver_example (c1, c2, c3, c4) values (1, 'abc ', '20131125 12:55:58.147393', 1.2345000505447388)11-25-2013 18:27:50.611 DEBUG [Thread-1] (TdsSrv.handleLanguage) statement: begin transaction ; insert into repserver_example (c1, c2, c3, c4) values (1, 'abc ', '20131125 12:55:58.147393', 1.2345000505447388)So I created two projects. First I ran with Studio's \"UTC\" configuration parameter unchecked. Both the Replication Server Adapter and the Generic DB Input Adapter displayed the date the same:Then I inserted a second row of data and ran with \"UTC\" configuration parameter checked:1> insert into repserver_example values (2,'def',current_bigdatetime(), 2.2345)2> select current_bigdatetime()3> go(1 row affected)  ----------------------------------  Nov 25 2013 1:00:02.450888PMAgain, both display the same date:", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How can I change default timezone of Studio?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-11-29 11:24:00", "resolve": true, "uid": "51", "title": "How to integrate complex event processing logic (C++)", "url": "http://scn.sap.com/thread/3462748", "text": "Hello,I am considering the following scenario: I get 2-3 digital images of approx 1-1.5 MByte from machines on a shop floor every 15-30s that I have to analyze with image processing algorithms within 5-10s. I am thinking of building the corresponding application with ESP and to integrate my special purpose image processing algorithm, written in C++, as a processing engine. Looking at the documentation I learned about custom adapters that seem the right way to go.Is this correct? Can anybody report on his or her experiences with such an approach?Thank you,Andreas", "views": "391", "answers": 1, "author": "Andreas Cardeneo", "upvotes": 1, "type": "question", "tags": "sap_sybase_event_stream_processor.adapter.esp_developer.esp_howto"},
{"date_time": "2013-12-02 18:38:00", "resolve": "solution", "uid": "51.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3462748", "text": "Actually, based on your description, I think you should take a look at the interface for integrating external functions: User-Defined External FunctionsThe adapter interface is how to stream data into an ESP project and/or subscribe to streaming output from an ESP project. But the external UDF interface is designed to let you invoke external C++ functions - and then the returned result can be used in your ESP project to determine further processing, output event, etc", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to integrate complex event processing logic (C++)", "type": "answer", "tags": "N/A"},
{"date_time": "2013-12-02 09:30:00", "resolve": true, "uid": "52", "title": "Unable to find Schema Discovery while adding input adapters", "url": "http://scn.sap.com/thread/3463105", "text": "Hello,While adding File CSV input adapter i can not find the schema discovery button as it should be on the adapter toolbar. Moreover, while editing the properties of the adapter it is not just asking for the directory containing the data files but specific file name as well.(screenshot attached).The only problem i can see in the error log is \"The i18N configuration path could not be determined - please ensure that the ESP_HOME environment variable is properly setFailed to read server's response: Connection refused: connect\"Can this be the reason? though i've tried adding ESP_HOME manually, but it didn't help.I've downloaded the 30 day trial version from http://scn.sap.com/community/developer-center/sybase-esp and using it to build the towermon project as discribed in the tutorial.Regards,Sarim", "views": "428", "answers": 3, "author": "Mohammad Sarim Khan", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-12-05 20:31:00", "resolve": "solution", "uid": "52.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3463105", "text": "Hello,Yes the tutorial you reference is slightly out of date. The directory and the file name are required for discovery to work.The missing discovery button is related to ESP_HOME not being set prior to starting ESP. I see the same behavior if I open a DOS command prompt and type \"set ESP_HOME=\" and then invoke ESP Studio (%ESP_HOME%\\studio\\esp_studio.exe).Are you sure that ESP_HOME was set properly prior to starting Studio?If you open a DOS command prompt and type \"set ESP\", does it show that it is set?If you type \"dir %ESP_HOME%\" does the directory display properly?If these first two steps confirm that the environment variable is set properly, can you try invoking Studio from the same command prompt by typing \"%ESP_HOME%\\studio\\esp_studio.exe\"?Do you see any errors on the DOS console when invoking Studio this way?If this doesn't help, let us know. Maybe tell us what version of Windows you are running.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unable to find Schema Discovery while adding input adapters", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "52.2", "author": "Mohammad Sarim Khan", "url": "http://scn.sap.com/thread/3463105", "text": "Hello Neal,Thanks a lot for taking this question.I was able to get the schema discovery button once i envoked the studio from command prompt as you said.It would be really helpful if the tutorial could be updated.Regards,Sarim", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unable to find Schema Discovery while adding input adapters", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "52.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3463105", "text": "Yes, we will be updating the tutorial in the next week or so. My apologies that this was previously overlooked and caused you to lose time trying to understand the problem.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unable to find Schema Discovery while adding input adapters", "type": "answer", "tags": "N/A"},
{"date_time": "2013-12-22 12:06:00", "resolve": true, "uid": "53", "title": "File XML Input values help", "url": "http://scn.sap.com/thread/3474177", "text": "Hi Folks,Using the evaluation version (5.1 SP03) I am trying to follow Building a simple project in the Sybase online for ESP (my_portfolio_valuation) SyBooks OnlineHowever, I am struggling to input values for File XML Input adapter; the documentation is older I believe.In this adapter the File, Row Expression and Column Expression are mandatory. I am not sure how to supply the Row Expression and Column Expression List values and there are no examples in the books online. I went on and tried to supply the values as per the screenshot. It saved ok but the schema discovery results in an error message \"Sorry, this adapter is undiscoverable\". I have googled to see if someone else have encountered the problem but I have not managed to resolve it.Perhaps the syntax for XPath expressions for Row and Columns is incorrect. I also wonder how I can choose to \"not\" specify the file name and upon schema discovery access the wizard like shown in the video tutorials.Please help as I feel stuck and unable to move on and have spent significant time on this without learning much.Merry Christmas.Pawan", "views": "536", "answers": 3, "author": "Pawan Sharma", "upvotes": 0, "type": "question", "tags": "esp_5.1.esp_tutorial.file_xml_input"},
{"date_time": "2013-12-23 16:47:00", "resolve": "", "uid": "53.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3474177", "text": "Hi Pawan,You can find examples on this adapter under%ESP_HOME%/adapters/framework/instances/file_xml_doc_input If you check the adapter_config.xml file you should get an idea of what your elementRowmapping and Columnmapping should be. If you still have difficulties then send us a sample of your xml input we should be able to send you the information on what you column expression and rows expression should be. Please note there is a issue with ESP 5.1 SP03 when using very long xml files which has been rectified in ESP 5.1 SP04. However if you are trying with a small xml file there shouldn't be any issues. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File XML Input values help", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "53.2", "author": "Pawan Sharma", "url": "http://scn.sap.com/thread/3474177", "text": "Hi Geetha,There doesn't seem to be a clearcut example of the values in the adapter_config.xml under the path you mentioned, however, under subfolder datetimeExample/bin I see an another adapter_config.xml which I took as a reference. Unfortunately, I still can't get it to work and continue to receive the error \"Sorry, this adapter is undiscoverable\".Here is what the input positions.xml looks like<Positions ESP_OPS=\"i\" BookId=\"Book1\" Symbol=\"MSFT\" SharesHeld=\"3000\"/><Positions ESP_OPS=\"i\" BookId=\"Book1\" Symbol=\"IBM\" SharesHeld=\"700\"/><Positions ESP_OPS=\"i\" BookId=\"Book2\" Symbol=\"MSFT\" SharesHeld=\"1000\"/>Here is what I have put in the UI properties dialog for File_XML_Input adapter (Screenshot was in the previous thread), so showing the text view below.ATTACH INPUT ADAPTER File_XML_Input1 TYPE toolkit_file_xmldoc_input PROPERTIES dir ='C:/Users/Administrator/My Documents/SybaseESP/5.1/workspace/exampledata' ,file = 'positions.xml' ,xmlElemMappingRowPattern = '/Positions' ,espColumnPattern = '/Positions/@ESP_OPS,/Positions/@BookId,/Positions/@Symbol,/Positions/@SharesHeld' ;ThanksPawan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File XML Input values help", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "53.3", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3474177", "text": "Hi Pawan,There are 2 types of xml input adapter in ESP the file xml event adapter and the file xml doc input adapter. The file xml event adapter works with xml input files like these <Positions ESP_OPS=\"i\" BookId=\"Book1\" Symbol=\"MSFT\" SharesHeld=\"3000\"/><Positions ESP_OPS=\"i\" BookId=\"Book1\" Symbol=\"IBM\" SharesHeld=\"700\"/><Positions ESP_OPS=\"i\" BookId=\"Book2\" Symbol=\"MSFT\" SharesHeld=\"1000\"/>whereas the file xml doc input works with document structured xml like the one you saw under the %ESP_HOME%/adapters/framework/instances/file_xmldoc_input/datetimeExample/data/data_1.xmlI believe you are using the wrong adapter for the wrong type of xml file.Please see attached picture you need to use the file xml record or list input adapter. If you want schema discovery to work you may need to remove the unwanted properties and keep only the directory and file property.http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01615.0513/doc/html/cgo1374509102803.htmlCREATE INPUT WINDOW Positions SCHEMA ( Symbol string , SharesHeld integer , BookId string ) PRIMARY KEY ( Symbol ) ;ATTACH INPUT ADAPTER File_Event_XML_Input1 TYPE toolkit_file_xmllist_input TO Positions PROPERTIES dir = 'C:/temp' ,file = 'test.xml' ; If you see %ESP_HOME%/adapter/framework/instances folder you will see different subfolder file_xmldoc_input and file_xmllist_input. The file_xmldoc_input is meant for document structured xml. The file_xmllist_input is more of ESP formatted xml as you can see the positions xmlfile has the stream name and the esp opcode that is needed for the input. Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File XML Input values help", "type": "answer", "tags": "N/A"},
{"date_time": "2014-01-23 14:25:00", "resolve": false, "uid": "54", "title": "How to use ESP with GIT/GERRIT", "url": "http://scn.sap.com/thread/3489102", "text": "Hello,is there a way to install a GIT/GERRIT plugin in ESP? Or do we have to use an external tool? I have found documentation how to add an existing plugin to an ESP project. However I did not find a way to install a plugin.Thanks,Silvana", "views": "451", "answers": 1, "author": "Silvana Straus", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-01-24 17:09:00", "resolve": "", "uid": "54.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3489102", "text": "Hi Silvana - just wanted to let you know we are looking into this; will get you some information soon.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to use ESP with GIT/GERRIT", "type": "answer", "tags": "N/A"},
{"date_time": "2014-01-28 17:54:00", "resolve": true, "uid": "55", "title": "How to read files using ReadFromRegexFileAdapterType?", "url": "http://scn.sap.com/thread/3491989", "text": "Hello,are there examples on how to use ReadFromRegexFileAdapterType in ESP Version: 5.1.04.00/20131119.1/SP04? Is it supported in that release?Thanks,Hristina", "views": "787", "answers": 9, "author": "Hristina Dinkova", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-01-28 18:08:00", "resolve": "", "uid": "55.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3491989", "text": "Hello,I think you are looking at an adapter provided with a different product named \"Sybase CEP\": Regular Expressions: Read From File Using a Regular Expression Adapter.The list of adapters available with ESP can be found in a different documentation set here: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01615.0514/doc/html/cgo1294857663390.htmlThere isn't an adapter that has the exact same functionality as the one you are referring to in Sybase CEP. There are several file input adapters that are available in ESP. You could read the file into an input stream and then apply a filter in a WHERE clause: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01621.0514/doc/html/emc1302203026193.htmlThere are also built-in regular expression functions that you can use.Let us know if you need more information.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "55.2", "author": "Hristina Dinkova", "url": "http://scn.sap.com/thread/3491989", "text": "Hi Neal,Thanks for your answer. Which file adapter do you recommend to read a whole line from a file as a string? Currently we use \"dsv_in\" but is requires a delimiter. When a delimiter value is not specified the adapter defaults to ','.Best regards,Hristina", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "55.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3491989", "text": "Hello,Can you provide a sample of what you data looks like? Is this data coming from some kind of log file?Can you give us more of the \"big picture\" in what you are trying to accomplish?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "55.4", "author": "Hristina Dinkova", "url": "http://scn.sap.com/thread/3491989", "text": "Hi Neal,Yes, I'm trying to read a log file. Here are several lines from the file I'm working with:<!--LOGHEADER[START]/--><!--HELP[Manual modification of the header may cause parsing problem!]/--><!--LOGGINGVERSION[2.0.7.1006]/--><!--NAME[./log/system/httpaccess/responses_00.trc]/--><!--PATTERN[responses_00.trc]/--><!--FORMATTER[com.sap.tc.logging.TraceFormatter([%25d] - %m)]/--><!--ENCODING[UTF8]/--><!--FILESET[0, 5, 10485760]/--><!--PREVIOUSFILE[responses_00.4.trc]/--><!--NEXTFILE[responses_00.1.trc]/--><!--LOGHEADER[END]/-->[Dec 3, 2009 8:54:48 AM ] - 127.0.0.1 : GET / HTTP/1.1 302 0[Dec 3, 2009 8:55:04 AM ] - 127.0.0.1 : GET /index.jsp HTTP/1.1 302 1715[Dec 3, 2009 8:55:04 AM ] - 127.0.0.1 : GET /startPage HTTP/1.1 200 2386[Dec 3, 2009 8:55:04 AM ] - 127.0.0.1 : GET /css/shared.css HTTP/1.1 200 0[Dec 3, 2009 8:55:04 AM ] - 127.0.0.1 : GET /css/graphics/icons/J2EE_Header.jpg HTTP/1.1 200 0[Dec 3, 2009 8:55:04 AM ] - 127.0.0.1 : GET /css/graphics/icons/welle.jpg HTTP/1.1 200 0[Dec 3, 2009 8:55:04 AM ] - 127.0.0.1 : GET /css/graphics/icons/sap.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/5_docs.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/caliper.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/clipboard.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/2_servers.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/3_people.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/activities.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/package_2puzzlepieces.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/NewspaperMagnifier.gif HTTP/1.1 200 0[Dec 3, 2009 8:55:05 AM ] - 127.0.0.1 : GET /css/graphics/picto/EarthCoffeebean.gif HTTP/1.1 200 0[Dec 3, 2009 8:56:23 AM ] - 127.0.0.1 : GET /nwa HTTP/1.1 302 1853Concerning the \"big picture\" => ideally we should be able to deal with different log files (not only HTTP server logs but also syslog etc.) and we would like to have the solution easily configurable.That is why we wanted to know the options to use the ReadFromRegexFileAdapterType.We had a look at the logfile adapter example as well => in the example file the field values have \" \" which is not our case. Can this adapter deal with fields without \" \"?We consider also the possibility to create a new adapter based on the sample adapter example => here we do not know for performance to ecpect compared to the above mentioned adapters.Thanks in advance for your answer,Hristina", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "55.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3491989", "text": "Hello,I think the Log File Adapter is probably what you want to use: Log File Input AdapterAllthough the example in %ESP_HOME%\\adapters\\logfile_input contains quotes around the columns, they are not necessary. I've used this adapter to read an Apache Tomcat log previously (the tricky part for me was getting the date format correct). The advantage to using this adapter is that it does most of the column parsing for you.You can use the CSV Input adapter to read in a file containing a single line by telling it to use a CSV delimiter that you know does not exist in your data. For example,I created a data file named \"oneline.txt\" that just contains one line of text on each line:line 1line 2 with more stuffline 3 with something elseline 4 and so onThen I used the following CCL with a delimiter '~!#' that I know will never be in my data:// Using a window here so it is easier to see the results.// A stream is probably more appropriate because a single string is not likely a good key value CREATE INPUT WINDOW SdkTest SCHEMA (C1 String) PRIMARY KEY (C1)KEEP ALL;ATTACH INPUT ADAPTER Adapter1 TYPE dsv_in TO SdkTest PROPERTIESexpectStreamNameOpcode = FALSE ,fieldCount =0 ,dir = 'C:/temp',file = 'oneline.txt',repeatCount = 0,repeatField = '-',delimiter = '~!#',hasHeader = FALSE,pollperiod = 0,safeOps = FALSE,skipDels = FALSE ,dateFormat = '%Y/%m/%d %H:%M:%S',timestampFormat = '%Y/%m/%d %H:%M:%S',blockSize =1;", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "55.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3491989", "text": "Hello,I worked up a \"properties\" file for the Log File Input Adapter that matches your log file along with a matching ESP project.It seems to work well. The adapter will throw parsing errors on the <!-- comment --> lines of your log file but then it parses and publishes all of the normal lines to the project.Is this log file from NetWeaver?I'll send you the example in an email since I am unable to attach it to the community forum.Hopefully this meets your requirements.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "55.7", "author": "Hristina Dinkova", "url": "http://scn.sap.com/thread/3491989", "text": "Hi Neal,Thanks for your response.Concerning your proposal for delimiter (in your post from Jan 29, 2014 4:52 PM) => I tried to use a delimiter which is longer than one character... the value is accepted but during its evaluation only the first character is taken... Some delimiters like '' cause compilation error. As a whole the workaround with delimiter is not a reliable solution...The log file which we try to process is the HTTP server log of Netweaver-Java.I tried to run the logfile-project which you sent me via e-mail. I receive the following error in the console: java.text.ParseException: Unparseable date: \"Dec 3, 2009 8:55:05 AM \" In parallel we go further with our tries to build own adapter using the provided sample adapter. We would appreciate further how-to tips from you. Currently we rely on http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.infocenter.dc01615.0514/doc/html/cas1342472077949.html and the README-files provided by the ESP-installation.Best regards,Hristina", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "55.8", "author": "Zbigniew Jerzak", "url": "http://scn.sap.com/thread/3491989", "text": "Hi Hristina,I have not seen the code Neal has sent you, but I know that SP04 had issues with passing custom date formats to input adapters. Hence I would bet on this to cause the issue. If Neal used earlier version of ESP it might have worked for him but will not work for you... AFAIK - the fix is on its way into SP08 (which is the next version following SP04).Cheers,", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "55.9", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3491989", "text": "Hello,You are getting the \"java.text.ParseException: Unparseable date\" exception because of a localization issue. I suspect you are running on a PC with German date localization (Go under Control Panel -> Region and Language -> Formats ). I was able to reproduce the exception when I changed my localization from English to German.The Log File Input Adapter currently parses dates using the machine's default localization. The dates in your log file are English. For example, \"Dec 3, 2009 8:55:05 AM\" would show as \"Dez 3, 2009 8:55:05 AM\" in German.So the adapter throws an \"Unparseable date\" exception because \"Dec\" is not valid in a German locale.I have filed a new feature request: 756716 - Log File Input Adapter localization supportThe purpose of this request would be to allow the user to specify the locale of the log file in the properties file and then parse dates in that locale rather than the machines default.You can test this by temporarily changing the locale of your machine to \"English\" or changing the date in the log file to use German abbreviations.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to read files using ReadFromRegexFileAdapterType?", "type": "answer", "tags": "N/A"},
{"date_time": "2013-10-18 05:43:00", "resolve": false, "uid": "56", "title": "JSON output format is invalid.", "url": "http://scn.sap.com/thread/3440132", "text": "Hi experts, Sorry, I find another issue about JSON output again.I think that is a importance issue. Look at below format , that is a output with JSON adapater. {\"CUSTOMER_ID\":1,\"SUBJECT_COLUMN\":\"Finance:1\"}{\"CUSTOMER_ID\":2,\"SUBJECT_COLUMN\":\"Finance:2\"}{\"CUSTOMER_ID\":3,\"SUBJECT_COLUMN\":\"Finance:3\"}Without separate symbol \"comma\" , it's a invaild JSON format. Thanks.", "views": "465", "answers": 7, "author": "Ango Tsai", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2013-10-18 15:43:00", "resolve": "", "uid": "56.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3440132", "text": "Hi,I went to the http://jsonlint.com/ site to see what the format needs to look like.Just adding a comma to separate them is not sufficient.I had to do this:[ { \"CUSTOMER_ID\": 1, \"SUBJECT_COLUMN\": \"Finance:1\" }, { \"CUSTOMER_ID\": 2, \"SUBJECT_COLUMN\": \"Finance:2\" }, { \"CUSTOMER_ID\": 3, \"SUBJECT_COLUMN\": \"Finance:3\" }]", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON output format is invalid.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "56.2", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3440132", "text": "Hi,Can you explain a little bit about what you are trying to accomplish?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON output format is invalid.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "56.3", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3440132", "text": "Hi,Just another pointer... The json file adapter does not seem to process null values properly.Here is the CR I opened for this same sometime back747738- toolkit file json input adapter does not take null for integer typesAlso the JSON output file adapter ignores null 747814-Null in field values skipped by JSON file output adapterThanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON output format is invalid.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "56.4", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3440132", "text": "Hello,I think those are valid JSON objects as per the JSON specification here: http://www.json.org/If you copy each individual object into this JSON validator, they will be valid: http://jsonlint.com/I think there is a problem between the JSON Input and Output Adapter. The JSON Input Adapter requires a \"rootPath\" whereas the JSON Output Adapter does not permit or create one. The JSON Output Adapter only appears to be able to create individual JSON objects.In order to make the JSON Input Adapter compatible with the JSON Output Adapter, I had to edit two files.1) Edit the JSON Input Adapter's \"cnxml configuration file\" (%ESP_HOME%\\lib\\adapters\\toolkit_file_json_input.cnxml). Change the \"jsonRootpath\" parameter to optional like this: <Parameter id=\"jsonRootpath\" label=\"JSON Root Path\" descr=\"Specify a rootpath for the JSON data.\" type=\"string\" use=\"optional\" />2) Edit the JSON Input Adapter's \"adapter configuration file\" (%ESP_HOME%\\adapters\\framework\\instances\\file_json_input\\adapter_config.xml). Make the rootPath parameter empty as follows (if it is not empty, the adapter appears to pick this up as a default value): <Module type=\"formatter\"> <InstanceName>MyJsonInFormatter</InstanceName> <Name>JsonStringToEspFormatter</Name> <Next>MyInStream_Publisher</Next> <Parameters> <JsonStringToEspFormatterParameters> <DateFormat>yyyy-MM-dd HH:mm:ss.SSS</DateFormat> <TimestampFormat>yyyy/MM/dd HH:mm:ss</TimestampFormat> <ColumnMappings> <ColsMapping streamname=\"\" rootpath=\"\"> <Column>display_text</Column> <Column>domain_role</Column> <Column>offset</Column> <Column>length</Column> </ColsMapping> </ColumnMappings> </JsonStringToEspFormatterParameters> </Parameters> </Module> 3) Restart Studio and restart your project. The JSON Input Adapter should now be able to read the file created by the JSON Output Adapter.I've logged a bug to correct this incompatibility: 748713 - JSON Input Adapter says jsonRootpath is required making it incompatible with output adapterI don't think it is proper to put a comma between individual JSON objects. If you have a different expected outcome, please describe the expected output and your use case in more detail.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON output format is invalid.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "56.5", "author": "Ango Tsai", "url": "http://scn.sap.com/thread/3440132", "text": "Hi In my case , my web page gets data from a JSON file that is generated by ESP(JSON output adapter).Because of the JSON file is invalid, the web page gets data failed. Current format for JSON output adapter as below:{\"CUSTOMER_ID\":1,\"SUBJECT_COLUMN\":\"Finance:1\"}{\"CUSTOMER_ID\":2,\"SUBJECT_COLUMN\":\"Finance:2\"}{\"CUSTOMER_ID\":3,\"SUBJECT_COLUMN\":\"Finance:3\"}Expect format for JSON output adapter as below:[{\"CUSTOMER_ID\":1,\"SUBJECT_COLUMN\":\"Finance:1\"},{\"CUSTOMER_ID\":2,\"SUBJECT_COLUMN\":\"Finance:2\"},{\"CUSTOMER_ID\":3,\"SUBJECT_COLUMN\":\"Finance:3\"}]Notes comma and square bracket . By the way , it's a better via value-parameter to set rootPath.Like this. if I set \"d.results\" for parameter, the output will be..{ \"d\": { \"results\":{\"CUSTOMER_ID\":1,\"SUBJECT_COLUMN\":\"Finance:1\"},{\"CUSTOMER_ID\":2,\"SUBJECT_COLUMN\":\"Finance:2\"},{\"CUSTOMER_ID\":3,\"SUBJECT_COLUMN\":\"Finance:3\"}]}}Thanks all for reply.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON output format is invalid.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "56.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3440132", "text": "Hello,I have logged another bug for the File JSON Output Adapter: 749269 - File JSON Output Adapter creates invalid JSON filesUnfortunately, I could not find a way to alter the various configuration files to force the Output adapter to format the file as you described.I will let you know as soon as I hear any news on these two CRs (749269 & 748713).Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON output format is invalid.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "56.7", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3440132", "text": "Hello,Engineering is evaluating 749269. Since ESP is designed to continuously process input events, engineering wanted to know what would signal the end of the input for your use case?In other words, how would ESP best know when to to write the closing ]}} in your situation? Would you stop the adapter? If the adapter were configurable to write a certain number of rows before writing the closing brackets? Or maybe if the adapter had not received rows after a certain period of time? Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:JSON output format is invalid.", "type": "answer", "tags": "N/A"},
{"date_time": "2014-02-17 13:39:00", "resolve": false, "uid": "57", "title": "Converting binary to integer/float", "url": "http://scn.sap.com/thread/3503693", "text": "Hello,I have a schema which contains a column with type binary. I am trying to convert that binary ti integer/float. How can I do that using SPLASH. I am able to convert the binary to hexstring, using hex_string function, but not able to find out how to convert the same to integer or float.Thanks & Regards,Gaurav SinghI072389+91-9538218550", "views": "422", "answers": 1, "author": "Gaurav Singh", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-02-17 15:06:00", "resolve": "", "uid": "57.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3503693", "text": "Hi,Is that binary column a single integer or float value or does it contain something else?If you convert it to string first then you can convert it in the next step with the to_integer() or to_float() etc.. functions.With a more complex encoding you might have to extract() it first.Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Converting binary to integer/float", "type": "answer", "tags": "N/A"},
{"date_time": "2014-02-18 11:53:00", "resolve": false, "uid": "58", "title": "Reference Table Queries", "url": "http://scn.sap.com/thread/3504309", "text": "Hello,I have created a project with a reference table query. I have installed HANA ODBC client and it works perfectly with another project which has HANA Output Adapter.The CCL file contains :CREATE INPUT STREAM recieverSCHEMA (id integer, pos integer, datatype string);CREATE REFERENCE maptabRef SCHEMA (id integer, pos integer, datatype string)PROPERTIES service='ND7ODBCService',source='maptaba', sourceSchema='M2M';CREATE OUTPUT STREAM outputStreamSCHEMA (id integer, pos integer, datatype string)AS SELECT maptabRef.id, maptabRef.pos, maptabRef.datatypeFROM reciever, maptabRefWHERE reciever.pos = maptabRef.pos;But when I am trying to run the same it gives following error:Failed call to:http://localhost:56105/RPC2 (Failed to read server's response: Connection refused: connect)Can somebody tell what could be the reason for this.Thanks,Gaurav Singh", "views": "577", "answers": 6, "author": "Gaurav Singh", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-02-18 14:24:00", "resolve": "", "uid": "58.1", "author": "Mike Weadley", "url": "http://scn.sap.com/thread/3504309", "text": "Hi Gaurav,Will you please describe how you are trying to run the project? Where are you deploying from, and where to? When you say \"it gives the following error\", is that a message you are seeing in an ESP Studio dialog, or is it appearing elsewhere?Errors like these can occur when you deploy a project from one machine to a remote machine whose ESP node configuration file HOSTNAME macro is set to localhost. Parts of the deployment will work, but other parts will fail due to the HOSTNAME setting. Can you find the stdstreams and esp_server.log file of the project you ran and attach them to this thread?Mike", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Reference Table Queries", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "58.2", "author": "Gaurav Singh", "url": "http://scn.sap.com/thread/3504309", "text": "Hello Mike,I am running the project in SYBASE ESP Studio and the error comes in a pop up window. In my localnode.xml the hostname is configured as follows:<Macro name=\"ESP_HOSTNAME\">localhost</Macro>And in node1.xml the same is configured as follows:<Macro name=\"ESP_HOSTNAME\">INLN50800330A</Macro>And the log file is as follows:2014-02-18 20:44:26.313 | 8592 | container | [SP-1-135021] (0.002) sp(5084) Platform::main() -- REVISION <ESP 5.1.04.00>, start timestamp (gmt): 02/18/2014 20:44:262014-02-18 20:44:26.313 | 8592 | container | [SP-3-100005] (0.002) sp(5084) ------ License check started ------2014-02-18 20:44:26.602 | 8592 | container | [SP-3-100005] (0.291) sp(5084) ------ License check succeeded ------2014-02-18 20:44:26.603 | 8592 | container | [SP-1-135036] (0.292) sp(5084) Platform::main() -- Starting initialization sequence.2014-02-18 20:44:28.491 | 8592 | container | [SP-2-722005] (2.180) sp(5084) Associating connection to application2014-02-18 20:44:28.495 | 8592 | container | [SP-2-722007] (2.184) sp(5084) Application successfully associated with connection2014-02-18 20:44:28.495 | 8592 | container | [SP-2-722008] (2.184) sp(5084) Attempting to register application with cluster2014-02-18 20:44:28.498 | 8592 | container | [SP-2-722011] (2.187) sp(5084) Application successfully registered2014-02-18 20:44:28.498 | 8592 | container | [SP-2-722023] (2.187) sp(5084) The application successfully registered2014-02-18 20:44:28.498 | 8592 | container | [SP-2-722025] (2.187) sp(5084) Starting application heartbeats on new connection2014-02-18 20:44:28.499 | 9032 | container | [SP-2-722012] (2.188) sp(5084) Entering heartbeat loop2014-02-18 20:44:28.502 | 8592 | container | [SP-4-114126] (2.191) sp(5084) Platform(): Auto Checkpoint interval is set to 0.2014-02-18 20:44:28.851 | 8592 | container | [SP-3-114113] (2.540) sp(5084) Platform()::processSignal(): fatal error (signal=11) in thread id 8592, thread name 'unknown thread'; aborting.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Reference Table Queries", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "58.3", "author": "Gaurav Singh", "url": "http://scn.sap.com/thread/3504309", "text": "hi mike,I missed one thing to add in the previous explanation that I have not changed anything in the configuration of the ESP Studio. And In my another project which contains HANA Output Adapter is able to insert data using the same configurations.Thanks,Gaurav Singh", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Reference Table Queries", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "58.4", "author": "Mike Weadley", "url": "http://scn.sap.com/thread/3504309", "text": "Hi Gaurav,When you run the project from ESP Studio, are you running it on Studio's local cluster (defaults to esp://localhost:9786) or on the external cluster (defaults to esp://localhost:19011)?Mike", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Reference Table Queries", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "58.5", "author": "Gaurav Singh", "url": "http://scn.sap.com/thread/3504309", "text": "Hello Mike,It is local cluster. esp://localhost:9786.Gaurav", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Reference Table Queries", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "58.6", "author": "Mike Weadley", "url": "http://scn.sap.com/thread/3504309", "text": "Hi Gaurav,Please try commenting out everything but the INPUT STREAM definition, compile, then see if you can deploy successfully. If that fails, then there may be an issue with configuration of your ESP Studio.If that succeeds, then please post your complete project and service.xml file and localnode.xml file and all related log files to our internal SAP JAM site for review.Mike", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Reference Table Queries", "type": "answer", "tags": "N/A"},
{"date_time": "2014-02-11 06:49:00", "resolve": false, "uid": "59", "title": "Error while adding project to cluster", "url": "http://scn.sap.com/thread/3499804", "text": "I have created two nodes \"node1\" and \"node2\" and configured CCR file as follows:<?xml version=\"1.0\" encoding=\"UTF-8\"?><Configuration xmlns=\"http://www.sybase.com/esp/project_config/2010/08/\"> <Runtime> <Clusters> <!-- we need this only if we have a project/stream binding --> <Cluster name=\"cluster1\" type=\"local\"> <Username>studio</Username> <Password>sap123</Password> </Cluster> </Clusters> <Bindings> <Binding name=\"BaseInput\"> <Cluster>cluster1</Cluster> <!-- this is always needed --> <Workspace>test</Workspace> <Project>test</Project> <BindingName>BaseInputBinding</BindingName> <!-- this is for plat-in adapter name--> <RemoteStream>BaseInput</RemoteStream> </Binding> </Bindings> <AdaptersPropertySet> <PropertySet name=\"Atom Feed Input\"> <Property name=\"URL\"></Property> </PropertySet> ... </AdaptersPropertySet> </Runtime> <Deployment> <Project ha=\"false\"> // no active-active deployment <Options> <Option name=\"time-granularity\" value=\"5\"/> <Option name=\"debug-level\" value=\"4\"/> </Options> <Instances> <Instance name=\"primary\"> <Affinities> <!-- By default no need to put affinity. --> <Affinity type=\"controller\" charge=\"positive\" strength=\"strong\" value=\"node1\"/>  <Affinity type=\"instance\" charge=\"negative\" strength=\"strong\" value=\"secondary\"/> </Affinities> </Instance> <Instance name=\"secondary\"> <Affinities> <!-- By default no need to put affinity. --> <Affinity type=\"controller\" charge=\"positive\" strength=\"weak\" value=\"node2\"/>  <Affinity type=\"instance\" charge=\"negative\" strength=\"strong\" value=\"primary\"/> </Affinities> </Instance> </Instances> </Project> <Cluster> <Failover enable=\"true\"> <FailureInterval>120</FailureInterval> <FailuresPerInterval>4</FailuresPerInterval> </Failover> <Affinities> <Affinity type=\"controller\" charge=\"positive\">myController</Affinity> </Affinities> </Cluster> </Deployment></Configuration>I have started two nodes \"node1\" and node2\" and try to add project to cluster using following command:esp_cluster_admin --uri=esp://10.66.186.103:9786 --username=studio --password=sap123 --add_project --project-name=jmsxmlinput --workspace-name=test--ccx=test.ccx --ccr=test.ccrI got following error[error] Passed in key must select exactly one node: FailoverHow to fix this error?ThanksShashi", "views": "593", "answers": 6, "author": "Shashidhara V Hebbar", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-02-11 23:28:00", "resolve": "", "uid": "59.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3499804", "text": "Hi Shashi,I would like to try to reproduce this problem in my environment. Can you provide the node1.xml and node2.xml files and where each are started and how they are started. Are they on the same machine? What is the OS environment? Are you using ESP 5.1 SP04?Please can you also provide the project files you are using. Did you use the ESP Studio to create the CCR, if not, where did it come from?Thank you,AliceMessage was edited by: Alice Silverstein Added \"Please can you also provide the project files you are using. Did you use the ESP Studio to create the CCR, if not, where did it come from?\"", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error while adding project to cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "59.2", "author": "Shashidhara V Hebbar", "url": "http://scn.sap.com/thread/3499804", "text": "Hi Alice,Thank you very much for your replay.I have installed ESP in two VMs: vewin764SA016, vewin764SA046I have created node1.xml and node2.xml and started using start_node.bat provided with ESP installation from 1st VM (vewin764SA016).start_node.bat node1start_node.bat node2I used ESP Studio to create the CCR and added cluster detailsWhen I tried to add project I got following error:esp_cluster_admin --uri=esp://vewin764SA016:19011 --username=sybase --password=sybase> add project jmsxml/jmsxml jmsxmlinput.ccx jmsxmlinput.ccr[error] Passed in key must select exactly one node: FailoverOS details: (vewin764SA016, vewin764SA046)Windows 7 ProfessionalProcessor: AMD Opteron processor 6128 HE 2.00 GHz (2 processors)RAM: 8 GBSystem type: 64-bit operating systemI have attached node1.xml, node2.xml and CCR (i could not able to attach .ccr file, so i changed extension to .txt) files.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error while adding project to cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "59.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3499804", "text": "Hi Shashi,What kind of failover configuration are you looking to accomplish?The ccr file has ha set to false, yet there are settings in there that are only useful when ha is set to true (ie, there are multiple instances, and there are affinities for type=instance). It is better to use the ESP Studio Project Configuration File Editor rather than editing the ccr file in a text editor. Since you have ha=\"false\", and you have an Instances section, ESP interprets that to mean that this is a Cold Failover type of configuration. For Cold Failover, there can only be one instance, and in the ccr file, there are two instances, which is only correct for ha=\"true\". Assuming that you are wanting only Cold Failover, you could modify your Deployment section to: <Deployment> <Project ha=\"false\"> <Options> <Option name=\"time-granularity\" value=\"5\"/> <Option name=\"debug-level\" value=\"4\"/> </Options> <Instances> <Instance> <Failover enable=\"true\"> <FailureInterval>120</FailureInterval> <FailuresPerInterval>4</FailuresPerInterval> </Failover> <Affinities> <Affinity charge=\"positive\" strength=\"strong\" type=\"controller\" value=\"node1\"/> <Affinity charge=\"positive\" strength=\"weak\" type=\"controller\" value=\"node2\"/> </Affinities> </Instance> </Instances> </Project> </Deployment></Configuration>Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error while adding project to cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "59.4", "author": "Shashidhara V Hebbar", "url": "http://scn.sap.com/thread/3499804", "text": "Hi Alice,My requirement is as follows:I want to create a project failover scenario with recoverable windows and persist messages into a log store for recoverability.When one instance goes down, I want to start a new ESP server and project instance on a new virtual machine and should be able to bring the project up in the recovered state by using log store to recover the state.I need help/suggestions to set up this.ThanksShashi", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error while adding project to cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "59.5", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3499804", "text": "Hi Shashi,Are you still getting the error?For guidance on setting up the log store:- if you are using ESP Studio Visual Editor:http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.infocenter.dc01613.0514/doc/html/kes1313078000075.html- if you are using ESP Studio Text Editor:http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.infocenter.dc01612.0514/doc/html/ksi1310053308183.htmlThank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error while adding project to cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "59.6", "author": "Shashidhara V Hebbar", "url": "http://scn.sap.com/thread/3499804", "text": "Hi Alice,It is working fine. Thank you very much.I started two nodes from two different hosts.When I added project to the cluster, it started running on both the hosts and both were getting data.Since I have to persist data in HANA, there will be duplicate entries in the table (both application instances enters data in the table).I want to setup a cluster such that, when I add a project, it should start on one host and when that host fails, another host should come-up with new project instance. Second host should recover project state from the log store.Currently I am looking at setting up the log store.I need help/suggestion to setup above mentioned cluster.Thanks Shashi", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error while adding project to cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2014-02-19 07:11:00", "resolve": false, "uid": "60", "title": "Getting error while compiling example project \"Stores\"", "url": "http://scn.sap.com/thread/3504831", "text": "Hi,I am getting following errors while compiling example project \"Stores\" provided with ESP installation (<InstalledDir>\\ESP-5_1\\examples\\ccl\\Stores).DescriptionResourcePathLocationType159211-4_WINDOW_NO_RETENTION_POLICYStores.ccl/Storesline 33 column 0CCL Compiler159211-4_WINDOW_NO_RETENTION_POLICYStores.ccl/Storesline 28 column 0CCL Compiler159211-4_WINDOW_NO_RETENTION_POLICYStores.ccl/Storesline 47 column 0CCL CompilerI am using ESP 5.1 SP03Following is CCL file:////This example shows a default store, memory store and log store//// the data for this example must be copied into your \"base-directory/exampledata\"////Sample Memory StoreCREATE MEMORY STORE MemStore  PROPERTIES INDEXSIZEHINT = 8 , INDEXTYPE = 'TREE' ;//// Sample Default store CREATE DEFAULT MEMORY STORE DefaultStore  PROPERTIES INDEXSIZEHINT = 8 , INDEXTYPE = 'TREE' ;//Sample Log StoreCREATE LOG STORE LogStore  PROPERTIES FILENAME = 'mylog.log' , MAXFILESIZE = 8 ,  SYNC = FALSE , SWEEPAMOUNT = 20 ,  RESERVEPCT = 20 , CKCOUNT= 10000 ;// ----------------------------// Input WindowCREATE INPUT WINDOW TradesWindowMem SCHEMA (Ts bigdatetime , Symbol STRING,  Price MONEY(2), Volume INTEGER) PRIMARY KEY (Ts) STORE MemStore; //// Out put window that uses the default memory store CREATE OUTPUT WINDOW DefaultStoreWindow  PRIMARY KEY ( Ts) AS  SELECT * FROM TradesWindowMem ;////Window that ues a log store// because multiple rows are processed in a millisecond// this stream has few rows.//If the log store is not removed, old rows will be loaded in at startupCREATE Output WINDOW LogStoreWindow  SCHEMA (Ts bigdatetime , Symbol STRING,  Price MONEY(2), Volume INTEGER)  PRIMARY KEY ( Ts,Symbol)  STORE LogStore AS  SELECT now() Ts, tw.Symbol,  tw.Price, tw.Volume  FROM TradesWindowMem tw; // ----------------------------// Input CSV AdaptorATTACH INPUT ADAPTER InConn TYPE dsv_in TO TradesWindowMem PROPERTIES  blockSize=1,  dateFormat='%Y/%m/%d %H:%M:%S',  delimiter=',',  dir='../exampledata',  expectStreamNameOpcode=false,  fieldCount=0,  file='stock-trades.csv',  filePattern='*.csv',  hasHeader=false,  safeOps=false,  skipDels=false,  timestampFormat='%Y/%m/%d %H:%M:%S';ThanksShashi", "views": "607", "answers": 3, "author": "Shashidhara V Hebbar", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-02-19 15:15:00", "resolve": "", "uid": "60.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3504831", "text": "Hi Shashi,Those compiler errors are actually warnings. They are warning you that you have not defined a retention policy on those windows. Windows default to \"KEEP ALL\". You have to be careful with KEEP ALL as this can appear to be a memory leak in your program.In your error message the \"4\" part of 159211-4 is a warning level. Please see my blog for more information on how to interpret ESP error messages: Demystifying Event Stream Processor Server ErrorsHowever, based on the way this error message printed, I can tell there is something wrong with your installation. The actual text of the error message is missing. This is where ESP would normally find the text for that error message:% cd $ESP_HOME/bin/i18n/serverDirectory: /work/nstack/ESP51_SP4/ESP-5_1/bin/i18n/server% grep 159211 *esp-server-errors.properties:159211-4_WINDOW_NO_RETENTION_POLICY_MSG=No retention policy has been specified for the window {0}. The amount of memory used by the window may grow without bound.Did you upgrade recently? Maybe your upgrade failed?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Getting error while compiling example project \"Stores\"", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "60.2", "author": "Shashidhara V Hebbar", "url": "http://scn.sap.com/thread/3504831", "text": "Hi Neal,Thank you very much for your replay.I added \"Keep all\" and it is working fine.I have recently installed ESP 5.1 SP03 , may be 10 days back.My CCL code is as follows:REATE LOG STORE LogStore PROPERTIES FILENAME = 'mylog.log' , MAXFILESIZE = 8 , SYNC = FALSE , SWEEPAMOUNT = 20 , RESERVEPCT = 20 , CKCOUNT = 10000 ;CREATE INPUT WINDOW Input_window SCHEMA ( id integer , batteryId string , storename string , lifeleft integer , timestampCol date ) PRIMARY KEY ( id ) KEEP 10 SEC ;CREATE OUTPUT WINDOW Log_Store_Window SCHEMA ( id integer , batteryId string , storename string , lifeleft integer , timestampCol date ) PRIMARY KEY ( id ) STORE LogStore KEEP ALL ROWS AS  SELECT * FROM Input_window ;I added \"KEEP 10 SEC\" to Input_window and \"KEEP ALL\" to Log_Store_Window.My query is whether its works fine or still i may get memory leak in your program.Thanks,Shashi", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Getting error while compiling example project \"Stores\"", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "60.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3504831", "text": "Hi Shashi,It is important to note that omitting a KEEP clause *is not* a memory leak. There are valid use cases to keep all the rows that come into a WINDOW.However, since \"KEEP ALL\" is the default retention for windows, a lot of new users are surprised when they start pushing data through the project and see it start to continuously grow in memory.Your OUTPUT WINDOW has a \"KEEP ALL\" clause. As long as rows are added to it, it will grow in memory usage. Will you ever be sending delete opcodes to your WINDOW to remove elements? Each record that comes into ESP has an \"opcode\" (delete/insert/update/upsert/safedelete): Operation CodesMaybe a STREAM is a better fit for your use case? A STREAM is stateless, it does not retain rows: Comparing Streams, Windows, and Delta Streams Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Getting error while compiling example project \"Stores\"", "type": "answer", "tags": "N/A"},
{"date_time": "2014-02-21 15:22:00", "resolve": true, "uid": "61", "title": "How to integrate ESP with BPM using the WebServices (SOAP) Output", "url": "http://scn.sap.com/thread/3506942", "text": "Hello,Can someone help me with integrating ESP project with SAP Netweaver BPM process?In order to explain what i'm doing, i have include some screen prints to clarify the steps i have made.First i have created a simple BPM proces called \"helloEspProcess\".The input of the process contains a complex type with two attributes \"hello\" and \"bpm\" (both strings).After deploying the process and webdynpro for the human activity, i have changed the process WSDL authentication to \"no-authentication\". Let's start the process by using the Web Service Navigator.Within the process, a task will be generated for the Universal Worklist within the portal. After completing the task, the process will be completed.The next step that i want to complete is the connection from ESP to my BPM process. For that, i have created a ESP project called \"hellobpm\".I've modeled an input stream and connected this stream to a filter. Within the filter, the bpm field (string) will be filtered on value 'bpm'.Let's start the ESP project on the local server and enter some input values for \"hello\" and \"bpm\".First test only displayed the entered values within the input stream.Second test also displayed the entered values within the filter.The BPM process works and the ESP project seems to work also, now lets integrate both worlds ... First, I've deleted the \"Filter\" and added a \"WebServices (SOAP) Output\".I've connected the webservice output with the input stream en configured the output (see next screenshot).When i wan't to perform a Schema Discovery, i get my first error (which i can't fix). Any idea's why this isn't working? So I've tried to start the server and maybe the project just works without the Schema Discovery...The server and the project starts but the connection to my webservice (the bpm process) is DEAD I've checked the console but no errors are described...After starting the adapter, the status will be changed to CONTINUOUS, DONE and within seconds DEAD... Can someone tell me what I'm doing wrong? To explain the configuration more, I've added some extra screenshots below...On my desktop, I've created a folder with the following files: adaptor_config.xml and the mapping.xml.Adaptor_config.xml has been changed with the settings of my ESP project and the services I'm calling.Mapping.xml has been changed by using the fields from ESP and the fields within the service interface.WSDL of my BPM process...I hope someone can help me...Kind regards,Martin", "views": "666", "answers": 6, "author": "Martin Gerritsen", "upvotes": 0, "type": "question", "tags": "sap_sybase_event_stream_processor.web_services.sybase.adapter.troubleshooting.esp_5.1.stream_processing.esp_developer.esp_howto.sybase_support.esp_studio"},
{"date_time": "2014-02-21 21:03:00", "resolve": "solution", "uid": "61.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3506942", "text": "Hello,What version of ESP are you using? (You should be able to go into Help -> About in Studio).The SOAP adapters are external adapters which means they run as a separate process from the ESP server process and they have a separate log file (or possibly files).Look in a directory similar to this for the log files: C:\\Users\\<user_name>\\Documents\\SybaseESP\\5.1\\workspace\\default.hellobpm.0\\logsThis should have some information as to why the adapter goes to DEAD but won't directly help with discovery failures (those don't get logged).Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to integrate ESP with BPM using the WebServices (SOAP) Output", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "61.2", "author": "Martin Gerritsen", "url": "http://scn.sap.com/thread/3506942", "text": "I have copy/paste the log in the map you described... i can't find any errors...02-21-2014 13:35:02.421 INFO [main] (Framework.main) start C:/Users/Gerritsen/Desktop/ESP-BPM files/adapter_config.xml02-21-2014 13:35:02.838 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd02-21-2014 13:35:02.842 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd02-21-2014 13:35:03.143 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-21-2014 13:35:03.145 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-21-2014 13:35:03.472 INFO [main] (AdapterController.init) Address 192.168.14.1:19082 is used to accept the control command.02-21-2014 13:35:03.514 INFO [main] (AdapterController.sendCommand) start C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\adapter_config.xml02-21-2014 13:35:04.649 INFO [Thread-1] (JCLLoggerAdapter.info) jetty-7.6.1.v2012021502-21-2014 13:35:04.726 INFO [Thread-1] (JCLLoggerAdapter.info) started o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:35:04.804 INFO [Thread-1] (JCLLoggerAdapter.info) Started SelectChannelConnector@192.168.14.1:1908202-21-2014 13:35:05.647 INFO [main] (AdapterController.executeStart) Adapter controller is started.02-21-2014 13:35:05.648 INFO [main] (AdapterController.executeStart) Starting adapter02-21-2014 13:35:05.687 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default02-21-2014 13:35:05.707 INFO [main] (JCLLoggerAdapter.info) stopped o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:36:25.088 INFO [main] (Framework.main) start C:/Users/Gerritsen/Desktop/ESP-BPM files/adapter_config.xml02-21-2014 13:36:25.510 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd02-21-2014 13:36:25.514 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd02-21-2014 13:36:25.827 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-21-2014 13:36:25.829 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-21-2014 13:36:26.127 INFO [main] (AdapterController.init) Address 192.168.14.1:19082 is used to accept the control command.02-21-2014 13:36:26.165 INFO [main] (AdapterController.sendCommand) start C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\adapter_config.xml02-21-2014 13:36:27.305 INFO [Thread-1] (JCLLoggerAdapter.info) jetty-7.6.1.v2012021502-21-2014 13:36:27.376 INFO [Thread-1] (JCLLoggerAdapter.info) started o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:36:27.455 INFO [Thread-1] (JCLLoggerAdapter.info) Started SelectChannelConnector@192.168.14.1:1908202-21-2014 13:36:28.303 INFO [main] (AdapterController.executeStart) Adapter controller is started.02-21-2014 13:36:28.303 INFO [main] (AdapterController.executeStart) Starting adapter02-21-2014 13:36:28.342 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default02-21-2014 13:36:28.362 INFO [main] (JCLLoggerAdapter.info) stopped o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:36:36.467 INFO [main] (Framework.main) start C:/Users/Gerritsen/Desktop/ESP-BPM files/adapter_config.xml02-21-2014 13:36:36.932 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd02-21-2014 13:36:36.936 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd02-21-2014 13:36:37.256 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-21-2014 13:36:37.258 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-21-2014 13:36:37.647 INFO [main] (AdapterController.init) Address 192.168.14.1:19082 is used to accept the control command.02-21-2014 13:36:37.686 INFO [main] (AdapterController.sendCommand) start C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\adapter_config.xml02-21-2014 13:36:38.834 INFO [Thread-1] (JCLLoggerAdapter.info) jetty-7.6.1.v2012021502-21-2014 13:36:38.901 INFO [Thread-1] (JCLLoggerAdapter.info) started o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:36:38.980 INFO [Thread-1] (JCLLoggerAdapter.info) Started SelectChannelConnector@192.168.14.1:1908202-21-2014 13:36:39.833 INFO [main] (AdapterController.executeStart) Adapter controller is started.02-21-2014 13:36:39.834 INFO [main] (AdapterController.executeStart) Starting adapter02-21-2014 13:36:39.867 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default02-21-2014 13:36:39.886 INFO [main] (JCLLoggerAdapter.info) stopped o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:36:44.707 INFO [main] (Framework.main) start C:/Users/Gerritsen/Desktop/ESP-BPM files/adapter_config.xml02-21-2014 13:36:45.143 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd02-21-2014 13:36:45.148 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd02-21-2014 13:36:45.478 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-21-2014 13:36:45.479 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-21-2014 13:36:45.818 INFO [main] (AdapterController.init) Address 192.168.14.1:19082 is used to accept the control command.02-21-2014 13:36:45.857 INFO [main] (AdapterController.sendCommand) start C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\adapter_config.xml02-21-2014 13:36:47.001 INFO [Thread-1] (JCLLoggerAdapter.info) jetty-7.6.1.v2012021502-21-2014 13:36:47.069 INFO [Thread-1] (JCLLoggerAdapter.info) started o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:36:47.146 INFO [Thread-1] (JCLLoggerAdapter.info) Started SelectChannelConnector@192.168.14.1:1908202-21-2014 13:36:47.999 INFO [main] (AdapterController.executeStart) Adapter controller is started.02-21-2014 13:36:47.999 INFO [main] (AdapterController.executeStart) Starting adapter02-21-2014 13:36:48.027 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default02-21-2014 13:36:48.047 INFO [main] (JCLLoggerAdapter.info) stopped o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:39:30.697 INFO [main] (Framework.main) start C:/Users/Gerritsen/Desktop/ESP-BPM files/adapter_config.xml02-21-2014 13:39:31.124 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd02-21-2014 13:39:31.129 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd02-21-2014 13:39:31.435 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-21-2014 13:39:31.436 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-21-2014 13:39:31.740 INFO [main] (AdapterController.init) Address 192.168.14.1:19082 is used to accept the control command.02-21-2014 13:39:31.777 INFO [main] (AdapterController.sendCommand) start C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\adapter_config.xml02-21-2014 13:39:32.913 INFO [Thread-1] (JCLLoggerAdapter.info) jetty-7.6.1.v2012021502-21-2014 13:39:32.982 INFO [Thread-1] (JCLLoggerAdapter.info) started o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:39:33.060 INFO [Thread-1] (JCLLoggerAdapter.info) Started SelectChannelConnector@192.168.14.1:1908202-21-2014 13:39:33.911 INFO [main] (AdapterController.executeStart) Adapter controller is started.02-21-2014 13:39:33.912 INFO [main] (AdapterController.executeStart) Starting adapter02-21-2014 13:39:33.950 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default02-21-2014 13:39:33.969 INFO [main] (JCLLoggerAdapter.info) stopped o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:42:38.739 INFO [main] (Framework.main) start C:/Users/Gerritsen/Desktop/ESP-BPM files/adapter_config.xml02-21-2014 13:42:39.187 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd02-21-2014 13:42:39.191 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd02-21-2014 13:42:39.503 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-21-2014 13:42:39.540 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-21-2014 13:42:39.853 INFO [main] (AdapterController.init) Address 192.168.14.1:19082 is used to accept the control command.02-21-2014 13:42:39.890 INFO [main] (AdapterController.sendCommand) start C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\adapter_config.xml02-21-2014 13:42:41.031 INFO [Thread-1] (JCLLoggerAdapter.info) jetty-7.6.1.v2012021502-21-2014 13:42:41.099 INFO [Thread-1] (JCLLoggerAdapter.info) started o.e.j.s.ServletContextHandler{/,null}02-21-2014 13:42:41.178 INFO [Thread-1] (JCLLoggerAdapter.info) Started SelectChannelConnector@192.168.14.1:1908202-21-2014 13:42:42.029 INFO [main] (AdapterController.executeStart) Adapter controller is started.02-21-2014 13:42:42.030 INFO [main] (AdapterController.executeStart) Starting adapter02-21-2014 13:42:42.072 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default02-21-2014 13:42:42.092 INFO [main] (JCLLoggerAdapter.info) stopped o.e.j.s.ServletContextHandler{/,null}02-21-2014 14:13:48.021 INFO [main] (Framework.main) start C:/Users/Gerritsen/Desktop/ESP-BPM files/adapter_config.xml02-21-2014 14:13:48.437 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd02-21-2014 14:13:48.441 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd02-21-2014 14:13:48.747 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-21-2014 14:13:48.749 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-21-2014 14:13:49.057 INFO [main] (AdapterController.init) Address 192.168.14.1:19082 is used to accept the control command.02-21-2014 14:13:49.094 INFO [main] (AdapterController.sendCommand) start C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\adapter_config.xml02-21-2014 14:13:50.227 INFO [Thread-1] (JCLLoggerAdapter.info) jetty-7.6.1.v2012021502-21-2014 14:13:50.292 INFO [Thread-1] (JCLLoggerAdapter.info) started o.e.j.s.ServletContextHandler{/,null}02-21-2014 14:13:50.369 INFO [Thread-1] (JCLLoggerAdapter.info) Started SelectChannelConnector@192.168.14.1:1908202-21-2014 14:13:51.225 INFO [main] (AdapterController.executeStart) Adapter controller is started.02-21-2014 14:13:51.226 INFO [main] (AdapterController.executeStart) Starting adapter02-21-2014 14:13:51.262 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default02-21-2014 14:13:51.281 INFO [main] (JCLLoggerAdapter.info) stopped o.e.j.s.ServletContextHandler{/,null}", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to integrate ESP with BPM using the WebServices (SOAP) Output", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "61.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3506942", "text": "Hello,I don't see any errors either. What version of ESP are you using?Maybe try editing the \"log4j.properties\" file and replace all of the references to \"INFO\" with \"DEBUG\": LoggingThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to integrate ESP with BPM using the WebServices (SOAP) Output", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "61.4", "author": "Martin Gerritsen", "url": "http://scn.sap.com/thread/3506942", "text": "I've downloaded the evaluation version from SDNSAP Sybase Event Stream Processor StudioVersion: 5.1.04.00/20131113.1/SP04 PL00/winnt/x86/32-bit/OPT/Wed Nov 13 12:24:21 PST 2013In my previous post (the log file), you see the following logtext before stopping the adapter....02-21-2014 14:13:51.262 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default02-21-2014 14:13:51.281 INFO [main] (JCLLoggerAdapter.info) stopped o.e.j.s.ServletContextHandler{/,null}How to integrate ESP with BPM using the WebServices (SOAP) OutputI think the adapter could connect to my ESP project, so I've changed the following parameters within the adapter_config.xml from... <Module type=\"transporter\"> <InstanceName>hellobpmTransporter</InstanceName> <Name>SOAPOutputTransporter</Name> <Polling> <Enabled>true</Enabled> <TimeInterval>20000</TimeInterval> </Polling> <Parameters> <SOAPOutputTransportParameters> <webservice name=\"helloEspProcess\"> <urls> <wsdlURL>http://sappo73.creetion.com:52000/bpm/vendor01com/process/helloEspProcessTrigger?wsdl</wsdlURL> </urls> <serviceTimeout>60000</serviceTimeout> <serviceRetries>2</serviceRetries> <request action=\"StartProcess\"/> <mappingFile>mapping.xml</mappingFile> </webservice> <workingDir>/tmp</workingDir> </SOAPOutputTransportParameters> </Parameters> </Module> </Modules> <EspProjects> <EspProject>  <Name>hellobpm</Name> <Uri>esp://localhost:9786/default</Uri> <Security> <User>studio</User> <Password>creetion</Password> <AuthType>user_password</AuthType> </Security> </EspProject> </EspProjects> <GlobalParameters></GlobalParameters></Adapter>to (blue text)... <Module type=\"transporter\"> <InstanceName>hellobpmTransporter</InstanceName> <Name>SOAPOutputTransporter</Name> <Polling> <Enabled>true</Enabled> <TimeInterval>20000</TimeInterval> </Polling> <Parameters> <SOAPOutputTransportParameters> <webservice name=\"helloEspProcess\"> <urls> <wsdlURL>http://sappo73.creetion.com:52000/bpm/vendor01com/process/helloEspProcessTrigger?wsdl</wsdlURL> </urls> <serviceTimeout>60000</serviceTimeout> <serviceRetries>2</serviceRetries> <request action=\"StartProcess\"/> <mappingFile>C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\mapping.xml</mappingFile> </webservice> <workingDir>/tmp</workingDir> </SOAPOutputTransportParameters> </Parameters> </Module> </Modules> <EspProjects> <EspProject>  <Name>hellobpm</Name> <Uri>esp://localhost:9786/default/hellobpm</Uri> <Security> <User>studio</User> <Password>creetion</Password> <AuthType>user_password</AuthType> </Security> </EspProject> </EspProjects> <GlobalParameters></GlobalParameters></Adapter>The good think now is that the adapter is running and the status equals CONTINUOUS .The bad thing is... its still not working. In the logfile, the following message appears... 02-21-2014 21:33:35.250 INFO [main] (Framework.main) start C:/Users/Gerritsen/Desktop/ESP-BPM files/adapter_config.xml 02-21-2014 21:33:35.791 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd02-21-2014 21:33:35.796 INFO [main] (XmlUtils$1.resolveResource) D:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd02-21-2014 21:33:36.191 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ... 02-21-2014 21:33:36.194 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-21-2014 21:33:36.594 INFO [main] (AdapterController.init) Address 192.168.14.1:19082 is used to accept the control command.02-21-2014 21:33:36.642 INFO [main] (AdapterController.sendCommand) start C:\\Users\\Gerritsen\\Desktop\\ESP-BPM files\\adapter_config.xml02-21-2014 21:33:37.818 INFO [Thread-1] (JCLLoggerAdapter.info) jetty-7.6.1.v2012021502-21-2014 21:33:37.910 INFO [Thread-1] (JCLLoggerAdapter.info) started o.e.j.s.ServletContextHandler{/,null}02-21-2014 21:33:38.018 INFO [Thread-1] (JCLLoggerAdapter.info) Started SelectChannelConnector@192.168.14.1:1908202-21-2014 21:33:38.816 INFO [main] (AdapterController.executeStart) Adapter controller is started.02-21-2014 21:33:38.817 INFO [main] (AdapterController.executeStart) Starting adapter02-21-2014 21:33:38.865 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default/hellobpm02-21-2014 21:33:39.783 INFO [main] (ModuleWrapper.initQue) Buffer Size for module hellobpmSubscriber is 10240.02-21-2014 21:33:39.786 INFO [main] (ModuleWrapper.initParallelParameters) Parallel setting of module hellobpmSubscriber is true.02-21-2014 21:33:39.793 INFO [main] (SubscribeProcesser.init) EspSubscriber is initializing02-21-2014 21:33:39.822 INFO [main] (EspProjectInfo.connect) Login to esp://localhost:9786/default/hellobpm02-21-2014 21:33:39.976 INFO [main] (ModuleWrapper.initQue) Buffer Size for module hellobpmTransporter is 10240.02-21-2014 21:33:39.979 INFO [main] (ModuleWrapper.initParallelParameters) Parallel setting of module hellobpmTransporter is true.02-21-2014 21:33:39.980 INFO [main] (TransporterWrapper.init) Before initializing the Transporter module hellobpmTransporter02-21-2014 21:33:41.694 INFO [main] (SOAPTransporter.generateStubs) located WSDL at http://sappo73.creetion.com:52000/bpm/vendor01com/process/helloEspProcessTrigger?wsdl02-21-2014 21:33:43.544 INFO [main] (DeploymentEngine.prepareRepository) No services directory was found under D:\\Sybase\\ESP-5_1\\adapters\\webservices\\config\\axis2repo.02-21-2014 21:33:43.765 INFO [main] (ModuleDeployer.deploy) Deploying module: addressing-1.6.2 - file:/D:/Sybase/ESP-5_1/adapters/webservices/config/axis2repo/modules/addressing-1.6.2.mar02-21-2014 21:33:43.784 INFO [main] (ModuleDeployer.deploy) Deploying module: rahas-1.6.2 - file:/D:/Sybase/ESP-5_1/adapters/webservices/config/axis2repo/modules/rahas-1.6.2.mar02-21-2014 21:33:43.816 INFO [main] (ModuleDeployer.deploy) Deploying module: rampart-1.6.2 - file:/D:/Sybase/ESP-5_1/adapters/webservices/config/axis2repo/modules/rampart-1.6.2.mar02-21-2014 21:33:45.678 INFO [main] (SOAPTransporter.createStubs) Created stub with default endpoints02-21-2014 21:33:45.679 INFO [main] (SOAPTransporter.generateStubs) Successully created sevice stubs02-21-2014 21:33:45.680 INFO [main] (TransporterWrapper.init) After initializing the Transporter module hellobpmTransporter02-21-2014 21:33:45.693 INFO [main] (ModuleWrapper.start) Before starting module hellobpmTransporter02-21-2014 21:33:45.693 INFO [main] (ModuleWrapper.start) After module hellobpmTransporter started02-21-2014 21:33:45.709 INFO [main] (ModuleWrapper.start) Before starting module hellobpmSubscriber02-21-2014 21:33:45.709 INFO [Thread-18] (TransporterWrapper.run) Before running the Transporter module hellobpmTransporter02-21-2014 21:33:45.733 INFO [main] (SubscribeProcesser.start) Subscriber of stream hellobpmInputStream is started02-21-2014 21:33:45.734 INFO [main] (ModuleWrapper.start) After module hellobpmSubscriber started02-21-2014 21:33:45.736 INFO [main] (AdapterController.executeStart) Adapter started02-21-2014 21:33:45.737 INFO [Thread-20] (EspConnectorWrapper.run) Running EspConnector Module hellobpmSubscriber02-21-2014 21:33:45.737 INFO [main] (AdapterController.executeStart) Starting adapter controller02-21-2014 21:34:00.535 ERROR [Thread-18] (SOAPOutputTransporter.execute) Unable to send row to web servicejava.lang.NoSuchMethodException: Unknown property 'startProcess' on class 'class com.sap.esp.ws.helloEspProcess.HelloEspProcessStub$StartProcess' at org.apache.commons.beanutils.PropertyUtilsBean.getSimpleProperty(PropertyUtilsBean.java:1322) at org.apache.commons.beanutils.PropertyUtilsBean.getNestedProperty(PropertyUtilsBean.java:770) at org.apache.commons.beanutils.PropertyUtilsBean.getProperty(PropertyUtilsBean.java:846) at org.apache.commons.beanutils.PropertyUtils.getProperty(PropertyUtils.java:426) at com.sap.esp.adapter.ws.AepRecordToADBMapper.getCurrentProperty(AepRecordToADBMapper.java:72) at com.sap.esp.adapter.ws.AepRecordToADBMapper.setProperty(AepRecordToADBMapper.java:66) at com.sap.esp.adapter.ws.AepRecordToADBMapper.populateADBBean(AepRecordToADBMapper.java:37) at com.sap.esp.adapter.ws.soap.transporter.SOAPOutputTransporter.getRequestObj(SOAPOutputTransporter.java:62) at com.sap.esp.adapter.ws.soap.transporter.SOAPOutputTransporter.execute(SOAPOutputTransporter.java:49) at com.sybase.esp.adapter.framework.wrappers.TransporterWrapper.run(Unknown Source) at java.lang.Thread.run(Thread.java:662)The next thing I've changed is the mapping.xml from...<?xml version=\"1.0\" encoding=\"UTF-8\"?><columnMappings> <mapping adapterField=\"startProcess.hello\" espCol=\"hello\" /> <mapping adapterField=\"startProcess.bpm\" espCol=\"bpm\" /></columnMappings>To...<?xml version=\"1.0\" encoding=\"UTF-8\"?><columnMappings> <mapping adapterField=\"hello\" espCol=\"hello\" /> <mapping adapterField=\"bpm\" espCol=\"bpm\" /></columnMappings>The service call is received by SAP Netweaver PO system, but still there is an error .The good thing is that the adapter is running and is sending a message to the SAP Netweaver PO BPM process The bad thing is that the payload of the message is xxx and xxxx Any idea what might be the reason for this?Is the mapping.xml incorrect if you compare it with my WSDL of the BPM process???The other thing is... (maybe more a SAP Netweaver PO problem rather then ESP...), there are also other error's logged according to the database.I've to find out what the reason for these errors are... to be continued ...", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to integrate ESP with BPM using the WebServices (SOAP) Output", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "61.5", "author": "Martin Gerritsen", "url": "http://scn.sap.com/thread/3506942", "text": "Update related to my previous post.SOAPUI and WSNavigator also provide xxx within the payload of the service call.Both are also generating a SQL error so i think the connection between ESP and SAP Netweaver PO is working and we have to fix another problem first. I will come back with an update.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to integrate ESP with BPM using the WebServices (SOAP) Output", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "61.6", "author": "Martin Gerritsen", "url": "http://scn.sap.com/thread/3506942", "text": "Problem solved...The steps I've described above works fine if you take the small changes within the adapter_config.xml and mapping.xml inconsideration.Neal, thank you for your help!", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:How to integrate ESP with BPM using the WebServices (SOAP) Output", "type": "answer", "tags": "N/A"},
{"date_time": "2014-02-27 06:21:00", "resolve": false, "uid": "62", "title": "TO setup Cold Failover in ESP Cluster", "url": "http://scn.sap.com/thread/3509996", "text": "Hi,I created two nodes (node1 and node2) and started in defferent machines, node1 in vewin764SA016(1st machine) and node2 in vewin764SA046(2nd machine)(I have attached both files).I created an ESP project which has input window attached to XML Input Adapter.I setup cluster configuration in CCR file as follows (I have attached CCR file also. I could not able to attach .ccr, so it change extension to txt):<?xml version=\"1.0\" encoding=\"UTF-8\"?><Configuration xmlns=\"http://www.sybase.com/esp/project_config/2010/08/\"> <Runtime> <Clusters> <Cluster name=\"esp://vewin764SA016:19011\" type=\"remote\"> <Auth>user</Auth> <Username encrypted=\"false\">sybase</Username> <Password encrypted=\"false\">sybase</Password> <Rsakeyfile></Rsakeyfile> <Managers> <Manager>vewin764SA016:19001</Manager> <Manager>vewin764SA046:19002</Manager> </Managers> </Cluster> </Clusters> <Bindings> <Binding name=\"Battery_Life_Input_Adapter_window\"> <Cluster>esp://vewin764SA016:19011</Cluster> <Workspace>test</Workspace> <Project>test</Project> <BindingName>b1</BindingName> <RemoteStream>remote1</RemoteStream> <Output>false</Output> </Binding> </Bindings> <AdaptersPropertySet> <PropertySet name=\"Atom Feed Input\"> <Property name=\"URL\"></Property> </PropertySet> ... </AdaptersPropertySet> </Runtime> <Deployment> <Project ha=\"false\"> <Options> <Option name=\"time-granularity\" value=\"5\"/> <Option name=\"debug-level\" value=\"4\"/> </Options> <Instances> <Instance> <Failover enable=\"true\"> <FailureInterval>120</FailureInterval> <FailuresPerInterval>5</FailuresPerInterval> </Failover> <Affinities> <Affinity charge=\"positive\" strength=\"strong\" type=\"controller\" value=\"node1\"/> <Affinity charge=\"positive\" strength=\"weak\" type=\"controller\" value=\"node2\"/> </Affinities> <Affinities/> </Instance> </Instances> </Project> </Deployment></Configuration>I added project to node1 using following command and started the projectesp_cluster_admin --uri=esp://vewin764SA016:19011 --username=sybase --password=sybase --add_project --project-name=test --workspace-name=test --ccx=test.ccx --ccr=test.ccrProject started in both machines and both getting data.As per ESP document: \"If cold failover is enabled, a failover occurs when a failed project switches to another server to continue processing.\"But in my case project is running in both the nodes and both getting data.I tried all possible combinations for Affinity attributes charge and strength(positive/negative, strong/weak). But it did not work out. How can I set up a cluster such that when i add a project, it should start running on one node and when that node goes down, it should bring up second node and start running on that.ThanksShashi", "views": "580", "answers": 3, "author": "Shashidhara V Hebbar", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-02-28 16:51:00", "resolve": "", "uid": "62.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3509996", "text": "Hi Shashi,Reviewing the configuration of your ccr file, you've got <Affinities> <Affinity charge=\"positive\" strength=\"strong\" type=\"controller\" value=\"node1\"/> <Affinity charge=\"positive\" strength=\"weak\" type=\"controller\" value=\"node2\"/> </Affinities> <Affinities/>Just note, that in your set-up, you've set strong and positive for node1. This means that it will only run on node1.So if your node1 is down, the project will not start up on node2. Is that what you are trying to accomplish?\"</Affinities>\" - that fifth line there is extra. I don't think it is harming anything though.I am assuming that you are using Studio to see the that the \"Project started in both machines and both getting data\".There is an outstanding New Feature Request CR for Studio to support HA and failover. Studio is really not compatible with HA. Studio makes it look like there are multiple instances of the project running when in fact there is only one instance running. Studio will start getting errors if the project crashes and is failed over to the secondary node. I cant really recommend using Studio at all when dealing with HA: CR 732974 - Request for Studio support of HA and failover.To confirm that there is only one instance of the project running, I look at esp_cluster_admin:$ esp_cluster_admin --uri esp://bryantpark:19011 --username=sybasePassword:> get managersManager[0]: node1@http://bryantpark.sybase.com:19011Manager[1]: node2@http://bryantpark.sybase.com:19012> get controllersController[0]: node1@http://bryantpark.sybase.com:19011Controller[1]: node2@http://bryantpark.sybase.com:19012> get projects=============================Workspace: testProject: testInstance Count: 1 ----------- Instance Details ----------- Instance Name: default Controller Name: node1 Current Status: started-running Requested Status: started-running Failure Interval: 120 Failures Per Interval: 5 -------------- Affinities -------------- Affinity Type: CONTROLLER Affinity Charge: POSITIVE Affinity Strength: STRONG Affinity Subject: node1 Affinity Type: CONTROLLER Affinity Charge: POSITIVE Affinity Strength: WEAK Affinity Subject: node2>The output from \"get projects\" shows that there are two active managers and controllers, and that the single instance is running from the controller named node1.Next, I run the \"get project\" command, and it shows me the Pid:> get project test/testWorkspace: testProject: test ------------------ Instance : 0 ------------------ Instance Id: Id_2000003_1393600620713 Command Host: bryantpark.sybase.com Command Port: 44905 Gateway Host: bryantpark.sybase.com Gateway Port: 41162 Sql Port: 47244 SSL Enabled: false Big Endian: false Address Size: 8 Date Size: 8 Money Precision: 4 Pid: 20637 Topology Ignored: false Timer Interval: 5 Active-Active: falseI run these Linux commands that also confirm to me that I have only one instance running:$ ps -ef | grep esp_serveralices 19963 19961 1 09:45 pts/0 00:00:27 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-node node1.xml --cluster-log-properties node1.log.propertiesalices 20243 20241 1 09:59 pts/1 00:00:15 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-node node2.xml --cluster-log-properties node2.log.propertiesalices 20637 19963 0 10:16 ? 00:00:00 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-container --cluster-container-id Id_2000003_1393600620713 --log-to 4alices 20729 18201 0 10:18 pts/2 00:00:00 grep esp_serverFrom here, I see that pid 20637's parent pid is 19963, which is the pid for node1 server.Next, I kill the active manager and the project to simulate a catastrophic failure:$ kill -9 20637 19963Due to the affinities, no failover happens to node2:$ ps -ef | grep esp_serveralices 20243 20241 1 09:59 pts/1 00:00:17 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-node node2.xml --cluster-log-properties node2.log.propertiesalices 20764 18201 0 10:21 pts/2 00:00:00 grep esp_serverNext, I use a different ccr file that does not have affinities configured.From esp_cluster_admin, I stop and remove the test/test project and then re-run using the modified ccr that has no affinities.$ esp_cluster_admin --uri esp://bryantpark:19012\\;bryantpark:19011 --username=sybasePassword:> remove project test/test[done]> add project test/test bin/test.ccx test-without-affins.ccr[done]> start project test/test[done]> get projects=============================Workspace: testProject: testInstance Count: 1 ----------- Instance Details ----------- Instance Name: default Controller Name: node2 Current Status: started-running Requested Status: started-running Failure Interval: 120 Failures Per Interval: 5This time, the project started on node2.> get project test/testWorkspace: testProject: test ------------------ Instance : 0 ------------------ Instance Id: Id_1000003_1393601774031 Command Host: bryantpark.sybase.com Command Port: 46151 Gateway Host: bryantpark.sybase.com Gateway Port: 36432 Sql Port: 50482 SSL Enabled: false Big Endian: false Address Size: 8 Date Size: 8 Money Precision: 4 Pid: 21422 Topology Ignored: false Timer Interval: 5 Active-Active: false>The pid is 21422.$ ps -ef | grep esp_serveralices 21213 21211 4 10:33 pts/0 00:00:07 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-node node1.xml --cluster-log-properties node1.log.propertiesalices 21282 21280 4 10:33 pts/1 00:00:07 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-node node2.xml --cluster-log-properties node2.log.propertiesalices 21422 21282 1 10:36 ? 00:00:00 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-container --cluster-container-id Id_1000003_1393601774031 --log-to 4alices 21500 18201 0 10:36 pts/2 00:00:00 grep esp_serverPid 21422's parent pid is 21282, which is the pid for node2 server.Kill the project and node2:$ kill -9 21422 21282$ ps -ef | grep esp_serveralices 21213 21211 4 10:33 pts/0 00:00:08 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-node node1.xml --cluster-log-properties node1.log.propertiesalices 21505 21213 12 10:36 ? 00:00:00 /work/alices/esp514/ESP-5_1/bin/esp_server --cluster-container --cluster-container-id Id_2_1393601813749 --log-to 4 --clusalices 21578 18201 0 10:36 pts/2 00:00:00 grep esp_serverThe project automatically fails over now to node1.> get managersManager[0]: node1@http://bryantpark.sybase.com:19011> get controllersController[0]: node1@http://bryantpark.sybase.com:19011> get projects=============================Workspace: testProject: testInstance Count: 1 ----------- Instance Details ----------- Instance Name: default Controller Name: node1 Current Status: started-running Requested Status: started-running Failure Interval: 120 Failures Per Interval: 5Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:TO setup Cold Failover in ESP Cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "62.2", "author": "Shashidhara V Hebbar", "url": "http://scn.sap.com/thread/3509996", "text": "Hi Alice,Thank you very much for your investigations and reply.Following are my answer/query for your reply:1. I am assuming that you are using Studio to see the that the \"Project started in both machines and both getting data\" Yes, I was using ESP Studio to check whether project started in both machines. I will use \"esp_cluster_admin\" command and let you know.2. Just note, that in your set-up, you've set strong and positive for node1. This means that it will only run on node1.So if your node1 is down, the project will not start up on node2. Is that what you are trying to accomplish? No. I want project should stat up on node2 as soon as node1 goes down. Whether I have to set weak and positive for both nodes? What should be the configuration for the Affinities to accomplish this?Thanks,Shashi", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:TO setup Cold Failover in ESP Cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "62.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3509996", "text": "Hi Shashi,Setting affinities is optional. If no affinities are configured, then the cluster will decide on its own which nodes to choose for where to run the project and for where to failover to. You only need to set up affinities if you want to limit which nodes in your cluster you want to use or if you want to establish which are the preferred nodes you'd like to use to run your project.You would set an weak and positive affinity for a node if you prefer it to run on that node rather than run on some other node.So, let's say you have 4 or 5 nodes in your cluster, and you'd prefer that the project only run on 2 out of those five, then you'd set weak positive affinities for each of the 2 nodes you'd prefer for the project to run on.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:TO setup Cold Failover in ESP Cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2014-02-25 22:19:00", "resolve": true, "uid": "63", "title": "ESP scenario question!?", "url": "http://scn.sap.com/thread/3509010", "text": "Hi all,I have the following scenario in mind, can someone tell me if ESP can support this scenario and which elements do I need to use in order to accomplish my scenarioI want to use an input-stream to receive a lot of twitter messages which I want to analyse based on tag and type of message e.g. #complain, #angry, #sad and even #happy, #good etc. I want to group all the message based on this type and after I have received for example 50 messages, I want to trigger a BPM process from ESP by using the Webservice Output Adapter.I know how to use the input-stream and the Webservice Output Adapter. But how can I support the steps in between? Ive used a Splitter to search the twittertext on keywords and define the path for further actions. The first step after the splitter is that the message will be received by a Window. The next thing that I want achieve is to store the messages within the window up till a count of 50. After that, all the messages within the window must be send to a Webservice Output Adapter for further actions (BPM process will be started).In the next scenario, I have used a CSV Output Adapter instead of the Webservice. What happens when I test my ESP process? All the message will be send one by one to the CSV file instead of bundled by 50 .Any help is welcome Header 1declare parameter integer threshold := 5;end;CREATE INPUT STREAM TwitterInputStream SCHEMA ( tweetDate string, tweetTime string, tweetId string, tweetUser string, tweetText string );CREATE OUTPUT SPLITTER TwitterInputSplitter AS WHEN lower ( TwitterInputStream.tweetText ) LIKE '%magnetron%' AND ( lower ( TwitterInputStream.tweetText ) LIKE '%klacht%' OR lower (TwitterInputStream.tweetText ) LIKE '%failure%' OR lower ( TwitterInputStream.tweetText ) LIKE '%boos%' ) THEN MagnetronBadHashTag WHEN lower ( TwitterInputStream.tweetText ) LIKE '%magnetron%' AND ( lower ( TwitterInputStream.tweetText ) LIKE '%happy%' OR lower ( TwitterInputStream.tweetText ) LIKE '%good%' OR lower ( TwitterInputStream.tweetText ) LIKE '%tevreden%') THEN MagnetronGoodHashTag SELECT * FROM TwitterInputStream ;CREATE OUTPUT WINDOW Window1 PRIMARY KEY DEDUCED KEEP EVERY threshold ROWS AS SELECT 'Klacht' tweetType , * FROM MagnetronBadHashTag GROUP BYMagnetronBadHashTag.tweetId ;ATTACH OUTPUT ADAPTER File_Hadoop_CSV_Output1 TYPE toolkit_file_csv_output TO Window1 PROPERTIES dir = 'C:/Users/Gerritsen/Desktop' , file = 'ESP_OUTPUT.csv' ;", "views": "475", "answers": 4, "author": "Martin Gerritsen", "upvotes": 0, "type": "question", "tags": "sybase.stream.stream_processing.esp_developer.esp_howto.sybase_support.esp_tutorial.esp_tip.sds_howto"},
{"date_time": "2014-02-25 22:43:00", "resolve": "", "uid": "63.1", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3509010", "text": "Hi,I guess you want the output in a bundle of 50 rows and not individual rows...If that is so then the way to do is, it needs a bit of tweaking1. Create a join as join produces rows in bundles. You can create a join by joining with some kind of trigger after every 50 rows. If there is a window with 50 rows try to join it with a trigger stream and it should produce 50 rows in a bundle. 2. Create a splash stream and make sure you read 50 rows from the input window and send it out in one read in a continous output statement. SPLASH combines continous output and makes them as one bundle.http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01612.0514/doc/html/san1311804098405.htmlUsing itereators read window data and keep sending it to the output using output statement.The mulitple outputs get combined to one bundle of data.Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP scenario question!?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "63.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3509010", "text": "Here's an example of a simple Flex Operator that turns continuous output into batched/pulsed output: How to get pulsed output in CCLThis example produces a batch every 10 seconds, but for your scenario, just take the statements out of the EVERY 10 SECONDS timer block and move them into the ON block, but put them inside an IF size(cache) = 50 { } block", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP scenario question!?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "63.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3509010", "text": "Did either of these suggestions enable you to do what you were trying to do? Or if we misunderstood what you are trying to implement - please do clarify.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP scenario question!?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "63.4", "author": "Martin Gerritsen", "url": "http://scn.sap.com/thread/3509010", "text": "Hi Jeff, sorry for my late reply. The problem is solved . I have created a Flex component and within the ON block, the stream is pushed into the cache and the cache size is checked within an IF statement. If the cache size equals the threshold level, the cache will be forwarded into the Flex component by using the output and the cache is cleared. Thanks for your help!!!", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP scenario question!?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-03-04 17:08:00", "resolve": false, "uid": "64", "title": "Where all ESP could be used?", "url": "http://scn.sap.com/thread/3512991", "text": "Dear All,Could you please let me know the sources from where all we can stream the data into SAP ESP?I want to know the real time example of this.If you have some links to share then please do.Regards,Vijay", "views": "941", "answers": 7, "author": "vijaykumar ijeri", "upvotes": 0, "type": "question", "tags": "esp_usage.esp_in_busines.different_sources_for_stream"},
{"date_time": "2014-03-04 18:17:00", "resolve": "", "uid": "64.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3512991", "text": "Hi Vijay - have a look at this document: SAP ESP Integration Options - it should give you what you need to know.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Where all ESP could be used?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "64.2", "author": "vijaykumar ijeri", "url": "http://scn.sap.com/thread/3512991", "text": "Hi Jeff,I wanted to know, if we can take the online activities on website and feed the data to esp?If yes how is it possible.Regards,Vijay", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Where all ESP could be used?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "64.3", "author": "Vijaigeetha Chittaranjan", "url": "http://scn.sap.com/thread/3512991", "text": "Hi Vijaykumar,Are you asking about some type of RSS feed from websites ? Thanks,Geetha.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Where all ESP could be used?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "64.4", "author": "vijaykumar ijeri", "url": "http://scn.sap.com/thread/3512991", "text": "Hi Geetha,I want to know the sources from where all the data can be fed to ESP. Like from sensors, click stream and others.How is it done with click stream in particular.Regards,Vijay", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Where all ESP could be used?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "64.5", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3512991", "text": "We have a number of customers that use ESP for real-time click stream analysis. In each case they use a third party tool that provides the click stream and then have done some custom integration to feed the data into ESP.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Where all ESP could be used?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "64.6", "author": "vijaykumar ijeri", "url": "http://scn.sap.com/thread/3512991", "text": "Hi Jeff,Could you please name a few of such tools. Is there any use case or something for the above mentioned point by you. Which describes all this.Regards,Vijay", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Where all ESP could be used?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "64.7", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3512991", "text": "I'm afraid I'm not current in this space - you'll probably need to do a bit of research. Products used in the past were Tealeaf (acquired by IBM) and Ominiture (acquired by Adobe).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Where all ESP could be used?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-02-28 14:43:00", "resolve": true, "uid": "65", "title": "How to use ESP SPLASH to create a UUID in a binary format with 16 bytes", "url": "http://scn.sap.com/thread/3511129", "text": "Hi colleagues,I need to generate a system UUID in ESP flex operator for each incoming row/event and import the data into HANA database, where this field is defined as BINARY(16). What I have tried so far is to write a custom function in ccl file and generate a random ID in the format of e.g. 4f86af8e-bdc3-4d1f-aa68-ab1bbdde248a. Thereafter I convert to binary with to_binary(). This seems to fail since HANA returns error message.How can I generate such an UUID in binary(16) in ESP?Alternatively it is also possible to call Java from within ESP. Do you recommend this? I am looking for an efficient way to do it. We expect a large number of entries in short time, for each row we have to create a GUID (in binary). Can you give me all th eoptions, and which one do you recommand?Thanks in advance!Wei-Guo", "views": "671", "answers": 6, "author": "Wei-Guo Peng", "upvotes": 0, "type": "question", "tags": "sap_hana.sap_sybase_event_stream_processor.esp_5.1.stream_processing.esp_developer.esp_howto"},
{"date_time": "2014-02-28 18:14:00", "resolve": "", "uid": "65.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3511129", "text": "Hello,What version of ESP are you using? (In Studio, go to Help -> About).What version of HANA are you using?What version of HANA ODBC Driver are you using?What error did HANA return to you?I did the following in my project:CREATE INPUT WINDOW InWindow1 SCHEMA ( C1 string , C2 binary )  PRIMARY KEY (C1);CREATE OUTPUT WINDOW OutWindow1 SCHEMA ( C1 string , C2 binary )  PRIMARY KEY (C1) AS SELECT IW.C1 as C1, to_binary(IW.C1) as C2 from InWindow1 IW;I then subscribe to the output window and insert your string to the InWindow.C1 column:C:\\>esp_subscribe -c studio:studio -p localhost:9786/default/p2 -s OutWindow1<OutWindow1 ESP_OPS=\"i\" C1=\"4f86af8e-bdc3-4d1f-aa68-ab1bbdde248a\" C2=\"34663836616638652D626463332D346431662D616136382D616231626264646532343861\"/>I confirm that it arrived in HANA:C:\\Program Files\\sap\\hdbclient>hdbsql -n archer:30015 -u SYSTEM -p Password1hdbsql=> \\paPage by page scroll output switched OFFhdbsql=> select * from BINARY_TESTC1,C2\"string\",0x42696E6172792064617461\"4f86af8e-bdc3-4d1f-aa68-ab1bbdde248a\",0x34663836616638652D626463332D346431662D616136382D6162316262646465323438612 rows selected (overall time 23.660 msec; server time 183 usec)Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to use ESP SPLASH to create a UUID in a binary format with 16 bytes", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "65.2", "author": "Wei-Guo Peng", "url": "http://scn.sap.com/thread/3511129", "text": "Hi Neal,Thanks for your example. I will try it later.I am using the version: Version: 5.1.04.00/20131119.1/SP04 PL00/winnt/x86_64/64-bit/OPT/Tue, Nov 19, 2013 4:06:09 AMWhat I have done meanwhile is to create a Flex Operator with user defined SPLASH routine, which generate a GUID in 32 hex chars and convert to 16 byte binary using hex_binary(). But by assignment from a binayr to another there seems to be a problem:Both statements (assign from ls_sm21 to ls_rec):ls_rec.HeaderId := ls_sm21.HeaderId;ls_rec.HeaderId := extract(ls_sm21.HeaderId,0,16);leads to the same result that the ls_rec.HeaderId contains more bytes than ls_sm21.HeaderId. Later this binary GUID is transferred to HANA database with a field defined as binary(16), and we get an error: Note: both ls_rec.HeaderId and ls_sm21.HeaderId are defined as binary in ESP: A binary value in an ESP row was too large to fit in the destination database column named HeaderId. The row has been discarded.If I print them out: print('GUID sm1 ', base64_string(ls_sm21.HeaderId));-->shows result is okayprint('GUID sm2 ', base64_string(ls_rec1.HeaderId));-->causes out of memory error and project is stopped.In addition, if I try to debug the debugger hangs and I have to kill the ESP studio.Do you have any idea where I did sth wrong?Thanks,Wei-Guo", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to use ESP SPLASH to create a UUID in a binary format with 16 bytes", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "65.3", "author": "Wei-Guo Peng", "url": "http://scn.sap.com/thread/3511129", "text": "Hi Neal,I just fixed the problem. Somehow if the binary values are assigned with structure assignment it works but not attribute by attribute.This works: ls_rec :=[HeaderId = ls_sm21.HeaderId; DetailId = ls_sm21.DetailId; ];But the ones below not:ls_rec.HeaderId := ls_sm21.HeaderId; ls_rec.DetailId := ls_sm21.DetailId; Both fields are binary data type. This is pretty confusing. But my project now is working. Thanks & have a nice day.Regards,Wei-Guo", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to use ESP SPLASH to create a UUID in a binary format with 16 bytes", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "65.4", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3511129", "text": "Hello,I think you have found a bug. I have logged the following bug:: 759000 - Assignment of binary column in SPLASH corrupts data when using the field assignment methodIf you are unable to use the workaround you have described of assigning the values in a record, let us know and we can raise the priority of the CR with engineering.As far as this error: print('GUID sm2 ', base64_string(ls_rec1.HeaderId)); -->causes out of memory error and project is stopped.This is related to the same bug, 759000.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to use ESP SPLASH to create a UUID in a binary format with 16 bytes", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "65.5", "author": "Wei-Guo Peng", "url": "http://scn.sap.com/thread/3511129", "text": "Hi Neal,Thanks. Can we have access of your bug database to track the bugs?My workaround works so far but the syntax is preetty cumbersome.Regards,Wei-Guo", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to use ESP SPLASH to create a UUID in a binary format with 16 bytes", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "65.6", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3511129", "text": "Hi Wei-Guo,Here is the link to how to access and track a Change Request (CR):https://support.wdf.sap.corp/sap/support/notes/1904061Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to use ESP SPLASH to create a UUID in a binary format with 16 bytes", "type": "answer", "tags": "N/A"},
{"date_time": "2014-03-14 21:41:00", "resolve": false, "uid": "66", "title": "Sybase ESP Adapter Reuters Marketfeed 5.1", "url": "http://scn.sap.com/thread/3520436", "text": "Hello,I was able to consume feed from RMDS MarketFeed message type via esp_rmds mechanism. The _FIDListField_ looks perfect and expected, however, all STRING fields (besides the key) appears corrupted, e.g. BASE_CCY STRING: USD@. The behavior is unpredictable and erratic, i.e. some fields should really be empty string but it gets spit out as otherwise.Here is a snippet of the log output:  _FIDListField_ STRING: FIDs: BASE_CCY: USDASK: 100.8828125BID: 100.8203125ASK_YIELD: 2.648BID_YIELD: 2.655CUSIP_CD:ISIN_1:COUPN_RATE: 2.75MATUR_DATE:SETTLEDATE:ISSUE_DATE: _SEQUENCE_NUMBER_ INTEGER: 5 BASE_CCY STRING: USD@ CUSIP_CD STRING: _DATE: ISIN_1 STRING: P_CD:ISIN_1:COUPN_RATE: 2.75MATUR_DATE:SETTLEDATE BID MONEY: 100.8203 ASK MONEY: 100.8828 ASK_YIELD MONEY: 2.6480 BID_YIELD MONEY: 2.6550And here's a snippet config file that gets feed into esp_rmds: <rfa config=\"...\" fidFile=\"...\" enumFile=\"...\" sessionName=\"Session1\" blank =\"\" blankDate =\"\" blankTimestamp=\"\" blankString =\"\" />Any idea what's going on? I couldn't figure out whether there is fixed-length chars in replacement of STRING type in the stream.Thank you,Chin", "views": "610", "answers": 1, "author": "Chin K Ling", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-03-14 21:48:00", "resolve": "", "uid": "66.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3520436", "text": "Hello,There is an outstanding bug with the ESP Reuters Adapter: 750640 - Reuters adapter garbles up data when there are 2 string fieldsIf you have a valid technical support contract, I suggest you log a case and request the issue be escalated. We see that the issues seems to happen only when the string field has data to the maximum number of characters. For example here TRD_1_SRC is a field with 6 characters and it gets affected only if it has 6 characters in the data that comes from the reuters feed.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Sybase ESP Adapter Reuters Marketfeed 5.1", "type": "answer", "tags": "N/A"},
{"date_time": "2014-03-14 22:30:00", "resolve": true, "uid": "67", "title": "streamMaps: Error formatting dateTimeField", "url": "http://scn.sap.com/thread/3520438", "text": "Hi,Per Sybase ESP Adapter Reuters Marketfeed 5.1 Linux x86-64, I'm struggling with parsing/ formatting/ using this feature: <streamMaps> <streamMap name=\"MyInfoStream\" opcode=\"upsert\" flags=\"BASE,NO_SHINE\"> ..... <dateTimeField dateName=\"ACTIV_DATE\" timeName=\"TIMACT\" />Included here is the log extract with ACTIV_DATE=yyyy-MM-dd format and TIMEACT as HH:mm format. I have also tried HH:mm:sss.SSSS format but doesn't work either.Does anyone have a working example on what it should be?-- LOG OUTPUT=============================(35.975) @4 ERROR:Error formatting dateTimeField ACTIV_DATE+TIMACT >2014-03-14<(35.975) @4 INFO:Publishing ICAPFI?ICAP_FI::10YRNOTE 9 of 15 on MyInfoStream as UPSERT(35.975) @4 DEBUG: _ITEM_NAME_ STRING: ICAPFI?ICAP_FI::10YRNOTE _FIDListField_ STRING: FIDs: BASE_CCY: USDASK: 100.8203125BID: 100.7578125ASK_YIELD: 2.655BID_YIELD: 2.662CUSIP_CD:ISIN_1:COUPN_RATE: 2.75MATUR_DATE:SETTLEDATE:ISSUE_DATE:ACTIV_DATE: 2014-03-14TIMACT: 17:22--- CCL Script=============================CREATE INPUT WINDOW MyInfoStreamSCHEMA ( symbol STRING, service STRING, fid_lists STRING, seq INTEGER, stale INTEGER, currency STRING, bid MONEY, ask MONEY, bid_yield MONEY, ask_yield MONEY, coupon MONEY, maturity_date DATE, settle_date DATE, issue_date DATE, \"when\" TIMESTAMP)PRIMARY KEY (symbol)STORE MyInfoStoreKEEP 100 ROWS ;Thank you.Chin", "views": "627", "answers": 3, "author": "Chin K Ling", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-03-17 14:56:00", "resolve": "solution", "uid": "67.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3520438", "text": "Hello,Are you saying that you are applying a mask of \"yyyy-MM-dd\" somewhere like in a configuration file or something?Or are you saying that your data arrives in this format?From what I have been able to find so far, it appears that the adapter expects the data in these formats:/** Reuters Marketfeed formats are:* DATE: dd mon YYYY (11-character format)* TIME: hh:mm (5-character 24-hour format)* TIMESECS: hh:mm:ss (8-character 24-hour format)**/Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:streamMaps: Error formatting dateTimeField", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "67.2", "author": "Chin K Ling", "url": "http://scn.sap.com/thread/3520438", "text": "Hi Neil,Thanks for your response. Your answer is very helpful -- I'm basically looking for what the adapter is expecting, in this case \"dd mon YYYY\" works really well. Two follow up question:- Is there a way for the adapter to specify format/ how to parse if the reuters date (and time) format is different- I see Reuters Marketfeed formats \"DATE, TIME and TIMESECS\" per what you highlighted, however, I am unable to find a good \"placeholder\" for \"hh:mm:ss.SSS\" format (12-character 24-hour format)Any ideas?Thank you,Chin", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:streamMaps: Error formatting dateTimeField", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "67.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3520438", "text": "Hello,I did not see a way to configure the adapter to expect different date/time formats. I think the expectation is that the date/time is formatted on the Reuter's side of the fence. If you require the Reuter's Adapter to be configurable to different date/time formats, please log a technical support case.From looking at the Reuter's Adapter code, I can see that it only supports \"second\" granularity. It does not go down to the microsecond or millisecond. If your input data comes in a finer time granularity than \"seconds\", please log a technical support case.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:streamMaps: Error formatting dateTimeField", "type": "answer", "tags": "N/A"},
{"date_time": "2014-03-21 00:58:00", "resolve": true, "uid": "68", "title": "Connect input stream from another project", "url": "http://scn.sap.com/thread/3523729", "text": "Hello,I am very new to authoring in CCL. I am trying to figure out is it possible for a project to get data from another project's input stream.For example:proj1.ccl -> compile and deploy as project1 in ESP server, within this project, there is a input stream definition Stream1proj2.ccl -> compile and deploy as project2 in ESP server** in project2, how can I access data from Stream1 of project1?The motivation is I would like (if possible) to use project1 as conectivity to RMDS via Reuters Marketfeed adapter that is able to inject streaming feed into Stream1 of project1I would like that project to stay as if you will connection to \"the outside world\".Then, other projects, e.g. project2, can subscribe to Stream1 of project1 and do development / subsequent processing as see fit.Please provide example if possible.Thank you,Chin", "views": "851", "answers": 6, "author": "Chin K Ling", "upvotes": 1, "type": "question", "tags": ""},
{"date_time": "2014-03-21 17:50:00", "resolve": "solution", "uid": "68.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3523729", "text": "Hi Chin,Yes, what you are looking to do is supported in ESP. In ESP, the functionality is called Binding.You are looking to subscribe from project2's stream to project1's stream. This is called an input binding.The attachment ESPInputBinding-GettingStarted.zip.txt is really a zip file - so please rename it to be a .zip (I could not attach a zip file here).The zip contains:1. Two ESP projects, proj1 and proj2, to use as a simple example that implements an input binding, where proj2's input stream is subscribing to proj1's input stream.2. Instructions for running the projects to illustrate the binding in action: Running the Example Input Binding Projects3. Instructions for how to create this set-up : Getting Started - Create Two Projects using Input BindingFor further reference see documentation available on Bindings here:1. Bindings on Streams, Delta Streams, and Windows2. Editing Bindings in Project ConfigurationThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Connect input stream from another project", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "68.2", "author": "Chin K Ling", "url": "http://scn.sap.com/thread/3523729", "text": "Works great with a minor tweak -- double click on proj2.ccr, select the localhost cluster, and make sure the password is entered correctlyThanks Alice -- good stuff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect input stream from another project", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "68.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3523729", "text": "Hi Chin,Good catch!I've provided a second version of the zip that has updated instructions with the step of changing the password.Thank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect input stream from another project", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "68.4", "author": "Chin K Ling", "url": "http://scn.sap.com/thread/3523729", "text": "Hi Alice,After geting it work in localhost, I then try out to connect to a remote server, and for some reason, it is not subscribing to it the way it works when both projects are local.The way I configure it is as follows:- File > New > ESP Project etc. to create a new project, call it subscribe_extproj- Edit the CCL to include all columns to NEWSTREAM input stream matching my remote server stream (already pre-configured)- Edit CCR by:-- Click on Discover, select the remote cluster (this only appear if I connect to the server via SAP Sybase ESP Run-Test perspective -- esps://<server name>:<port>)-- It will show up on All Clusters panel as esps://<server name>:<port>(remote)-- In Cluster Details, I set it Type to remote, Authentication is User/Password, with correct user name and password (the remote server is configured as SSL)-- In Bindings tab, add the new stream, remote stream section:---- cluster: esps://<server name>:<port>---- remote stream: MyInfoStream---- workspace: demo---- project: myprojectClick Run ESP Project at the top of the toolbar to runUsing manual input to inject dummy data into the remote stream (esps://<server name>:<port>/demo/myproject, I don't see it gets subscribed on subscribe_extproj:NEWSTREAMThe log only shows (related to URI binding):2014-03-21 16:18:52.887 | 36064 | container | [SP-3-150004] (0.866) sp(41732) Connection(_URIBINDING_NEWSTREAM1/NEWSTREAM):: No reconnect interval value is defined, defaulting to 5 seconds.When we get the earlier example working, we have an additional log row:2014-03-21 16:35:48.466 | 42588 | container | [SP-4-150005] (30.879) sp(40300) Connection(_URIBINDING_p2stream11/p2stream1):: the binding is using a clear text passwordCan you try yours out as against a remote setup? If you know of a way to turn on more logging, that would be helpful for me to debug too...Thank you,Chin", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect input stream from another project", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "68.5", "author": "Chin K Ling", "url": "http://scn.sap.com/thread/3523729", "text": "We manage to figure this out -- turns out we're missing one step of adding managers that point to the remote server...https://<remote server>:<port> on the CCR", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect input stream from another project", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "68.6", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3523729", "text": "Chin K Ling wrote:\n\nWe manage to figure this out -- turns out we're missing one step of adding managers that point to the remote server...https://<remote server>:<port> on the CCR\nHi Chin,SAP Support logged some change requests to address this issue.Just an additional note:The step of adding clusters (this is step 5 in SAP Sybase Event Stream Processor 5.1 SP04 > Studio Users Guide > Project Configurations > Project Configuration File Editor > Editing Cluster Parameters in Project Configuration) is needed for both SSL-enabled clusters and non-SSL-enabled clusters.For non-SSL-enabled clusters, the format would be http://<remote server>:<port> .Thank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect input stream from another project", "type": "answer", "tags": "N/A"},
{"date_time": "2014-04-03 13:22:00", "resolve": false, "uid": "69", "title": "Controller and Manager", "url": "http://scn.sap.com/thread/3531477", "text": "Hi Colleagues,currently I am working on a project using the Sybase ESP, whichis part of my bachelor thesis.As I planned to write about clustering in ESP, I need to understand the basic concept of managers and controllers.As far as I understood: - 1 Cluster consists of 1 or more ESP Servers - 1 ESP Server consits of 1 or more Nodes - Each Server needs exactly 1 Controller, and at least 1 Manager. Is this assumption correct?And in the next step, I couldnt really find an explanation, what tasksa controller ( and the manager) have. Could anybody roughly point me out the major tasks of a controllerand a manager? (or a document I can find an explanation in).Thanks in advance,and best regardsPatrick Herholz", "views": "271", "answers": 2, "author": "Patrick Herholz", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-04-03 15:32:00", "resolve": "", "uid": "69.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3531477", "text": "Hi,That should be all in the Administration Guide, it has a chapter about clusters.In short:A cluster has manager, controller and projects running on nodes or ESP Servers.A manager handles or administers the cluster, for example for failover.A controller handles projects like starting and stopping them on a node.You can set some affinities strong\\weak positive\\negative to define where the project should be run i.e. only on \\ preferably on or not on a specific one. Similar for failoverBen", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Controller and Manager", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "69.2", "author": "Patrick Herholz", "url": "http://scn.sap.com/thread/3531477", "text": "Hi Ben,thanks for clarifying the concept of clusters. I already read the administration guide before , but couldn't find as explicit answers as yours.Best regardsPatrick", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Controller and Manager", "type": "answer", "tags": "N/A"},
{"date_time": "2014-04-07 12:17:00", "resolve": false, "uid": "70", "title": "ESP Cluster Architecture", "url": "http://scn.sap.com/thread/3533138", "text": "Hello,  In our existing Aleri configuration,we have established a group user ID as 'asap' which controls the binaries. We have for each branch a single userID defined. The single user ID has access to all the models for that branch.LondonBranch Environment:  UseraspLDN  Groupasap  /home/aspLDN/LDNFX/models/home/aspLDN/LDNFX/scripts/home/aspLDN/LDNFX/props/home/aspLDN/LDNFX/logs ShanghaiBrranch Environment:  UseraspSHA  Groupasap  /home/aspSHA/SHAAlerts/models/home/aspSHA/SHAAlerts/scripts/home/aspSHA/SHAAlerts/props/home/aspSHA/SHAAlerts/logsNew York Branch Environment:  UseraspNYK  Groupasap /home/aspNYK/NYKFX/models/home/aspNYK/NYKFX/scripts/home/aspNYK/NYKFX/props/home/aspNYK/NYKFX/logs/home/aspNYK/NYKAC/models/home/aspNYK/NYKAC/scripts/home/aspNYK/NYKAC/props/home/aspNYK/NYKAC/logsOur New York branch has two models viz.NYKAC & NYKFX for which we have a single ID on Linux as 'aspNYK' both ofthe models are accessible by the single ID. New York ID doesnt have access toother branches models or data. Similarlyfor London we have a single ID viz 'aspLDN' which controls a single model. ForShanghai branch it is the same procedure with a single model as well. The threebranches IDs (aspLDN, aspNYK & aspSHA) use a single set of binariescontrolled by 'asap' group user ID. We are trying to work out how we should configure Clusters/workspaces/nodes to give us a similar arrangement as above, our concern is on ESP with having single cluster controlling multiple workspaces (i.e workspace for each branch) and within that multiple projects we risk having all the projects stopped if the single cluster crushes. To maintain some resilience under single server we would like to have a separate cluster for each branch and within that be able to have multiple workspaces/projects.To summarise:- Each Branch should have a single id associated with it which can be used to start /stop / amend that Branches ProjectsEach Project can be start / stop independently Only the asap (esp) id itself can update / replace the esp binariesAny feedback will be appreciated.", "views": "560", "answers": 2, "author": "Nasir Chohan", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-04-08 14:55:00", "resolve": "", "uid": "70.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3533138", "text": "Hi Nasir,What you describe is easy to accomplish.1. Copy the example cluster configuration file ($ESP_HOME/cluster/nodes/node1/*) to each branch: mkdir $ESP_HOME/cluster/nodes/London mkdir $ESP_HOME/cluster/nodes/NewYork mkdir $ESP_HOME/cluster/nodes/Shanghai Modify each of these \"node1.xml\" cluster configuration files to use their own unique ports. For complete details on configuring clusters please see this section of the manual: Get Started with a Cluster 2. All projects can start and stop independently. This is how ESP is designed. I'm not sure if you are asking whether or not access can be restricted such that only a certain user can start and stop a given project? If this is what you are asking, you can employ roles and grant access and privileges to users: Roles, Resources, and Actions3. By default, when a user installs the software, only that user has \"write\" permission. So for example, the user \"nstack\" installed the software and only \"nstack\" can replace the binaries:ls -la $ESP_HOME/bintotal 31656drwxrwxr-x 3 nstack sybase 4096 2014-04-07 11:44 .drwxrwxr-x 18 nstack sybase 4096 2014-04-07 11:44 ..-rwxr-xr-x 1 nstack sybase 1040240 2014-04-03 17:42 esp_aml2ccl-rwxr-xr-x 1 nstack sybase 2959280 2014-04-03 17:42 esp_client-rwxr-xr-x 1 nstack sybase 11304 2014-04-03 17:42 esp_cluster_admin-rwxr-xr-x 1 nstack sybase 12408 2014-04-03 17:42 esp_cluster_node-rwxr-xr-x 1 nstack sybase 17072 2014-04-03 17:42 esp_cluster_util...etc...Members of the \"group\" \"sybase\" can read/execute as well as the \"other\" users. You could revoke permission to other users with the \"chmod\" command. You could also change it so that only the user who installed ESP had access to the various cluster configuration files for each branch and therefore prevent anyone else from starting ESP.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Cluster Architecture", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "70.2", "author": "Nasir Chohan", "url": "http://scn.sap.com/thread/3533138", "text": "Many thanks Neal for the suggestions. I shall attempt this early next week, have good weekend. Kind Regards Nasir", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Cluster Architecture", "type": "answer", "tags": "N/A"},
{"date_time": "2014-04-25 18:30:00", "resolve": false, "uid": "71", "title": "INTEGRATION TOOL", "url": "http://scn.sap.com/thread/3543864", "text": "Hello, my name is Toshi.I am Microsoft Dynamics GP consultant and no knowledge about SAP.One of my GP client has been acquired by another company who uses SAP. Now the parent company(SAP) needs to import some transaction data from the child company(GP).Import data would be the followings. - Shipping data - Billing data - PO Receiving data - PO/Invoice Matching data - Inventory data - AR data - Cash Receipts data - AP data - Payment data - GL dataI would like to know the followings.1) The name of SAP Integration Tool and its functions *white paper or document2) Typical way of integration between SAP and other ERPThank you for your help.", "views": "237", "answers": 0, "author": "Toshiya Anzai", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-04-28 07:44:00", "resolve": true, "uid": "72", "title": "ESP \"Server\" Installation - What is needed?", "url": "http://scn.sap.com/thread/3544481", "text": "Hi guys,just a simple ESP question. I want to install a ESP Server on a linux machine and use it with my Notebook (with installed ESP Studio). Which components do i need?I'm not sure if its enough to install ESP for Linux and just add the Server Details under Prefreences >SAP ESP > Run Test.Thanks", "views": "476", "answers": 2, "author": "Andreas Hohl", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-04-28 16:08:00", "resolve": "solution", "uid": "72.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3544481", "text": "Hello,That should be all that is needed. If you are having trouble connecting from ESP Studio on your PC to an ESP Server running on your Linux box, make sure that the \"ESP_HOSTNAME\" specified in the server's cluster configuration file (typically \"node1.xml\") can be resolved by the PC.Open a DOS Command prompt and try to \"ping\" the server defined by the \"ESP_HOSTNAME\" parameter.If your company uses proxy servers, you may have some additional configuration steps to follow in order to allow Studio and the server to communicate. See this manual with a section on proxy servers: Configuring a ClusterThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP \"Server\" Installation - What is needed?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "72.2", "author": "Andreas Hohl", "url": "http://scn.sap.com/thread/3544481", "text": "Thanks Neal.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP \"Server\" Installation - What is needed?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-04-21 16:37:00", "resolve": false, "uid": "73", "title": "Hadoop Adaptor Usage", "url": "http://scn.sap.com/thread/3540908", "text": "I am trying to read data from Hadoop (Hortonworks). Is there any documentation or guide about this subject?I am seeing File/Hadoop csv,xml,json adapters available in SP4 but I could not find the way to connect to Hadoop.Thanks", "views": "689", "answers": 9, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-04-21 17:32:00", "resolve": "", "uid": "73.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3540908", "text": "See the ESP adapters guide. That should give you the info you need (I hope).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "73.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3540908", "text": "Jeff, thanks for quick response:)I have read File/Hadoop CSV Input Adapter properties but I could not understand completely. Actually I am not so familiar with the Hadoop but I will test Hadoop Adapter on customer site. Therefore I am searching how can I configure the integration. On the below screen (file/hadoop csv input adapter) there are Directory and File fields. I am expecting IP and user etc. fields for hadoop.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "73.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3540908", "text": "Hello,It looks like they did not document the Hadoop specific information for the managed adapters. They only put this information into the unmanaged adapters. I have logged a documentation bug for this: 762524 - Hadoop support not documented on managed adaptersSee if the Hadoop specific information about the 'Dir' parameter for the unmanaged adapters gives you the information you need to proceed: File/Hadoop CSV Output Adapter ConfigurationThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "73.4", "author": "Michael Jess", "url": "http://scn.sap.com/thread/3540908", "text": "Hi Jeff,the docs do not seem to cover the Hadoop authentication. I tried hdfs://user:password@host:9000/path, but this does not seem to do the trick. Is there some option I missed?Thanks,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "73.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3540908", "text": "Hello,The hdfs URL you show would seem correct. Were there any clues in the \"esp_server.log\" for your project? See the following section on how to find the \"esp_server.log\" file: SyBooks OnlineThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "73.6", "author": "Michael Jess", "url": "http://scn.sap.com/thread/3540908", "text": "Hi Neal,Thank you for your suggestion, but it seems there were no issues according to the log. All it says is:2014-04-29 16:09:28.205 | 9368 | container | [SP-4-108062] (187.932) sp(2036) GatewayClient::GatewayClient(9368:141) host:[<host>] has initiated a connection.2014-04-29 16:09:29.130 | 9368 | container | [SP-4-108008] (188.857) sp(2036) GatewayClient(9368:141)::execute() Client closed/dropped connection.2014-04-29 16:09:29.142 | 9368 | container | [SP-4-108001] (188.869) sp(2036) GatewayClient(9368:141)::~GatewayClient() destroyed (auto).When I set the CSV/Hadoop adapter URL to some local folder, ESP writes the output file just fine.Best regards,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "73.7", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3540908", "text": "Hi Michael,Based on what I see in the docs for File/Hadoop CSV Input Adapter Configuration, maybe try eliminating the user and password from the uri you are using.From:hdfs://user:password@host:9000/pathTo:hdfs://host:9000/pathThanks,AliceHere's what the docs say:To use Hadoop system files, use an HDFS folder uri instead of a local file system folder. For example,hdfs://<hdfsserver>:9000/<foldername>/<subfoldername>/<leaffoldername>.To use Hadoop, download the binaries for Hadoop version 1.2.1 fromhttp://hadoop.apache.org. Copy the hadoop-core.jar file (for example, for version 1.2.1hadoop-core-1.2.1.jar) to %ESP_HOME%\\adapters\\framework\\libj. Ensure you use a stable version rather than a beta.Use a forward slash for both UNIX and Windows paths.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "73.8", "author": "Michael Jess", "url": "http://scn.sap.com/thread/3540908", "text": "Hi Alice,I actually tried this before, but it did not work for me. Using the Java API I could confirm that authentication is really enabled and unauthorized connections are refused, so that there is no way for ESP to connect to Hadoop without magically guessing the user name Best regards,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "73.9", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3540908", "text": "Hello,I should have had you look at a different log. In ESP there are three logs:stdstreams.log - This log contains licensing information/errors.esp_server.log - This log contains information/errors about the project and certain adaptersframeworkadapter.log - This log contains information/errors about certain adapters (including the Hadoop adapter). In my testing I could see some errors in the \"frameworkadapter.log\". However, sometimes exceptions that are thrown to \"stderr\" only show up in stdstreams.log. I've been doing some testing and I finally have it working. First thing I should mention is it doesn't look like Hadoop itself accepts the user name/password in the URL: % hadoop fs -put test.txt hdfs://hadoopUser:Password1@servername.acme.com:9000/user/hadoop/data/test.txt put: Permission denied: user=nstack, access=WRITE, inode=\"/user/hadoop/data\":hadoop:supergroup:drwxr-xr-xBut there is a not-very-well-known environment variable that you can set: % setenv HADOOP_USER_NAME hadoopUser % hadoop fs -put test.txt hdfs://servername.acme.com:9000/user/hadoop/data/test.txtThis is essentially equivalent to setting it in your Java program: System.setProperty(\"HADOOP_USER_NAME\", \"hadoopUser\");You can edit $ESP_HOME/adapters/framework/bin/start.sh and set the Hadoop user name there: HADOOP_USER_NAME=hadoopUser;export HADOOP_USER_NAMEFor version 2.2.0, copy these files over to %ESP_HOME%\\adapters\\framework\\libj: hadoop-common-2.2.0.jar hadoop-auth-2.2.0.jar hadoop-hdfs-2.2.0.jar guava-11.0.2.jar protobuf-java-2.5.0.jar commons-cli-1.2.jar (SP04 requires but SP08 already has it)NOTE: There is a problem with ESP 5.1 SP04. When running the Hadoop Output Adapter inside a project (managed mode), I could not stop it. This was using the Hadoop 2.2.0 JAR files, I did not test Hadoop 1.2.1 because it can't communicate with Hadoop 2.2.0.This was not a problem with the upcoming release of ESP 5.1 SP08. Nor was it a problem with SP04 when running the adapter in unmanaged mode (started and stopped manually from outside the project).So if you wish to use ESP 5.1 SP04, run the adapter in unmanaged mode:1) Edit $ESP_HOME/adapters/framework/bin/start.sh and set the Hadoop user name there: HADOOP_USER_NAME=hadoop;export HADOOP_USER_NAME 2) Make a copy of the file output (and/or input) adapter: cp -Rf $ESP_HOME/adapters/framework/instances/file_csv_output /tmp cd /tmp/file_csv_output3) Edit the copy's adapter_config.xml file and change it so that it can run in unmanaged mode: a) Uncomment these lines and change the \"StreamName\" element to the stream in the project that the adapter should subscribe to. Leave \"ProjectName\" as is: <ProjectName>EspProject2</ProjectName> <StreamName>MyStream</StreamName> b) Change the \"Dir\" and \"File\" elements belonging to \"FileOutputTransporterParameters\": <Dir>hdfs://servername.acme.com:9000/user/hadoop/data</Dir> <File>neal_test.csv</File> c) Change the \"Uri\" element for the project \"EspProject2\" to point to your ESP project: <Uri>esp://esp_server_name.acme.com:51011/default/hadoop_test</Uri> d) Change the \"User\" and \"Password\" so the adapter can connect to the ESP project: <User>espadm</User> <Password encrypted=\"false\">Password1</Password> e) Start the adapter: ./start_adapter.sh d) Stop the adapter: ./stop_adapter.shThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Hadoop Adaptor Usage", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-06 10:36:00", "resolve": false, "uid": "74", "title": "run error", "url": "http://scn.sap.com/thread/3548744", "text": "hi,when the project start to run in ESP studio,it tips run error \"Invalid action:[FAILURE:Application wait for starus is started,but application current status is nit started]\".pls see the pic:who can tell me why and how to fix it.thanks,aaron", "views": "237", "answers": 6, "author": "aaron hu", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-05-06 14:04:00", "resolve": "", "uid": "74.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3548744", "text": "Hello,There are two log files in the directory: C:\\Users\\<user_name>\\Documents\\SybaseESP\\5.1\\workspace\\default.proj1.0* stdstreams.log - Contains information about licensing errors* esp_server.log - Contains information about the running of the project and other errors.My guess is that your license has expired.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:run error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "74.2", "author": "aaron hu", "url": "http://scn.sap.com/thread/3548744", "text": "thanks for your reply.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:run error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "74.3", "author": "aaron hu", "url": "http://scn.sap.com/thread/3548744", "text": "by the way.how can I change the default workspace dir.thanks.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:run error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "74.4", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3548744", "text": "Hi Aaron,It would be great if you could post your new question in a separate topic (that way others can find the topic and its answer).Also, if Neal's reply answered your question, please mark it answered.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:run error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "74.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3548744", "text": "Hi Aaron,You screen shot shows us that you are using Studio's \"local cluster\". This is a development sandbox that gets recreated each time you restart Studio. You can't change the workspace name in this cluster: Clusters If you go to %ESP_HOME%\\cluster\\nodes\\node1, there is a \"production\" cluster. In this file is a configuration parameter: <Persistence enabled=\"false\">You can set this to \"true\". Then when you start this node and connect to it, it will remember any workspaces you created and any projects that were loaded into it.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:run error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "74.6", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3548744", "text": "Hi Aaron,To change the default directory that ESP Studio uses for the workspace location, modify the Eclipse settings in the <esp install directory>/ESP-5_1/studio/esp_studio.ini file: osgi.instance.areaosgi.instance.area.default(The Eclipse docs are here: Eclipse runtime options)Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:run error", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-09 12:20:00", "resolve": true, "uid": "75", "title": "cannot find the hana output adapter, please help me.", "url": "http://scn.sap.com/thread/3551116", "text": "I have downloaded the latest version of ESP in SAP software Download center, here is the screenshotHowever, when I try to install the hana output adapter in the custom installation process, I couldn't find it. Here is the screenshot:please help me with it.", "views": "184", "answers": 1, "author": "Kevin He", "upvotes": 0, "type": "question", "tags": "adapter.esp_5.1.esp_hana"},
{"date_time": "2014-05-09 15:22:00", "resolve": "solution", "uid": "75.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3551116", "text": "Hi Kevin,The HANA Output Adapter is one of the adapters that is a part of every installation (assuming you installed ESP 5.1 SP04). It was not available until ESP 5.1 SP01. I know one of the links on the download site takes you to the ESP 5.1 GA release which did not have the HANA Output Adapter. Double check the version you installed. If you did not install ESP 5.1 SP04, see my blog post here on how to get it: Getting the latest release of ESP from the SAP Software Download CenterIf you did install SP04, it is already a part of the product. Use the \"F6\" key to toggle ESP Studio into the Visual Authoring mode. Then expand \"Output Adapters\" palette and choose the \"HANA Output Adapter\" by click on it once and then clicking on the canvas once. See the attached screen shot:Make sure you have installed the HANA ODBC driver and add an entry to ESP's \"service.xml\" file as described here and you should be good to go: SAP HANA Output AdapterThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:cannot find the hana output adapter, please help me.", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-09 12:37:00", "resolve": true, "uid": "76", "title": "how to prevent the db adapter, which is attached to a window, from deleting data in database when the data in the attached window has expired?", "url": "http://scn.sap.com/thread/3551117", "text": "Here is the problem I've got: In the ESP project, I have a window that do some operations on the input data, and I have a db adapter that attach the window and insert the data in the database. At first, every row in the window will be inserted in the database. But as time goes by, some rows in the windows will expire, and at the same time, the db adapter will make the database also delete the corresponding data in database.  In my case, I don't want the db adapter to delete any rows in the database. Can anyone help me?", "views": "204", "answers": 1, "author": "Kevin He", "upvotes": 0, "type": "question", "tags": "adapter.esp"},
{"date_time": "2014-05-09 15:30:00", "resolve": "solution", "uid": "76.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3551117", "text": "Kevin - there are a couple of different ways to address this, depending on the use case. Start by reading this post. The simplest is to configure the adapter for Data Warehouse mode - if that works for your use case.And if that doesn't meet your needs, there are other options that can be considered:- feed the window through a stream (which will strip out the deletes)- set up a Flex operators to filter based on opCodes or otherwise transform events - including their opCodes- and it doesn't sound like you are using updates, but just an FYI, there is a new feature coming in SP08 called \"Keyed Streams\" that adds some additional flexibility", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:how to prevent the db adapter, which is attached to a window, from deleting data in database when the data in the attached window has expired?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-09 17:52:00", "resolve": true, "uid": "77", "title": "What is the most efficient way to convert TIMESTAMP to BIGDATETIME?", "url": "http://scn.sap.com/thread/3551322", "text": "I'll probably fumble my way into a solution here (because I have none at the moment) but hoping someone chimesin with their favorite way to do this.Thanks,Michael", "views": "228", "answers": 2, "author": "Michael Scharber", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-05-09 18:25:00", "resolve": "solution", "uid": "77.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3551322", "text": "Hello,I have a couple of ways to do it:CREATE INPUT WINDOW INWINDOW SCHEMA (C_Integer integer,C_Bigdatetime bigdatetime,C_Timestamp timestamp,C_Date date,C_Long long,C_String string,C_Money2 money(2),C_Money7 money(7),C_Binary binary,C_Float float) PRIMARY KEY ( C_Integer ) ;CREATE OUTPUT WINDOW OUTWINDOW SCHEMA ( Column1 integer , Column2 bigdatetime , Column3 bigdatetime ) PRIMARY KEY ( Column1 ) AS SELECT IW.C_Integer as Column1, cast(bigdatetime,IW.C_Timestamp) as Column2, to_bigdatetime(to_long(IW.C_Timestamp)*1000) as Column3 FROM INWINDOW IW ;You can test it with esp_subscribe:%ESP_HOME%\\bin\\esp_subscribe -c studio:studio -p localhost:9786/default/p6 -s INWINDOW,OUTWINDOW<INWINDOW ESP_OPS=\"i\" C_Integer=\"500\" C_Bigdatetime=\"2014-05-10 04:10:26.609123\" C_Timestamp=\"2014-05-10 04:10:26.609\" C_Date=\"1970-01-01 19:12:12\" C_Long=\"76\" C_String=\"string\" C_Money2=\"2.22\" C_Money7=\"7.7777777\" C_Binary=\"42696E6172792064617461\" C_Float=\"3.141590\"/><OUTWINDOW ESP_OPS=\"i\" Column1=\"500\" Column2=\"2014-05-10 04:10:26.609000\" Column3=\"2014-05-10 04:10:26.609000\"/>Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:What is the most efficient way to convert TIMESTAMP to BIGDATETIME?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "77.2", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3551322", "text": "Perfect. Thanks Neal.I've gone with this approach :to_bigdatetime(to_long(a.timestamp_column)*1000) and wrapped it with totimezone to move my implied EST timestamps into true GMT bigdatetime values.totimezone(to_bigdatetime(to_long(a.timestamp_column)*1000),'EST','GMT')This is working well for me.Greatly appreciated.Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:What is the most efficient way to convert TIMESTAMP to BIGDATETIME?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-15 11:44:00", "resolve": true, "uid": "78", "title": "File/Hadoop Csv Input Adapter Cannot Read File", "url": "http://scn.sap.com/thread/3554199", "text": "Here is the problem: I want to use to file/hadoop csv input adapter to load a test.csv file into the attached window. The following is the snap screen.And the corresponding csv file is like this:1,a2,b3,cBut, when I started the project, I found nothing in the window, and then I checked the adapter run-time information, and I found this:It seems that the adapter read nothing.I am sure that the dir path and file path is correct, and there is no errors printed on the console.So, what should I do?", "views": "224", "answers": 2, "author": "Kevin He", "upvotes": 0, "type": "question", "tags": "adapter.esp_5.1"},
{"date_time": "2014-05-15 16:19:00", "resolve": "solution", "uid": "78.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3554199", "text": "Hi Kevin,There are two choices you have for solving this.Choice 1: Set the adapter property of Stream name, opcode expected to FALSE, since it defaults to TRUE.orChoice 2: Change the format of your csv file's records to include the stream name and opcode, so that your csv file records look like this:InputWindow1,i,1,aInputWindow1,i,2,bInputWindow1,i,3,cYou will find more information about the adapter run-time in the frameworkadapter.log file for the project. Since you are running the project in Studio's local cluster, the log file will be here:<user's-home-dir>/SybaseESP/5.1/workspace/default.ftpcvstest.0/logs/frameworkadapter.logThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:File/Hadoop Csv Input Adapter Cannot Read File", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "78.2", "author": "Kevin He", "url": "http://scn.sap.com/thread/3554199", "text": "Hi Alice, Thank you for the answer, I have solved this by using the choice 1. And also thank you for the invitation to the ESP internal community.Best, RegardsKevin", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File/Hadoop Csv Input Adapter Cannot Read File", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-23 15:24:00", "resolve": true, "uid": "79", "title": "getData() to insert data into HANA", "url": "http://scn.sap.com/thread/3559142", "text": "Hi there,we struggle while using the getData() function to insert data into HANA.Here is our test coding: typedef [  binary HeaderId;  Timestamp \"Timestamp\"; string SystemType; string SystemId; | ] ts_Log_Header ;vector ( ts_Log_Header ) lt_Log_Header ; getData( lt_Log_Header, 'ServiceHDBANA', 'Insert into \"SAP_SEC_MON\".\"sap.secmon.db::Log.LogHeader\" values ( ?, ?, ?,? )', WithNullIDs.HeaderId, WithNullIDs.\"Timestamp\", 'PILLE', '');We see the following error in the console output as well as in the project log file:Error:2014-05-23 14:41:46.718 | 6924 | container | [SP-3-100005] (18.299) sp(18744) Error retrieving column 1 value from result set. 2014-05-23 14:41:46.718 | 6924 | container | [SP-3-100005] (18.299) sp(18744) A result row is skipped due to error retrieving column data.2014-05-23 14:41:46.718 | 6924 | container | [SP-3-104003] (18.299) sp(18744) Error in function 'getData': Error iterating result set2014-05-23 14:41:46.734 | 6924 | container | [SP-4-131038] (18.315) sp(18744) Stream(): error occurred in computation of row.The according schema of the table in HANA looks like this:CREATE COLUMN TABLE \"SAP_SEC_MON\".\"sap.secmon.db::Log.LogHeader\" (\"HeaderId\" VARBINARY(16) CS_RAW, \"Timestamp\" LONGDATE CS_LONGDATE, \"SystemType\" NVARCHAR(50), \"SystemId\" NVARCHAR(5000))Any help would be appreciated.Or is there any example coding available ?Were using ESP SP04 on a windows machine.", "views": "500", "answers": 2, "author": "Hartwig Seifert", "upvotes": 1, "type": "question", "tags": ""},
{"date_time": "2014-05-23 23:32:00", "resolve": "solution", "uid": "79.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3559142", "text": "Hi,Create a procedure in HANA that handles the insert, and have it return a dummy record, something similar to this:HANA Procedure:CREATE PROCEDURE insert_stock (symbol varchar(10), volume integer, price float)LANGUAGE SQLSCRIPT ASBEGIN INSERT INTO \"SYSTEM\".\"stock\" values(symbol, volume, price); SELECT ::ROWCOUNT FROM DUMMY;ENDESP CCL:CREATE INPUT stream StockStream SCHEMA (symbol string, volume integer, price float);CREATE Flex stock_flex IN StockStream OUT OUTPUT STREAM stock_traded SCHEMA(symbol string, volume integer, price float) BEGIN DECLARE /* The typedef must be the same as the return value of the stored procedure. */ typedef [integer dummydata;|] datarec;  /* dummydatarec is a vector variable to store the return value of the stored procedure */ vector(datarec) dummydatarec; END;  ON StockStream { if ( isnull(dummydatarec) ) { dummydatarec := new vector(datarec);  } getData(dummydatarec, 'HANAODBCService',  'CALL \"SYSTEM\".\"INSERT_STOCK\" (?,?,?)',  StockStream.symbol, StockStream.volume, StockStream.price ); resize(dummydatarec,0); };  END;Hope that helps!Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:getData() to insert data into HANA", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "79.2", "author": "Hartwig Seifert", "url": "http://scn.sap.com/thread/3559142", "text": "perpfect, works fine !thanks a lot!", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:getData() to insert data into HANA", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-27 18:48:00", "resolve": true, "uid": "80", "title": "Can DB Generic Ouput adapter be used in \"warehouse\" mode?", "url": "http://scn.sap.com/thread/3560929", "text": "Hello,I'm using Greenplum (Generic DB Output adapter in ESP) and started getting this response now after a few millionrecords are in my target table :ConnectionWriter(ESPToDbTableB) is started.2014-05-27 16:42:26.301 | 20622 | container | [SP-3-100005] (2468.241) sp(3349) Error executing SQL statement select * from wh._esp_b_stream. java.lang.OutOfMemoryError: GC overhead limit exceeded2014-05-27 16:42:26.301 | 20622 | container | [SP-3-148011] (2468.241) sp(3349) ConnectionWriter(ESPToDbTableB) connection reset error: 2014-05-27 16:42:26 DBOutput_Adapter::resetConnection - executeQuery not successful - resetConnection() ended abnormallyThe adapter is connected to a Stream in my ESP project, but only recently. Previous to being a Stream, it was a Flex Window. I would likesimple - blind inserts from the ESP project.....but it appears the adapter does not know this and is trying to pull in the entire contents of the table beforeinitializing and getting started.Any advice greatly appreciated, as usual.Thank youMichael", "views": "241", "answers": 4, "author": "Michael Scharber", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-05-27 19:24:00", "resolve": "", "uid": "80.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3560929", "text": "Hi Michael,I'm a little confused by the statement \"it appears the adapter does not know this and is trying to pull in the entire contents of the table before initializing and getting started\". The DB Output Adapter would not read the contents of a database table. It only writes to the DB table.Do you have a WINDOW with the Generic Database Input Adapter attached to it somewhere else in your project?Assuming that you are using ESP 5.1 SP04, there is a memory leak in the Generic DB Input Adapter: 751392 - Memory leak in Generic DB Input adapter causes ESP to crashThis has been fixed in ESP 5.1 SP08 scheduled for release this week and a special ESP 5.1 SP04 ONE-OFF patch available from technical support.The DB Output Adapter does not have a \"warehouse\" mode but this could be achieved by passing the data through a stream (or a flex stream): Comparing Streams, Windows, and Delta StreamsSP08 introduces a new feature for the Database Input Adapter whereby you can specify a \"key\" column that it uses to remember where it left off so it only pulls in rows that are new since the last time it polled the database.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can DB Generic Ouput adapter be used in \"warehouse\" mode?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "80.2", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3560929", "text": "Hi Neal,I'm confused as well. My CCL statement is : ATTACH OUTPUT ADAPTER ESPToDbTableB TYPE db_out TO ESPToStorage PROPERTIES service = 'my_db' , table = 'wh._esp_b_stream' ;Yes - we are using ESP 5.1 SP04, and no, this is not an input from a DB but rather an output to a DB (from a stream).Why the \"select * \" rears up as the adapter is initializing?Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can DB Generic Ouput adapter be used in \"warehouse\" mode?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "80.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3560929", "text": "Hello,I turned on ODBC tracing and I see that the Generic Database Output Adapter does indeed issue a \"select *\" against the database. It issues the query to get a list of the columns and their types. It should be doing a \"select * from table where 1=2\" so that no rows are ever returned.I have logged the following bug for this issue: 764785 - Generic Database Output Adapter issues select * against databaseESP uses the result set from this query to get a description of the table and then it disposes of the result set. I don't see this causing it to use excessive amounts of memory. I have a table with 3 million rows and five columns. When I start my project with the Generic Database Output Adapter, I never see it consume more than 55 MB of physical memory.At this point you should probably open a technical support case so this bug can be prioritized with engineering. In the technical support case, if you could provide the project's complete \"esp_server.log\" log file, the \"stdstreams.log\" log files and your CCL, it might help us see why you are getting the out of memory error.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can DB Generic Ouput adapter be used in \"warehouse\" mode?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "80.4", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3560929", "text": "Thanks Neal. That makes sense now. I don't like it, but it makes sense.I'll work around it for now, and try to find some time to book the case to get the fix prioritized.Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can DB Generic Ouput adapter be used in \"warehouse\" mode?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-28 10:25:00", "resolve": true, "uid": "81", "title": "Newbie Question: Simple Way to use HANA Output Adepter", "url": "http://scn.sap.com/thread/3561279", "text": "Hi ESP experts,i am new to ESP and have a simple question:Whats do i have to do to use the HANA Output Adapter? I found this article here: Sybase ESP Integration with SAP HANABut it isn't working. If i am editing the services.xml and put in my connection details in \"SampleHanaJDBC\" and use the outut adapter, it says \"schema discovery not supportet. Do i have to ask my basis team to do something? Is there a another guide how to use it?", "views": "250", "answers": 1, "author": "Andreas Hohl", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-05-28 14:47:00", "resolve": "solution", "uid": "81.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3561279", "text": "Hello,Have you copied the HANA client JAR \"ngdbc.jar\" to %ESP_HOME%\\libj ? You have to obtain it separately in the HANA Client distribution. For any JDBC connection, you have to get the targets JDBC driver and copy it to this directory.Most people use the HANA ODBC driver (also available in the HANA Client distribution) to connect ESP to HANA. Detailed instructions are here: SAP HANA Output AdapterOnce you install the HANA client, configure an ODBC DSN for your HANA database. Do a \"Test Connection\" with the ODBC Administrator. If this succeeds, you can use this DSN in your ESP \"service.xml\" and discovery should work.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Newbie Question: Simple Way to use HANA Output Adepter", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-30 05:23:00", "resolve": true, "uid": "82", "title": "Cann't read data from socket csv input adapter", "url": "http://scn.sap.com/thread/3562648", "text": "Here is the ccl code:CREATE INPUT WINDOW InputWindow1 SCHEMA ( id INTEGER , name string , age INTEGER ) PRIMARY KEY ( id ) KEEP ALL ROWS ;ATTACH INPUT ADAPTER Socket_CSV_Input1 TYPE toolkit_socket_csv_input TO InputWindow1 PROPERTIES host = '10.128.162.179' , port = 4700 , csvExpectStreamNameOpcode = FALSE , csvDelimiter = ',' , csvHasHeader = FALSE ;And I have a simple JAVA socketserver to publish data, and here is the java code:However, when I tried to run the java project and esp project, I got nothing in the window. The log file in esp said that: received record for unknown stream. Index: 16In the java project console, it shows that the socketserver worked fine, and publish data every 1 second.So, how can I fix this problem?", "views": "491", "answers": 2, "author": "Kevin He", "upvotes": 0, "type": "question", "tags": "adapter.socket"},
{"date_time": "2014-05-30 16:28:00", "resolve": "solution", "uid": "82.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3562648", "text": "Hi Kevin,Check your project's \"frameworkadapter.log\" file. It will contain errors related to the toolkit based adapters (identifiable by the TYPE in your CCL). When I run your reproduction I see:05-30-2014 14:08:52.239 ERROR [Thread-18] (CSVInputFormatter.parseCSV) Error code:402002, Severity : 3 (Error)Error message:CSV line contains 1 fields, expected 3.Error description:CSV line contains 1 fields, expected 3.05-30-2014 14:08:52.240 ERROR [Thread-18] (CSVInputFormatter.convert) Error code:402005, Severity : 3 (Error)Error message:CSV Formatter failed to convert a string: ??This tells me that there is a mismatch in what your Java program is sending and what the ESP adapter is expecting. I think ObjectOutputStream sends some extra information. According to the Java docs (http://docs.oracle.com/javase/7/docs/api/java/io/ObjectOutputStream.html), ObjectOutputStream outputs:\"Primitive data, excluding serializable fields and externalizable data, is written to the ObjectOutputStream in block-data records. A block data record is composed of a header and data. The block data header consists of a marker and the number of bytes to follow the header. Consecutive primitive data writes are merged into one block-data record. The blocking factor used for a block-data record will be 1024 bytes. Each block-data record will be filled up to 1024 bytes, or be written whenever there is a termination of block-data mode. Calls to the ObjectOutputStream methods writeObject, defaultWriteObject and writeFields initially terminate any existing block-data record.\"I think ESP is just looking for a CSV string so if I change your code as follows it works for me: //private ObjectOutputStream out; private PrintStream out;  //out = new ObjectOutputStream(client.getOutputStream()); out = new PrintStream(client.getOutputStream(),true);  out.println(++i + \",kevin,20\"); //out.writeObject(++i + \",kevin,20\"); //out.flush(); If you are not sure what format an adapter is expecting, it helps to look at the \"adapter_config.xml\" file (%ESP_HOME%\\adapters\\framework\\instances\\socket_csv_input\\adapter_config.xml) and then look at either: Transporter Modulesor Formatter ModulesThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Cann't read data from socket csv input adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "82.2", "author": "Kevin He", "url": "http://scn.sap.com/thread/3562648", "text": "Hi Neal, Thanks for your answer, and I have solve this problem, but in another way. I replace the ObjectOutputStream with DataOutputStream, and use the methed \"writeBytes\". In this way, I also get the right workflow. Anyway, thank you all the same.Best Regards,Kevin", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Cann't read data from socket csv input adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2014-06-03 16:44:00", "resolve": true, "uid": "83", "title": "Problem connecting ESP to IQ", "url": "http://scn.sap.com/thread/3564738", "text": "Hi there,We are currently attempting to load data from ESP into SAP Sybase IQ usingthe SAP Sybase IQ Output Adapter but we are receiving the following error: IQAdapter, IQOutput, sybase_iq_out, 0,, DEAD, 0, 0, 0, 2014-05-23 16:33:01, Unable to establish a DB connection forIQODBCService service.[01000][0][[unixODBC][DriverManager]Can't open lib'/home/cisco/sybase/IQ_Client/IQ-16_0/lib64/libdbodbc16_r.so' : file not found]Unable to get connection to thedatabase., NULLWe have double-checked the directory and the file definitely exists and isexecutable. We have also added the directory /home/cisco/sybase/IQ_Client/IQ-16_0/lib64to the LD_LIBRARY_PATH in sybase.sh. The IQ ODBC driver has been successfullyinstalled on the ESP system, so there should be no issue there either. Do you know where we might be going wrong?Kind regards,Richard", "views": "591", "answers": 11, "author": "Richard Lowe-Lauri", "upvotes": 0, "type": "question", "tags": "sap_sybase_event_stream_processor.sap_sybase_iq.output.adapter.esp"},
{"date_time": "2014-06-03 18:23:00", "resolve": "", "uid": "83.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3564738", "text": "Hi Richard,1. Confirm that the version of unixODBC driver you are using is version 2.3.0 or higher: a. check that LD_LIBRARY_PATH has the correct unixODBC directory included - some flavors of Linux come with unixODBC pre-installed to one directory. System Admins install it to a second directory. So you need to make sure you know which one is in your LD_LIBRARY_PATH. b. run the command odbcinst -j to get the version 2. Confirm that ESP can find unixODBC's driver manager, libodbc.so.1  a. cd to <esp_install_dir>/lib b. run the command ldd libesp_db_odbc64_lib.so, e.g.$ ldd libesp_db_odbc64_lib.so linux-vdso.so.1 => (0x00007ffff33ff000) libodbc.so.1 => /usr/local/lib/libodbc.so.1 (0x00007fcae0f1e000)...3. Run the command ldd /home/cisco/sybase/IQ_Client/IQ-16_0/lib64/libdbodbc16_r.so and make sure the output for it indicates that all libraries are found4. Check your .odbc.ini file settings for the IQ DSN, similar to this:[my_IQ]Driver = /home/cisco/sybase/IQ-Client/IQ-16_0/lib64/libdbodbc16_r.soDescription = Sybase IQ ServerDatabaseName=iqdemoServerName=ffiqCommLinks=tcpip{host=myhost.com;port=16238}5. Confirm that your <esp_install_dir>/bin/service.xml settings match what's in your .odbc.ini file, similar to this: <Service Name=\"IQ_Service\" Type=\"DB\"> <Parameter Name=\"DriverLibrary\">esp_db_odbc64_lib</Parameter> <Parameter Name=\"DSN\">my_IQ</Parameter> <Parameter Name=\"User\">DBA</Parameter> <Parameter Name=\"Password\">sql</Parameter> </Service>Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.2", "author": "Richard Lowe-Lauri", "url": "http://scn.sap.com/thread/3564738", "text": "Hi Alice,Thank you for the comprehensive response. I have followed each of your proposed steps and have included the outcome of each in turn below.1. I can confirm that the unixODBC driver version is 2.3.1. It also looks like LD_LIBRARY_PATH has the correct unixODBC directory included. The IQ driver library is also included here.  2. By the looks of it, ESP can find unixODBC's driver manager without a problem. 3. I have run the requested command and everything appears to be in order except libdbtasks16_r.so. Could this be an issue?4. I have checked the .odbc.ini file settings and these seem fine.[Exact ServerName, DatabaseName and Database File removed for security reasons]. I presume defining the IQ user ID and password in both this file and the service.xml file is inconsequential?  5. The service.xml file settings correctly match up with the .odbc.ini file settings (along with the configuration parameters detailed in the ESP ccl file).Can you spot anything from the above that we might be missing?Richard", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3564738", "text": "For #3, libdbtasks16_r.so not found - that needs to get resolved.It should be located in /home/cisco/sybase/IQ-Client/IQ-16_0/lib64. Is it there?Do you have permissions to it?For #4, the user and password specified in the service.xml file are the ones that get used.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.4", "author": "Richard Lowe-Lauri", "url": "http://scn.sap.com/thread/3564738", "text": "Hi Alice,I have had a good look for libdbtasks16_r.so but could not find it anywhere. It is not in /home/cisco/sybase/IQ_Client/IQ-16_0/lib64.Nor is it in any directory such as /lib or /home/cisco/sybase/ESP-5_1/lib. A simple search did not return anything either.Is this missing file likely to be the root of our issue?Richard", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.5", "author": "Richard Lowe-Lauri", "url": "http://scn.sap.com/thread/3564738", "text": "I have now copied the libdbtasks16_r.so file from another server to the /home/cisco/sybase/IQ_Client/IQ-16_0/lib64 directory on our ESP server so it can now be found.However, when I try to run ESP I now get a different error message:IQAdapter, IQOutput, sybase_iq_out, 0, , DEAD, 0, 0, 0, 2014-06-04 12:41:01, Unable to establish a DB connection for IQODBCService service.[IM004][0][[unixODBC][Driver Manager]Driver's SQLAllocHandle on SQL_HANDLE_HENV failed]Unable to get connection to the database., NULL", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3564738", "text": "Hi Richard,The fact that \"libdbtasks16_r.so\" was missing is very concerning. This would indicate that your IQ installation is incomplete and there could be other files missing.Before worrying about ESP connecting to IQ, lets try connecting with the unixODBC driver's \"isql\" utility:/usr/local/unixODBC/bin/isql -v your_DSN_here your_user your_passwordWhat output does this give you?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.7", "author": "Richard Lowe-Lauri", "url": "http://scn.sap.com/thread/3564738", "text": "Hi Neal,Running the specified command gives me the following output:Thanks,Rich", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.8", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3564738", "text": "Hello,It looks like there is a space between \".../bin\" and \"isql\" so you ended up executing Sybase's \"isql\" utility instead of unixODBC's. So make sure you execute it without spaces:/usr/local/unixODBC/bin/isql -v IQ dba sqlNOTE: I believe that in more recent releases of IQ, the user \"dba\" is capitalized.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.9", "author": "Richard Lowe-Lauri", "url": "http://scn.sap.com/thread/3564738", "text": "Thanks for heads up Neal,There was actually no space. I just executed the command directly from the /usr/local/unixODBC/bin directory. Specifying the full directory in the command, however, gave me the following output (with both dba and DBA):This is the same message I get when I try to connect ESP to IQ.Richard", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "83.10", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3564738", "text": "Hello,Can you email me the following: /home/cisco/sybase/IQ_Client/log/iq_client_common.log odbcinst -j > odbc_version.out env > env.outThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "83.11", "author": "Richard Lowe-Lauri", "url": "http://scn.sap.com/thread/3564738", "text": "Hi all,Thanks to Neal and Alices help we have now resolved this issue. Ultimately there were two problems that needed to be fixed:The IQ ODBC driver was originally installed independently, but the installation did not appear to be completely successful and certain files (such as libdbtasks16_r.so) were missing. We solved this by uninstalling the driver and installing the full IQ Client.Because our IQ database was already running, we did not need the DatabaseFile parameter in our .odbc.ini file. Once this was removed we were able to connect to IQ successfully.Many thanks for all your help once again.Richard", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem connecting ESP to IQ", "type": "answer", "tags": "N/A"},
{"date_time": "2014-05-28 06:43:00", "resolve": false, "uid": "84", "title": "ESP - MQ High Availability options", "url": "http://scn.sap.com/thread/3561125", "text": "Hi there,My organisation (DHS Australia) have recently upgraded our Websphere Message Broker environment from v7 to v8.As part of this upgrade, in our Production environment we are now running 4 queue managers, the idea behind this is that it helps to provide a higher level of availability (i.e. basically if one queue manager goes down, the others can pick up its load).The ESP MQ adapter currently only allows for connection to the one queue manager, so in our ESP-MQ implementation we are exploring possibilities of how we can possibly get the output from ESP shared across the 4 queue managers. We are looking at a number of options within MQ/Broker itself (eg. clustered queue definitions, clustered queue manager etc), and currently doing some testing to see how/if this works with the supplied ESP MQ adapters.However, my question for the ESP community/tech-team is whether there has been any thought to implementing something similar to how SAP PI can connect to MQ in a High Availability sense? For example, see this blog post:http://scn.sap.com/people/anandan.krishnamoorthy/blog/2010/06/08/high-availability-in-jms-adapterHas there been any thought given to whether the ESP MQ adapter can be enhanced or configured to use a MQ Client Channel Definition Table, as an alternative connection configuration method?Cheers,Jason.", "views": "1002", "answers": 2, "author": "Jason Kelly", "upvotes": 0, "type": "question", "tags": "websphere.esp.mqadapter"},
{"date_time": "2014-05-28 17:51:00", "resolve": "", "uid": "84.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3561125", "text": "Jason - this isn't something that is currently on the ESP roadmap, but perhaps it should be. I'll be interested to see if others in the community have other perspectives on this, or experience doing something similar.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP - MQ High Availability options", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "84.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3561125", "text": "Jason - just an update. The ESP development team are looking into this, and we may be able to add this feature to the MQ adapter. I'll let you know what they conclude.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP - MQ High Availability options", "type": "answer", "tags": "N/A"},
{"date_time": "2014-06-23 10:48:00", "resolve": true, "uid": "85", "title": "SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "url": "http://scn.sap.com/thread/3575487", "text": "Hello all,we need our help regarding the StockTrader example project that is delivered with SAP Sybase Event Stream Processor (Sybase ESP 5.1).we want to build a simple Web Service and follow the instructions as described in the Sybase Infocenter. We have attached a screenshot (\"Sybase InfoCenter\") that contains the described steps (as copying the URL always lead to a wrong page).We have problems with Step 10 (\"Start the ESP project by running the start_project.bat or start_project.sh script.\"). We get the error message \"Invalid URI\" as you can see in screenshot \"[error] Invalid Uri\". Previously we started the \"start_node.bat\" (Step 9) - see also screenshot \"[error] Invalid Uri\".Like in steps 6 and 7 mentioned, we have changed the parameters \"USER\" and \"PASSWORD\" of the adapter_config.xml files and the parameters \"ADAPTER_EXAMPLE_USERNAME\"and \"ADAPTER_EXAMPLE_PASSWORD\" of theset_example_env.bat files. Here, we were a bit confused wether we should change these parameters in all those files as there are 4 adapter_config.xml and 4 set_example_env.bat files. Please refer to the attached screenshot (\"changed files\").Does anyone know why this error occurs and how to continue to complete the Web Service?Later we want to push data with this Web Service into a SAP HANA database table.We are thankful for any input and help.Regards, Andreas", "views": "2226", "answers": 9, "author": "Andreas Fuchs", "upvotes": 0, "type": "question", "tags": "sap_hana.sap_sybase_event_stream_processor.sybase.adapter.cep.esp.esp_5.1.esp_developer.soap_adapter.webservice;.esp_studio"},
{"date_time": "2014-06-23 17:13:00", "resolve": "solution", "uid": "85.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3575487", "text": "Hello,Unless you changed the user name and password of the example cluster in %ESP_HOME%\\cluster\\examples, they should be set as follows in \"set_example_env.bat\" and \"adapter_config.xml\":User name = sybasePassword = sybaseNOTE: You should only have to change the \"set_example_env.bat\" and \"adapter_config.xml\" of the example you are running. So in your case it looks like you are running the \"input\" example and should only have to change those two files.As far as the specific error about an invalid URI, I can't tell what the URI was set to. When you call \"start_project.bat\", this file calls three other scripts: call \"%ADAPTER_EXAMPLE_BIN%\\compile.bat\" call \"%ADAPTER_EXAMPLE_BIN%\\add_project.bat\" call \"%ADAPTER_EXAMPLE_BIN%\\start_project.bat\"(these should all be found in %ESP_HOME%\\adapters\\webservices\\examples\\bin)Edit each of these files and turn the echo on and rerun \"start_project.bat\" so we can see the output: @echo onThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 2, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "85.2", "author": "Andreas Fuchs", "url": "http://scn.sap.com/thread/3575487", "text": "Hello Neal,thanks a lot for your fast reply. Your answer helped us, simply changing the username and password to 'sybase' made the project run and we can see now that data is generated.But we have a next question and hope that you can help us again. We are trying to get the data of the webservice into an InputStream or InputWindow in Sybase ESP Studio but after compiling and running the project, no data is displayed in the stream.In the attached file (\"adapter properties\") you can see our project in Sybase ESP Studio and the parameters of the WebService.We are not sure if the parameters like \"Discovery Working Directory\" have the correct path.Moreover, you find the console output in the file \"bat-files\". Here we get some warnings like \"The server localhost failed to respond\".Finally, in the attached screenshot (\"run project\") you can see that we get no data in the InputStream in ESP Studio and also the log output in the ESP Studio console.Sorry to bother you again.Thanks for your effort and help,Andreas", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "85.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3575487", "text": "Hello,In the future, if you could start a new post with each question, it helps other users find answers quicker. It makes it more difficult to find an answer when we just keep appending on to a post.I have filed the following bug for this issue: 766294 - Web Services SOAP adapter does not work in managed modeThe work around is to edit %ESP_HOME%\\adapters\\webservices\\examples\\input\\adapter_config.xml and make the following two changes:1) Comment out the following two lines: <Module type=\"espconnector\"> <InstanceName>StockTraderServicePublisher</InstanceName> <Name>EspPublisher</Name> <Parameters> <EspPublisherParameters> <!--Uncomment the following 2 elements when you use 'start_adapter[.bat|.sh]' --> <!--ProjectName>StockTraderProject</ProjectName--> <!--StreamName>tradesIn</StreamName--> </EspPublisherParameters> </Parameters> </Module> </Modules>2) The full path must be specified to the 'mappingFile' parameter:<mappingFile>C:/ESP51/ESP-5_1/adapters/webservices/examples/input/stockTraderMappings.xml</mappingFile>Then try the following CCL in your project and it will work:CREATE SCHEMA tradesSchema ( buyerId INTEGER, sellerId INTEGER, supervisorId INTEGER, tradeTime LONG, amount INTEGER, price FLOAT, symbol STRING);CREATE INPUT STREAM tradesIn SCHEMA tradesSchema;CREATE OUTPUT STREAM tradesOut SCHEMA tradesSchema AS SELECT * FROM tradesIn;/* * mapFilePath is currently ignored and must be set via the mappingFile configuration parameter * in the given adapter configuration file (configFilePath). */ATTACH INPUT ADAPTER Web_Services__SOAP__Input__external_1 TYPE soapinput TO tradesIn PROPERTIES configFilePath = 'C:/ESP51/ESP-5_1/adapters/webservices/examples/input/adapter_config.xml' , mapFilePath = 'C:/ESP51/ESP-5_1/adapters/webservices/examples/input/stockTraderMappings.xml' ,  jdkHome = 'C:/Program Files/Java/jdk' , discoveryWsdl = 'http://localhost:8080/axis2/services/StockTraderService?wsdl' , discoveryWorkingDir = 'C:/temp/webservices_example' , discoveryServiceName = 'StockTraderService' ;", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "85.4", "author": "Andreas Fuchs", "url": "http://scn.sap.com/thread/3575487", "text": "Hi Neal,thanks for your reply. We tried all possible combinations of values for the path variables but we receive only \"NULL\" data in the console ouput of Sybase ESP Studio (see screenshot \"console output). In the attachement you find our adapter_config.xml file where we uncommented these lines (<!--ProjectName>StockTraderProject</ProjectName--> <!--StreamName>tradesIn</StreamName-->).Do you know what the problem could be? Thanks...This is our ccl Code:CREATE SCHEMA tradesSchema ( buyerId INTEGER, sellerId INTEGER, supervisorId INTEGER, tradeTime LONG, amount INTEGER, price FLOAT, symbol STRING );CREATE INPUT STREAM tradesIn SCHEMA tradesSchema;CREATE OUTPUT STREAM tradesOut SCHEMA tradesSchema  AS SELECT * FROM tradesIn;/* * mapFilePath is currently ignored and must be set via the mappingFile configuration parameter * in the given adapter configuration file (configFilePath). */ATTACH INPUT ADAPTER Web_Services_SOAP_Input_Adapter TYPE soapinput TO tradesIn PROPERTIES configFilePath = 'C:/Sybase/ESP-5_1/adapters/webservices/examples/input/adapter_config.xml' , mapFilePath = 'C:/Sybase/ESP-5_1/adapters/webservices/examples/input/stockTraderMappings.xml' , jdkHome = 'C:/Software/Java/jdk' , discoveryWsdl = 'http://localhost:8080/axis2/services/StockTraderService?wsdl' , discoveryWorkingDir = 'C:/tmp/adapter/soap' , discoveryServiceName = 'StockTraderService' ;", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "85.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3575487", "text": "Hello,I'm not sure. I think we need see the adapter's and the project's log files. I'm not sure which cluster you are running the project in so there are a number of places to look for the log files.1) Local cluster (started in Studio and listening to port 9786): * C:\\Users\\<user_name>\\Documents\\SybaseESP\\5.1\\workspace\\default.webservices_input_example.0\\logs\\frameworkadapter.log * C:\\Users\\I825186\\Documents\\SybaseESP\\5.1\\workspace\\default.webservices_input_example.0\\esp_server.log2) Remote cluster (started at command line using the %ESP_HOME%\\cluster\\nodes\\node1\\node1.xml cluster configuration file): * %ESP_HOME%\\cluster\\projects\\test-name-1\\default.webservices_input_example.0\\logs\\frameworkadapter.log * %ESP_HOME%\\cluster\\projects\\test-name-1\\default.webservices_input_example.0\\esp_server.log3) Example cluster (started at command line using the %ESP_HOME%\\cluster\\examples\\node1.xml file): * %ESP_HOME%\\cluster\\examples\\projects\\default.webservices_input_example.0\\logs\\frameworkadapter.log * %ESP_HOME%\\cluster\\examples\\projects\\default.webservices_input_example.0\\esp_server.logThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "85.6", "author": "Andreas Fuchs", "url": "http://scn.sap.com/thread/3575487", "text": "Hi Neal,thanks for you reply.We have uploaded all logfiles we could find to dropbox (as we can only attach 3 files here).The Link is: Dropbox - SAP Sybase ESP Logfiles 26.06.2014At the following paths we can't find any logfiles:* %ESP_HOME%\\cluster\\projects\\test-name-1\\default.webservices_input_example.0\\logs\\frameworkadapter.log* %ESP_HOME%\\cluster\\projects\\test-name-1\\default.webservices_input_example.0\\esp_server.log* %ESP_HOME%\\cluster\\examples\\projects\\default.webservices_input_example.0\\logs\\frameworkadapter.logI hope the logfiles can help us in any way as it is difficult to find support or descriptions in any SAP Sybase ESP documents or Sybase InfoCenter.Regards, AndreasPS: You can also write us an email to maik.hofman@contrimo.com if its easier for you with regard to exchanging required files.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "85.7", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3575487", "text": "Hello,According to the frameworkadapter.log file the Web Services adapter published 36 rows to the \"tradesIn\" stream:06-26-2014 08:06:54.470 INFO [Thread-24] (EspPublisher.stop) Publisher of stream tradesIn is stopped06-26-2014 08:06:54.671 INFO [Thread-24] (EspPublisher.stop) Totally 36 rows are published by module StockTraderServicePublisher, 36 success.I'm wondering if this is a display problem with Studio? Have you completely shutdown Studio recently?Or there might be an orphaned \"esp_server.exe\" process causing interference.Try shutting down Studio. Look for any \"esp*.exe\" processes in Windows Explorer and kill them.Restart Studio.Restart your project.From a DOS Command line prompt subscribe to the project: esp_subscribe -c studio:studio -p localhost:9786/default/ws -s tradesIn(-c parameter is user:password)If this does not resolve the problem, we might need to arrange a desktop sharing session.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "85.8", "author": "Andreas Fuchs", "url": "http://scn.sap.com/thread/3575487", "text": "Hi Neal,thanks for the help, that's really friendly. We would like to do the desktop sharing session as after hours of trying we can't proceed and still only receive \"NULL\" values in Sybase ESP Studio console. Also after pushing the data into a HANA database table the data is \"?\", so we assume it may not be a display error. Moreover we were not able to execute the \" esp_subscribe -c sybase:sybase-p localhost:9786/default/ws -s tradesIn\" command (we don't know to which folder we have to move).Our email adress is: maik.hofmann@contrimo.comWe have Webex, TeamViewer, Sykpe, how would you like to continue? You can write us an email on which day and which time it is possible for you?Regards, Andreas and Maik.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "85.9", "author": "Andreas Fuchs", "url": "http://scn.sap.com/thread/3575487", "text": "Hello Neal,thanks a lot for your help.The solution for us was to change the column names inside Sybase ESP Studio to the column names in StockTraderMappings.xml.After compiling and running the project we could see the data and were also able to push it to SAP HANA.This is the CCL Code that worked for us:CREATE SCHEMA tradesSchema ( transaction_buyerId INTEGER, transaction_sellerId INTEGER, transaction_supervisorIds INTEGER, transaction_tradeTime LONG, transaction_trades_amount INTEGER, transaction_trades_price FLOAT, transaction_trades_symbol STRING);CREATE INPUT STREAM tradesIn SCHEMA tradesSchema;CREATE OUTPUT STREAM tradesOut SCHEMA tradesSchema  AS SELECT * FROM tradesIn;/** mapFilePath is currently ignored and must be set via the mappingFile configuration parameter* in the given adapter configuration file (configFilePath).*/ATTACH INPUT ADAPTER Web_Services_SOAP_Input_Adapter TYPE soapinput TO tradesIn PROPERTIES configFilePath ='C:/Sybase/ESP-5_1/adapters/webservices/examples/input/adapter_config.xml' ,mapFilePath = 'C:/Sybase/ESP-5_1/adapters/webservices/examples/input/stockTraderMappings.xml' ,jdkHome = 'C:/Software/Java/jdk' ,discoveryWsdl = 'http://localhost:8080/axis2/services/StockTraderService?wsdl' ,discoveryWorkingDir = 'C:/tmp/adapter/soap' ,discoveryServiceName = 'StockTraderService' ;Regards, Andreas and Maik", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP Sybase ESP - Error: Invalid URI at Example: Using a Simple Web Services (SOAP) Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2014-07-14 10:27:00", "resolve": true, "uid": "86", "title": "Default password for sccadmin", "url": "http://scn.sap.com/thread/3586649", "text": "Dear colleagues,I just learned about the possibility to monitor my ESP Server with the SCC that is included in the installation of ESP 5.1.After starting the server and visiting https://localhost:8283/scc/, I have a log in prompt. I found out that the default user is sccadmin. After trying various kind of passwords, eg. blank, my ESP password, \"Sybase4me\" I am lost now because no password is working. I also can't remember, that I had to choose one when installing ESP Studio 5.1. Therefore I have the question: is there another default password that I am missing or can I change the password for the sccadmin user somewhere else? Thanks for your help and regards,Lukas", "views": "593", "answers": 1, "author": "Lukas Carullo", "upvotes": 1, "type": "question", "tags": "scc.esp"},
{"date_time": "2014-07-14 14:20:00", "resolve": "solution", "uid": "86.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3586649", "text": "Hello,If you do a \"custom\" installation, it prompts you for the password. I'm not sure if it does during a \"typical\" installation. You could try \"sybase\". If that does not work, you can always change it:http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.infocenter.dc01710.0514/doc/html/bth1234519233016.htmlThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default password for sccadmin", "type": "answer", "tags": "N/A"},
{"date_time": "2014-07-08 16:59:00", "resolve": false, "uid": "87", "title": "Sybase ESP Studio - integrating own webservice does not work", "url": "http://scn.sap.com/thread/3583949", "text": "Hi all,my colleague has written his own little webservice that generates random temperature data and we are now trying to integrate this webservice across the Web Service SOAP Input Adapter in Sybase ESP Studio. After configuring the Web Service SOAP Input Adapter we created (via schema discovery) an input stream with inline schema, run the project within Sybase ESP Studio but we get no data displayed. You can see our modeled process in Sybase ESP Studio in the attached file (\"Project Sybase\") and the output in (\"Run Project\").Biggest problem is that we don't know what to configure exactly in the adapter_config.file. We have marked the tags were we are unsure what to write with \"<??????????????>\" comments. (see \"adapter_config\").Also in the mappings file (we called it \"TempMapping.xml\") we have the following content and don't know if thats correct:<columnMappings> <mapping adapterField=\"getRandomTempResponse._return\" espCol=\"getRandomTempResponse__return\"/></columnMappings>Outside Sybase ESP Studio our webservice is running and generates data (we have tested that via \"SoapUI\").Does anyone know what the problem could be?Thanks in advance & regards,Andreas & Maik", "views": "910", "answers": 3, "author": "Andreas Fuchs", "upvotes": 0, "type": "question", "tags": "sap_hana.sap_sybase_event_stream_processor.complex_event_processing.hana.sybase.webservice.adapter.cep.sybase_esp.esp.esp_5.1.esp_developer.soap_adapter.esp_studio"},
{"date_time": "2014-07-08 21:51:00", "resolve": "", "uid": "87.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3583949", "text": "Hello,You really need to provide the project's \"frameworkadapter.log\" file in order for us to see what is going on. This adapter runs as a separate process from the project itself so it writes to that log file rather than the \"esp_server.log\" (which is what we see in the \"Run Project.PNG\" screen capture.As far as the questions in the adapter_config.xml file. This adapter was built with the Adapter Toolkit. The Adapter Toolkit has three types of modules (transporters, formatters and espconnectors): Event Stream Processor Adapter ToolkitThe adapter_config.xml parameters for this adapter are documented here: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01615.0514/doc/html/cgo1376338716093.html1) The \"InstanceName\" such as \"StockTraderServiceTransporter\" is just a generic name to identify and give meaning to that module.2) The \"Next\" parameter such as \"StockTraderServicePublisher\" tells the adapter which module comes next.3) The \"webservice\" parameter needs the \"name\" attribute to identify the name of the web service you want the adapter to connect to (appears to be \"GetTemperature\" in your case).4) The \"request\" parameter needs the \"action\" attribute which specifies the action performed by the Web service operation that is being called.5) <Module type=\"espconnector\"> - One of the three types of modules. An espconnector is a module that publishes to an ESP project or subscribes from the ESP project. This looks fine and isn't something that should be changed.6) <Name>EspPublisher</Name> - Name of the module as defined in the modulesdefine.xml file. Don't change this either.7) Since the \"ProjectName\" and \"StreamName\" of the \"EspPublisherParameters\" are commented out, the adapter should be running in \"managed\" mode meaning the adapter is started and stopped by the project itself in the \"ATTACH ADAPTER\" CCL clause. When \"ProjectName\" and \"StreamName\" are commented out, the adapter does not look at the \"EspProjects\" section because that is all derived from the CCL.As for the mappings file, I am not sure if that is correct or not. From your previous posting, I wasn't clear on what was wrong with the \"stockTraderMappings.xml\" file and why it needed to be modified (I did not have to modify mine). I don't know what it looked like before and after. Perhaps there was some kind of localization issue (I'm running everything on a standard U.S. English locale).The two things that I think might need to be modified in the adapter_config.xml file:1) Change the back slashes to forward slashes on the \"mappingFile\" parameter: <mappingFile>C:\\Sybase\\ESP-5_1\\adapters\\webservices\\examples\\Temperature\\TempMapping.xml</mappingFile>2) Change the \"workingDir\" parameter to a valid directory on your PC (and also use forward slashes): <workingDir>/tmp/adapter/soap</workingDir>If the adapter can't find the mapping file, there should be an error in the \"frameworkadapter.log\" file.Thanks,Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Sybase ESP Studio - integrating own webservice does not work", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "87.2", "author": "Andreas Fuchs", "url": "http://scn.sap.com/thread/3583949", "text": "Hello Neal,we changed the two parameters as described but could still not get the project run, now we again receive \"NULL\" values as in the StockTrader project.Therefore, we think it could be a problem with the Mappings XML File. We are not sure what to enter here for his webservice.We sent you an email with the whole WebService, maybe you can have a look over it and if required we could do a webex. But only if you have time and it is ok for you.Thanks a lot for your help.Regards, Andreas and Maik", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Sybase ESP Studio - integrating own webservice does not work", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "87.3", "author": "Andreas Fuchs", "url": "http://scn.sap.com/thread/3583949", "text": "Hi Neal, just want to inform you that the integration of the own webservice worked now.This is how my colleague could solve the issue:He followed these two guides:1) Program webservice with the help of axis2 : Eclipse WTP Tutorials - Creating Bottom Up Web Service via Apache Axis22) Create an .aar file for the webservice : https://www.eclipse.org/webtools/community/education/web/t320/Deploying_a_web_service.pdfFinally you have to put that .aar file into the folder: tomcat\\webapps\\axis2\\WEB-INF\\services Then the integration in Sybase Studio worked.Hope that helps others to solve similar issues.Regards, Andreas", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Sybase ESP Studio - integrating own webservice does not work", "type": "answer", "tags": "N/A"},
{"date_time": "2014-07-21 16:33:00", "resolve": true, "uid": "88", "title": "How to generate records faster in Sybase ESP Studio", "url": "http://scn.sap.com/thread/3590855", "text": "Hi all,we have written our own webservice and integrated it into Sybase ESP Studio. In the attachement you can see that records are generated only every 20 seconds in Sybase ESP Studio (\"console output\"). How can we let Sybase ESP Studio make faster GET requests to the WebService?Thanks & Regards,Andreas", "views": "229", "answers": 2, "author": "Andreas Fuchs", "upvotes": 1, "type": "question", "tags": "sybase.sybase_esp.esp.esp_studio"},
{"date_time": "2014-07-21 22:38:00", "resolve": "solution", "uid": "88.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3590855", "text": "Hi Andreas,In the adapter configuration file that you specify with your \"ATTACH ADAPTER\" statement: configFilePath = 'C:/ESP51/ESP-5_1/adapters/webservices/examples/input/adapter_config.xml'There is a polling parameter that you can adjust from the default value of 20 seconds:<Polling> <Enabled>true</Enabled> <TimeInterval>20000</TimeInterval></Polling>The parameters in the \"adapter_config.xml\" file are documented here: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01615.0514/doc/html/cgo1376338716093.htmlThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to generate records faster in Sybase ESP Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "88.2", "author": "Andreas Fuchs", "url": "http://scn.sap.com/thread/3590855", "text": "Hi Neal,thanks a lot. Works ! Great help as always!Regards, Andreas", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to generate records faster in Sybase ESP Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2014-07-31 14:55:00", "resolve": true, "uid": "89", "title": "json input adapter root path", "url": "http://scn.sap.com/thread/3596637", "text": "Hi all,What should I set to roothpath fo JSON Input file adapter when json data do not include root? What I try is to get following json data into an ESP window.{\"sessionid\":\"14697550182\",\"time\":\"2013-Nov-03 12:41:18\",\"size\":\"2434\",\"payload\":\"1902\",\"medium\":\"1\"}{\"sessionid\":\"14697550183\",\"time\":\"2013-Nov-03 12:41:18\",\"size\":\"1926\",\"payload\":\"1394\",\"medium\":\"1\"}When I wrote * to rootpath but I get following error:jsonRootpath = '\\\"*\\\"' , jsonRootpath = '*' ,jsonRootpath = '\"*\"' ,all of them gives following error.07-31-2014 12:46:34.440 ERROR [Thread-18] (JSONInFormatter.getMultiRecordsByRootPath) Error code:402305, Severity : 3 (Error)Error message:Invalid rootpath, please check the JSON rootpath.Error description:Invalid rootpath, please check the JSON rootpath.07-31-2014 12:46:34.441 ERROR [Thread-18] (JSONInFormatter.convert) Exception is thrownjava.lang.Exception: Error code:402305, Severity : 3 (Error)Do you have any ideas?Thanks and regards,Bulut", "views": "418", "answers": 4, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-07-31 16:51:00", "resolve": "", "uid": "89.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3596637", "text": "According to the SP08 docs, the jsonRootpath is an optional parameter. Based on that, have you tried not specifying the jsonRootpath?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:json input adapter root path", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "89.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3596637", "text": "Ys, I tried not specifying the jsonRootpath but it didn't work. Compilation gives the following error when I do not specifying root path. This means that jsonRootpath is not an optinal parameterDescriptionResourcePathLocationType[ESP-3-157502] Error occurred while validating property jsonRootpath for adapter File_Hadoop_JSON_Input2.Parameter 'jsonRootpath' (JSON Root Path) may not be left unspecified", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:json input adapter root path", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "89.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3596637", "text": "Hello,I'm not a json expert, but I have the following suggestions:1. Please see if the answer provided in http://scn.sap.com/message/14403192#14403192 will shed any light.2. Please see if the information provided in the ESP 5.1 SP04 Release Bulletin for CR 748713 will help: SyBooks OnlineThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:json input adapter root path", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "89.4", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3596637", "text": "Hi Alice,Thank you for your answer.Editing toolkit_file_json_input.cnxml and changing jsonrootPath parameter to optinal worked for me .Thanks again.Regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:json input adapter root path", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-05 17:14:00", "resolve": true, "uid": "90", "title": "csv input adapter - read rows with different # of columns", "url": "http://scn.sap.com/thread/3598889", "text": "I have a csv file which includes rows with different number of columns. I want to read all the rows( of different # of cols) into ONE stream only and then split into separate streams afterwards.I saw that CSV File Input Adapter does not add missing columns with nulls by default. Is it possible somehow? How can I generate a workaround?Thanks.", "views": "375", "answers": 2, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-08-05 17:30:00", "resolve": "solution", "uid": "90.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3598889", "text": "Hello,The CSV Input Adapter expects to find a fixed number of fields. If you attach the input adapter to a stream/window with 3 fields, it will always try to read three fields. You can have missing data and this will be read into a column as a NULL value but the delimiters must still be there. For example:1,1,12,2,23,3,34,,45,5,5CREATE INPUT WINDOW inWindow SCHEMA (c1 integer, c2 integer, c3 integer) PRIMARY KEY (c1);ATTACH INPUT ADAPTER File_Hadoop_CSV_Input2 TYPE toolkit_file_csv_input TO inWindow PROPERTIES csvExpectStreamNameOpcode = FALSE , dir = 'c:/temp' , file = 'test.csv' , csvDelimiter = ',' ;A workaround you might consider is reading an entire line from your file into a stream with a single string column. The trick is that you have to choose a character for the column delimiter that you are certain will never show up in your data. Than once you have read that line into a stream, you can use the string functions to parse out the columns as needed:CREATE INPUT STREAM csv_instream SCHEMA ( log_line_message string);// Choose a character that is certain to never show up in the data in order to read the entire line// from the CSV file into a single columnATTACH INPUT ADAPTER File_Hadoop_CSV_Input1 TYPE toolkit_file_csv_input TO csv_instream PROPERTIES csvExpectStreamNameOpcode = FALSE , dir = 'C:/temp' , file = 'error_log' , csvDelimiter = '@' ;// Parse out the individual columnsCREATE OUTPUT STREAM csv_outstream SCHEMA ( log_datetime timestamp , debug_level string , host string , message string ) AS SELECT to_timestamp(substr(CI.log_line_message, 1, 24), 'DY MON DD HH24:MI:SS YYYY') as log_datetime, substr(CI.log_line_message, patindex(CI.log_line_message, '[', 2)+1, (patindex(CI.log_line_message, ']', 2) - patindex(CI.log_line_message, '[', 2))-1) AS debug_level, replace(substr(CI.log_line_message, patindex(CI.log_line_message, '[', 3)+1, (patindex(CI.log_line_message, ']', 3) - patindex(CI.log_line_message, '[', 3))-1), 'client ', '') AS host, substr(CI.log_line_message, patindex(CI.log_line_message, ']', 3)+1, 500) AS message FROM csv_instream CI WHERE CI.log_line_message IS NOT NULL;Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:csv input adapter - read rows with different # of columns", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "90.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3598889", "text": "Hi Neal,Thank you very much your answer.I have implemented as you said. I read all rows into a stream with a single column and then parse each row with string functions as I need.Thanks again.Best regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:csv input adapter - read rows with different # of columns", "type": "answer", "tags": "N/A"},
{"date_time": "2014-07-07 10:34:00", "resolve": false, "uid": "91", "title": "File Input Adapter - Dynamic Mode", "url": "http://scn.sap.com/thread/3583013", "text": "Hi,I want to use dynamicFile and dynamicPath together for file input adapter but I am getting error when I write both of them in DynamicMode parameter. Is it possible somehow? Let me explain my scneario. A server is generating logs and I need to read them from ESP. The server writes logs in a file and when size of the file reaches 100MB, logs are started to be written a new log file. So, I need to read each newly coming data from a single log file and also get entries from a new file if previous log file reaches its maximum size.How can I handle this kind of request?Thanks and regards,Bulut", "views": "964", "answers": 8, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-07-07 17:12:00", "resolve": "", "uid": "91.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3583013", "text": "Hi Bulut,Please share your project and possible some sample input csv file that I can use to reproduce the problem.What is the error that is reported? Please share the log files where the error is reported.You can send the files to me privately if needed.Thank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File Input Adapter - Dynamic Mode", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "91.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3583013", "text": "Hi Alice,To be able to use wildcard in the File Parameter, I should choose dynamicPath in dynamicMode paramater. But when I choose dynamicPath, adaptor didnt read newly written entries (incremental data) in log files.Vice versa, to able to get incremental data from a log file I should choose dynamicFile in dynamicMode. This time, I could not use wildcard (*) and I should specify a certain file in File Parameter.you can see my adapter codes below: 1- DynamicFileCREATE INPUT WINDOW InputWindow1 SCHEMA ( Column1 string , Column2 string ) PRIMARY KEY ( Column1 ) ;ATTACH INPUT ADAPTER File_Hadoop_CSV_Input1 TYPE toolkit_file_csv_input TO InputWindow1 PROPERTIES csvExpectStreamNameOpcode = FALSE , dir = 'E:/gg/t' , file = 'new2.txt' , dynamicMode = 'dynamicFile' , removeAfterProcess = FALSE , csvDelimiter = ',' , csvDateFormat = '' , csvTimestampFormat = '' , csvHasHeader = FALSE , pollingPeriod = 5 , scanDepth = 0 ; 2- DynamicPathCREATE INPUT WINDOW InputWindow1 SCHEMA ( Column1 string , Column2 string ) PRIMARY KEY ( Column1 ) ;ATTACH INPUT ADAPTER File_Hadoop_CSV_Input1 TYPE toolkit_file_csv_input TO InputWindow1 PROPERTIES csvExpectStreamNameOpcode = FALSE , dir = 'E:/gg/t' , file = '*' , dynamicMode = 'dynamicPath' , removeAfterProcess = FALSE , csvDelimiter = ',' , csvDateFormat = '' , csvTimestampFormat = '' , csvHasHeader = FALSE , pollingPeriod = 5 , scanDepth = 0 ;My new2.txt file includes:A,AB,BC,CD,D,I could not find a way to handle this situation. Do you have any idea? How can I use both dynamicFile and dynamicPath options together?Regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File Input Adapter - Dynamic Mode", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "91.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3583013", "text": "Hi Bulut,I think that what you want to use is the Log File Input Adapter rather than the File/Hadoop CSV Input Adapter. Have you taken a look at that one yet?Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File Input Adapter - Dynamic Mode", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "91.4", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3583013", "text": "Hi Alice,I have chance to look Log File Input Adapter today. Yes, you are right it is more appropriate for me. I have one question related to the Log File Input Adapter. My log file is advancing file which is defined in the docs as below:For advancing files, when one file is full, the log file writer creates a new file and starts writing to that new file. The naming convention is typically a base name plus a suffix, where the suffix might be based on date/time or a sequential number (for example, \"access-log.2007-01-01\", \"access-log.2007-01-02\", and so on, or \"access.log.1\", \"access.log.2\", and so on). Regardless of the naming convention, the adapter opens these log files in chronological order by the most recent modification date.For .properties file the document is saying that set Input.WaitForGrowth parameter to true. I also set Input.FileName. I did it and adapter read the appended data. But when I create a new log file and write new logs into it adapter didn't read new file. Do I need to set some other parameters? Do you have any opinion about how I can read advancing files?You can use this adapter to read either live or historical log files.To read a historical file, specify the file name in the Input.Filename property, and set the Input.WaitForGrowth property to false.To read a live file, whether rotated or advancing, set the Input.WaitForGrowth property to true. The Log File Input adapter goes to the end of the file and then reads as new data is appended to the file. When the file size shrinks to zero (after the old log file is renamed and a new, empty one is created), the Log File Input adapter continues reading from the beginning of the new file.Thanks and regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File Input Adapter - Dynamic Mode", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "91.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3583013", "text": "Hi Bulut,There are at least 6 bugs in ESP 5.1 SP04 that limit the Log File Adapter's functionality. Some of these have been fixed in SP08, others have not. One of the six that have not been fixed is: 761559 - Log File Input Adapter does not work on advancing filesRather than discussing them here, it would be easier if you could open a technical support case so that we can discuss your project requirements (what type of log files you are reading, what language/locale they are in), your timeline, how far are you in your current project, if you would feel comfortable upgrading to SP08 and so on.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File Input Adapter - Dynamic Mode", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "91.6", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3583013", "text": "Hi Neal,I have opened a technical case from sybase case-express. CaseId is 11717464. If you have chance to look and and make some comment, they will be valuable and helpful for me.Thank and regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File Input Adapter - Dynamic Mode", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "91.7", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3583013", "text": "Hello,Since your technical support contract was migrated from Sybase to SAP, we are not allowed to work under the old Sybase systems. As long as you log a case under the SAP component BC-SYB-ESP, I will get a notification and we can start working with you directly.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File Input Adapter - Dynamic Mode", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "91.8", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3583013", "text": "Hello Neal,The technical support contract migration have been completed and I could open an incident. The incident name and id: Log File Input Adapter - Advancing Files ( 791723 / 2014 ).Thanks and regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File Input Adapter - Dynamic Mode", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-08 09:30:00", "resolve": true, "uid": "92", "title": "Question on a basic concept of ESP Window", "url": "http://scn.sap.com/thread/3600662", "text": "Hello, I am new to ESP and recently doing some researching of this product. I currently have two concept questions, please have a look.I realize that a Window could save events. My question is, for a derived window which has query defined on it, what kind of data is exactly it will save? are the incoming events (maybe from two or more different previous window or stream) of this window will be saved first and then apply the query and then output; or, it will apply query first and then save the result of the query into the Window and then output?Thanks", "views": "632", "answers": 8, "author": "Richard Gu", "upvotes": 0, "type": "question", "tags": "esp"},
{"date_time": "2014-08-08 10:25:00", "resolve": "", "uid": "92.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3600662", "text": "Hi,A, quick answer, it does not save incomming events only what is needed by the query and the retention policy.It is often described as a data-flow maried with a sql like language.The clauses or queries acts as filters and only the records are saved or stored in the window that matches the query. Those records are not saved indefinitely normally, but as long as it fullfils the keep-clause, i.e. you can keep them for 5 minutes or you can keep 500 rows possibly per column value.The rows are propagated using insert, update etc. data events as you can see for example when you manually feed in some data in the studio or look at some splash code examples like the Top3TradesFlex in the Splash Programming chapter.Thanks,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question on a basic concept of ESP Window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "92.2", "author": "Richard Gu", "url": "http://scn.sap.com/thread/3600662", "text": "Hi Plujim,Thanks for the reply. Let me use an example to describe my question. In this developer center we have a sample about capture the Weather station and the weather data. In that example, we have a derived window and the query of it is to join the weather data with the station master data. Both weather data and station is the input of this window. Now my question would be, are the result (the joined data between weather data and station) will be saved into this window, or the input (weather data and station) will be saved into this window? Thanks", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question on a basic concept of ESP Window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "92.3", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3600662", "text": "Hi,The derived window should contain the joined data and not the input of both weather data and station. If you have some kind of aggregration I think the events opcode lead to modification of the result (as a delta); a sum or otherwise will not be recalculated from scratch.Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question on a basic concept of ESP Window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "92.4", "author": "Richard Gu", "url": "http://scn.sap.com/thread/3600662", "text": "So, how a window would be CRUD are mainly depends on the opCodes of output, right?Thanks indeed", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question on a basic concept of ESP Window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "92.5", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3600662", "text": "Thinks so , yes,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question on a basic concept of ESP Window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "92.6", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3600662", "text": "It might be useful to add a bit more detail here:- As Ben describes, the output of the window is the result of the query logic attached to that window.- What's held in that window is not the input events but the results of the continuous query, where these results are updated each time the window receive a new input event- The KEEP clause affects what's in the window, and the behavior of the KEEP clause is different depending on where it's used:When you apply the KEEP clause to the Window itself, like this:CREATE LOCAL WINDOW RecentWeatherData PRIMARY KEY DEDUCED KEEP 4 HOURS AS SELECT...Then this tells the window to only keep the rows in the window that have been added or updated on the last 4 hours. It doesn't affect the inputs to the window, just the rows \"maintained\" in the window (i.e. the output of the window)When you apply the KEEP clause as part of the FROM clause, it creates a an unnamed window - think of it as an invisible window - on the input to the window (or stream) being created by the CCL CREATE statement that contains the FROM clause. So this:CREATE OUTPUT WINDOW AVG_TEMPPRIMARY KEY DEDUCEDAS SELECT ...FROM EVENTS KEEP 30 SEC GROUP BY EVENTS.MACHINEID ;Would have the effect of only computing the group values across the set of input events from \"EVENTS\" that arrived in the last 30 secondsHere are a couple of posts that might be useful:Creating windows from event streams: http://scn.sap.com/docs/DOC-40921Understanding opcodes: http://scn.sap.com/docs/DOC-40207", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question on a basic concept of ESP Window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "92.7", "author": "Richard Gu", "url": "http://scn.sap.com/thread/3600662", "text": "Hi Jeff,Many thanks for your complementary. Please allow me ask further questions: for this example, CREATE OUTPUT WINDOW AVG_TEMPPRIMARY KEY DEDUCEDAS SELECT ...FROM EVENTS KEEP 30 SECGROUP BY EVENTS.MACHINEID ;do you mean the system will first create an unnamed window which save the query result (SELECT XXX FROM EVENTS) for 30 seconds, and then the system will create your named window based on that unnamed window , do the group by aggregation and save the group by result? if so, in principle, can I also set KEEP on the header of the CREATE WINDOW statement as well to set the retain policy for the group by result? ( so in this one statement we could have two KEEP policies, on for NAMED WINDOW and one for UNNAMED WINDOW? )", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question on a basic concept of ESP Window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "92.8", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3600662", "text": "Not quite. The system will create an unnamed 30 second window on the stream \"EVENTS\", holding all events received in the last 30 seconds. The query (SELECT...GROUP BY) will be run against that 30 second window.Yes, you can also set a KEEP policy on AVG_TEMP, eg:CREATE OUTPUT WINDOW AVG_TEMPPRIMARY KEY DEDUCEDKEEP 5 MINUTESAS SELECT ...This will not affect the 30 second window that serves as the input to the continuous query. What it will do is automatically remove any summary row from AVG_TEMP for a group that has not be create or updated in the last 5 minutes.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question on a basic concept of ESP Window", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-14 14:43:00", "resolve": true, "uid": "93", "title": "Socket Input Adapter", "url": "http://scn.sap.com/thread/3603869", "text": "Hi all,I am trying to get streaming data with socket csv input adapter. The streaming data is machine generated event logs and does not include \"\\n\" character. So, I could not get data into ESP.When I try this with a simple java socket server and send string without \"\\n\", ESP does not insert any data into IputStream. When I append \"\\n\" to the string, then ESP insert streaming data into InputStream.Do you have any idea about getting streaming data which does not include \"\\n\".Thanks and regards,Bulut", "views": "648", "answers": 7, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-08-14 17:26:00", "resolve": "", "uid": "93.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3603869", "text": "Hi Bulut,Some of the adapters supplied with ESP are built with the toolkit. These adapters consist of modules as illustrated here:Event Stream Processor Adapter ToolkitIf you look at the CSV Socket Input Adapter's configuration file (%ESP_HOME%\\adapters\\framework\\instances\\socket_csv_input\\adapter_config.xml), you will see that it consists of four modules (an input transport, two formatters and an ESP connector):SocketInputTransporter -> StreamToStringFormatter -> CsvStringToEspFormatter -> EspPublisherAfter the socket input transporter reads a stream of TCP data, the StreamToStringFormatter needs to somehow identify where one line begins and the next ends so that it can begin to parse the data into columns that can then be published to ESP.You can see what another user did here with their Socket Server: Cann't read data from socket csv input adapterThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Socket Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "93.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3603869", "text": "Hi Neal,Thanks for your answer. I have been looking the details of the adapter toolkit especially streaming input example. So, what I understand from your answer is that existing I should modify the adapter with adapter toolkit. Do you know more easier way to get streaming data which does not include newline (\"\\n\") character?Thanks and regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Socket Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "93.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3603869", "text": "Hello,The source code for the CSV Socket Input Adapter is not publicly available so you would have to write you own from scratch.Even if you wrote your own, how would you know where one line of data began and the next ended? ESP deals with messages. For the CSV Socket Input Adapter: 1 line of data = 1 messageI don't understand how your data is structured such that as it was being read from the TCP socket server, how would the data be parsed into a single message to be published into ESP?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Socket Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "93.4", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3603869", "text": "Yes, you are right, 1 line of data is 1 message. But, I am trying to parse a log data in Common Event Format (CEF). As you can see in the attached file, single CEF message is start with \"CEF\" and CEF messages are comming without a newline char. So, what my opinion is that read the message from tcp socket in length of packet buffer size. So, 1 line of data is the data in tcp packet with buffer size. Then, I parse the incoming messages in a FlexOperator. I did the parsing CEF events in a file like attached file, but now I am trying same thing with tcp socket.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Socket Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "93.5", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3603869", "text": "Sorry, I could not attached a file. You can see similar CEF data below:CEF:0|Check Point|VPN-1 & FireWall-1||drop|drop|Low| eventId=111111111 msg=Address spoofing proto=TCP categorySignificance=/Informational/Warning categoryBehavior=/Access categoryTechnique=/Traffic Anomaly/Network Layer/Spoof categoryDeviceGroup=/Firewall categoryOutcome=/Failure categoryObject=/Host/Application/Service art=1111111111111 cat=SecurityLog act=drop rt=1111111111111 deviceDirection=0 src=1.22.333.444 sourceZoneURI=/All Zones/ArcSight System/Public Address Space Zones/APNIC/1.22.333.444-1.22.333.444 (APNIC) spt=637 dst=1.22.333.444 destinationZoneURI=/All Zones/ArcSight System/Public Address Space Zones/APNIC/1.22.333.444-1.22.333.444 (APNIC) dpt=500 destinationServiceName=ISAKMP cs1= & cs3=Mg7-MM cs6=fwgtout-32992011tufin cs1Label=rule & Rule Name cs2Label=UFP category cs3Label=Manager cs4Label=Rule UID cs5Label=Total bytes cs6Label=Policy Name cn1Label=Elapsed Time in Seconds cn2Label=icmp_type cn3Label=icmp_code deviceCustomDate1Label=Local Time c6a2Label=Source IPv6 Address c6a3Label=Destination IPv6 Address ahost=1.22.333.444 agt=1.22.333.444 agentZoneURI=/All Zones/ArcSight System/Private Address Space Zones/RFC1918: 1.22.333.444-1.22.333.444 av=1.22.333.4444.0 atz=Europe/Istanbul aid=flL+iYoBABCAO6bMvUEZYZ\\=\\= at=checkpointfirewall_ad_opsec dvc=1.22.333.444 deviceZoneURI=/All Zones/ArcSight System/Private Address Space Zones/RFC1918: 1.22.333.444-1.22.333.444 dtz=Europe/Istanbul deviceInboundInterface=eth-s1p1c0 _cefVer=0.1 ad.has__accounting=0CEF:0|Check Point|VPN-1 & FireWall-1||drop|drop|High| eventId=111111111 msg=Address spoofing proto=UDP categorySignificance=/Informational/Warning categoryBehavior=/Access categoryTechnique=/Traffic Anomaly/Network Layer/Spoof categoryDeviceGroup=/Firewall categoryOutcome=/Failure categoryObject=/Host/Application/Service art=1111111111111 cat=SecurityLog act=drop rt=1111111111111 deviceDirection=0 shost=1-65-32-002.static.netvigator.com src=1.22.333.444 sourceZoneURI=/All Zones/ArcSight System/Public Address Space Zones/APNIC/1.22.333.444-1.22.333.444 (APNIC) spt=500 dhost=2-55-32-011.static.netvigator.com dst=1.22.333.444 destinationZoneURI=/All Zones/ArcSight System/Public Address Space Zones/APNIC/1.22.333.444-1.22.333.444 (APNIC) dpt=500 destinationServiceName=ISAKMP cs1= & cs3=Mg1-NG cs6=fwgtout-30092011tufin cs1Label=rule & Rule Name cs2Label=UFP category cs3Label=Manager cs4Label=Rule UID cs5Label=Total bytes cs6Label=Policy Name cn1Label=Elapsed Time in Seconds cn2Label=icmp_type cn3Label=icmp_code deviceCustomDate1Label=Local Time c6a2Label=Source IPv6 Address c6a3Label=Destination IPv6 Address ahost=1.22.333.444 agt=1.22.333.444 agentZoneURI=/All Zones/ArcSight System/Private Address Space Zones/RFC1918: 1.22.333.444-1.22.333.444 av=1.22.333.4444.0 atz=Europe/Istanbul aid=plL+iSoBABCEO6bMvUYOYT\\=\\= at=checkpointfirewall_ad_opsec dvc=1.22.333.444 deviceZoneURI=/All Zones/ArcSight System/Private Address Space Zones/RFC1918: 1.22.333.444-1.22.333.444 dtz=Europe/Istanbul deviceInboundInterface=eth-s3p1c0 _cefVer=0.1 ad.has__accounting=0CEF:0|Check Point|VPN-1 & FireWall-1||drop|drop|Low| eventId=111111111 msg=Address spoofing proto=UDP categorySignificance=/Informational/Warning categoryBehavior=/Access categoryTechnique=/Traffic Anomaly/Network Layer/Spoof categoryDeviceGroup=/Firewall categoryOutcome=/Failure categoryObject=/Host/Application/Service art=1111111111111 cat=SecurityLog act=drop rt=1111111111111 deviceDirection=0 src=1.22.333.444 sourceZoneURI=/All Zones/ArcSight System/Public Address Space Zones/APNIC/1.22.333.444-1.22.333.444 (APNIC) spt=500 dst=1.22.333.444 destinationZoneURI=/All Zones/ArcSight System/Public Address Space Zones/APNIC/1.22.333.444-1.22.333.444 (APNIC) dpt=500 destinationServiceName=ISAKMP cs1= & cs3=Mg1-NG cs6=fwgtout-34392011tufin cs1Label=rule & Rule Name cs2Label=UFP category cs3Label=Manager cs4Label=Rule UID cs5Label=Total bytes cs6Label=Policy Name cn1Label=Elapsed Time in Seconds cn2Label=icmp_type cn3Label=icmp_code deviceCustomDate1Label=Local Time c6a2Label=Source IPv6 Address c6a3Label=Destination IPv6 Address ahost=1.22.333.444 agt=1.22.333.444 agentZoneURI=/All Zones/ArcSight System/Private Address Space Zones/RFC1918: 1.22.333.444-1.22.333.444 av=1.22.333.4444.0 atz=Europe/Istanbul aid=flL+iYoBABCAO6bMvUEZYZ\\=\\= at=checkpointfirewall_ad_opsec dvc=1.22.333.444 deviceZoneURI=/All Zones/ArcSight System/Private Address Space Zones/RFC1918: 1.22.333.444-1.22.333.444 dtz=Europe/Istanbul deviceInboundInterface=eth-s4p2c0 _cefVer=0.1 ad.has__accounting=0", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Socket Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "93.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3603869", "text": "Hello,So if you are reading from a socket, you must have some way of:1) Determining columns2) Terminating a record (or message or line):* Is there a delimiter in the data signifying the end of message?* Is the data a fixed length?* Do you read the data one character at a time and keep appending to form a message until you hit some kind of end of message marker? InputStreamReader (Java Platform SE 7 ) BufferedReader (Java Platform SE 7 ) DataInputStream (Java Platform SE 7 )ESP's TCP Socket Input Adapter reads a byte buffer (of size determined by the \"inputBufferSize\" parameter. See: Socket CSV Input Adapter Studio Properties ). I think the closest publicly available example (including source code) of how this is done is the $ESP_HOME/adapters/framework/examples/streaming_input adapter. This particular example reads from a file rather than a socket but it is fairly close.It reads a byte stream from an XML file and sends this byte buffer to the next module using the ESP Toolkit Adapter API's: utility.sendRowsBuffer(ByteBuffer.wrap(buf, 0, iRead));See the following example: $ESP_HOME/adapters/framework/examples/src/com/sybase/esp/adapter/framework/examplemodules/ExampleStreamingInputTransporter.javaThen the next module in line has to parse XML elements from the byte buffer and forms a record (AepRecord) to send to the next module: $ESP_HOME/adapters/framework/examples/src/com/sybase/esp/adapter/framework/examplemodules/ExampleStreamingInputFormatter.javaThe last module in line gets the AepRecord and publishes it to the ESP project. See: $ESP_HOME/adapters/framework/examples/src/com/sybase/esp/adapter/framework/examplemodules/ExampleEspInputTransporter.javaIn your data I see a pipe symbol (|) delimits the columns.But how are you determining when one record/message ends and the next begins? Counting the number of columns?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Socket Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "93.7", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3603869", "text": "If I can get CEF messages line-by-line, it is, of course, more easier way but I have been requested to get CEF messages without end-of-line char.I am working on the Input Formatter to get CEF messages. A CEF message start with \"CEF\" string. So, I try to parse the incoming stream so that a one line data will be the data stay between two \"CEF\" string.Thanks for your comments and advices.Best regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Socket Input Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-14 19:21:00", "resolve": true, "uid": "94", "title": "Deploying and Starting a Cluster in Linux", "url": "http://scn.sap.com/thread/3604080", "text": "Hi all,I have installed ESP5.1 SP08 on RHEL 6.0 x64. I completed setup without any error. Then, I set environment variables and start esp_cluster.db as described in the following link.Deploying and Starting a Cluster - Installation Guide (Linux) - SAP LibraryBut, when I start node, I am getting following error. I checked my db is up and running. cluster.cfg exists in the directory. What could the reason of this error?Aug 14 2014 10:14:12.576 INFO - SAP Event Stream Processor Cluster Node 5.1.08.00/20140618.1/SP08 PL00/linux/x86_64/64-bit/OPT/Wed Jun 18 10:33:37 PDT 2014Aug 14 2014 10:14:12.969 FATAL - CODE_700418 | Could not load config from databasecom.sybase.esp.cluster.config.ConfigException: com.sybase.esp.cluster.config.ConfigException: java.io.EOFException at com.sybase.esp.cluster.impl.ConfigDatabaseAccessor._load(Unknown Source) at com.sybase.esp.cluster.impl.ConfigDatabaseAccessor.load(Unknown Source) at com.sybase.esp.cluster.impl.ConfigDatabaseManager.load(Unknown Source) at com.sybase.esp.cluster.impl.Node.initialize(Unknown Source) at com.sybase.esp.cluster.FactoryNode.factory(Unknown Source) at com.sybase.esp.cluster.FactoryNode.main2(Unknown Source)Caused by: com.sybase.esp.cluster.config.ConfigException: java.io.EOFException at com.sybase.esp.cluster.config.Config.readData(Unknown Source) ... 6 moreCaused by: java.io.EOFException at java.io.DataInputStream.readFully(DataInputStream.java:197) at java.io.DataInputStream.readLong(DataInputStream.java:416) ... 7 moreAug 14 2014 10:14:12.971 FATAL - CODE_700412 | Factory of new node failedThanks and regards,Bulut", "views": "1707", "answers": 13, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-08-14 19:31:00", "resolve": "", "uid": "94.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3604080", "text": "Hi Bulut,That generally means that the username/password in the \"cluster.cfg\" file used by the \"start_node.sh node1\" command does not match the password defined in the cluster database.Follow these steps to confirm that the password in the config file does not match:1) Set you Linux PATH environment variable to include the SQL Anywhere executables: setenv PATH $ESP_HOME/sqla/bin64:${PATH}2) Set your Linux LD_LIBRARY_PATH environment variable: setenv LD_LIBRARY_PATH $ESP_HOME/sqla/lib64:${LD_LIBRARY_PATH}3) Issue the \"dblocate\" command to find the running instance of your cluster database:% dblocateSQL Anywhere Server Enumeration Utility Version 16.0.0.1691Server Name Address----------- -------esp_cluster_esp1_denn00530262a DENN00530262A.acme.com:191114) Test authentication to this database with the credentials you *think* are valid:dbping -d -c \"UID=espdbadm;PWD=Password1;ENG=esp_cluster_esp1_denn00530262a;DBN=esp_cluster\"SQL Anywhere Server Ping Utility Version 16.0.0.1691Connected to SQL Anywhere 16.0.0.1691 server \"esp_cluster_esp1_DENN00530262A\" and database \"esp_cluster\".Ping database successful.5) Use those credentials in the \"cluster.cfg\" bootstrap file. I would only worry about encrypting them if this is a cluster deployment:jdbc-url=jdbc:sybase:Tds:localhost:19111jdbc-username=espdbadmjdbc-password=Password1jdbc-password-is-encrypted=falsecluster-name=esp1cluster-password=Password1cluster-password-is-encrypted=falseThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3604080", "text": "Hi Neal,While I can connect to databae, I could not start cluster again. I changed cluster.cfg based on my credentials, but I am getting same error. Any idea?The steps I did:[sybase@localhost esp1]$ . start_db.sh SQL Anywhere Start Server In Background Utility Version 16.0.0.1691[sybase@localhost esp1]$ dbping -d -c \"UID=sybase;PWD=sybase;ENG=esp_cluster_esp1_localhost.localdomain;DBN=esp_cluster\"SQL Anywhere Server Ping Utility Version 16.0.0.1691Connected to SQL Anywhere 16.0.0.1691 server \"esp_cluster_esp1_localhost.localdomain\" and database \"esp_cluster\".Ping database successful.[sybase@localhost esp1]$ . start_node.sh mynode[sybase@localhost esp1]$ more mynode.log Aug 14 2014 13:40:48.033 INFO - SAP Event Stream Processor Cluster Node 5.1.08.00/20140618.1/SP08 PL00/linux/x86_64/64-bit/OPT/Wed Jun 18 10:33:37 PDT 2014Aug 14 2014 13:40:48.736 FATAL - CODE_700418 | Could not load config from databasecom.sybase.esp.cluster.config.ConfigException: com.sybase.esp.cluster.config.ConfigException: java.io.EOFException at com.sybase.esp.cluster.impl.ConfigDatabaseAccessor._load(Unknown Source) at com.sybase.esp.cluster.impl.ConfigDatabaseAccessor.load(Unknown Source) at com.sybase.esp.cluster.impl.ConfigDatabaseManager.load(Unknown Source) at com.sybase.esp.cluster.impl.Node.initialize(Unknown Source) at com.sybase.esp.cluster.FactoryNode.factory(Unknown Source) at com.sybase.esp.cluster.FactoryNode.main2(Unknown Source)Caused by: com.sybase.esp.cluster.config.ConfigException: java.io.EOFException at com.sybase.esp.cluster.config.Config.readData(Unknown Source) ... 6 moreCaused by: java.io.EOFException at java.io.DataInputStream.readFully(DataInputStream.java:197) at java.io.DataInputStream.readLong(DataInputStream.java:416) ... 7 moreAug 14 2014 13:40:48.743 FATAL - CODE_700412 | Factory of new node failed[sybase@localhost esp1]$ [sybase@localhost esp1]$ [sybase@localhost esp1]$ [sybase@localhost esp1]$ more cluster.cfg #config-type=file#file=cluster.xml#The following url points to a default location.#Set as appropriate for your environment.jdbc-url=jdbc:sybase:Tds:localhost:19111jdbc-username=sybasejdbc-password=sybasejdbc-password-is-encrypted=falsejdbc-type=sqlajdbc-sqla-ha=falsejdbc-sqla-ha-mirror-primary=jdbc-sqla-ha-mirror-partner-1=jdbc-sqla-ha-mirror-partner-2=cluster-name=esp1cluster-password=sybasecluster-password-is-encrypted=false#cipher-file=/sybase/ESP-5_1/cluster/keys/esp1/cluster.key[sybase@localhost esp1]$ Thanks.Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3604080", "text": "Hi Bulut,I just had someone else report something similar that you might check. Look in $SYBASE/log/init_cluster_db.log. Are there any errors in there?If not, try starting the node with the node name \"node1\" as that is the default the installer normally uses: start_node.sh node1If there were errors, the installer is supposed to create and initialize with the SQL Anywhere cluster database with the admin user and password and then installer is supposed to populate the database with some tables.If you can ping it, the database admin and user were created and you might have to manually create the tables:cd $ESP_HOME/cluster/sqldbisql -c \"UID=sybase;PWD=sybase;ENG=esp_cluster_esp1_localhost.localdomain;DBN=esp_cluster\" -nogui sqla.sqlAfter the tables have been created, deploy the cluster configuration to the database:$ESP_HOME/bin/esp_cluster_node --config cluster.cfg --deploy --config-type file --file cluster.xmlThen try starting the cluster manager again:start_node.sh node1After the cluster manager node has been started, you will have to use the special \"espsysusr\" security user to grant permission to a valid user (valid according to the authentication type you selected at installation):$ESP_HOME/bin/esp_cluster_admin --uri=esp://localhost:19011 --username=espsysusr --password=Password1> grant perm all to user my_linux_user> quitThen you can test authenticating and doing something with this user:$ESP_HOME/bin/esp_cluster_admin --uri=esp://localhost:19011 --username=my_linux_user --password=Password1> add workspace default[done]", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.4", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3604080", "text": "Hi Neal,When I tried to create the tables manually, I get following errors which show tables are already created. ----------------------[sybase@localhost sql]$ dbisql -c \"UID=sybase;PWD=sybase;ENG=esp_cluster_esp1_localhost.localdomain;DBN=esp_cluster\" -nogui sqla.sqlCould not execute statement. Item 'ESP_CLUSTER_CONFIG_ENTRY' already exists SQLCODE=-110, ODBC 3 State=\"42S01\" File: \"sqla.sql\" on line 1, column 1 CREATE TABLE ESP_CLUSTER_CONFIG_ENTRY ( VERSION BIGINT NOT NULL, SEQUENCE_NUMBER INTEGER NOT NULL, SEGMENT VARBINARY(2048) NOT NULL, ... You can continue executing or stop.1. Stop2. ContinueSelect an option: 2(Continuing after error)Could not execute statement. Item 'ESP_CLUSTER_CONFIG_HISTORY' already exists SQLCODE=-110, ODBC 3 State=\"42S01\" File: \"sqla.sql\" on line 11, column 1 CREATE TABLE ESP_CLUSTER_CONFIG_HISTORY ( VERSION BIGINT NOT NULL, TIME_CREATED TIMESTAMP NOT NULL, USER_NAME VARCHAR(128) NOT NULL, ... You can continue executing or stop.1. Stop2. ContinueSelect an option: 2(Continuing after error)Could not execute statement. Item 'ESP_CLUSTER_CONFIG_VERSION' already exists SQLCODE=-110, ODBC 3 State=\"42S01\" File: \"sqla.sql\" on line 22, column 1 CREATE TABLE ESP_CLUSTER_CONFIG_VERSION ( CURRENT_VERSION BIGINT NULL, PREVIOUS_VERSION BIGINT NULL ) ... You can continue executing or stop.1. Stop2. Continue-----------------------And again, I could not start node1. Same message lines were writen into node1.log file.Aug 15 2014 08:14:20.301 INFO - SAP Event Stream Processor Cluster Node 5.1.08.00/20140618.1/SP08 PL00/linux/x86_64/64-bit/OPT/Wed Jun 18 10:33:37 PDT 2014Aug 15 2014 08:14:20.540 FATAL - CODE_700418 | Could not load config from databasecom.sybase.esp.cluster.config.ConfigException: com.sybase.esp.cluster.config.ConfigException: java.io.EOFException at com.sybase.esp.cluster.impl.ConfigDatabaseAccessor._load(Unknown Source) at com.sybase.esp.cluster.impl.ConfigDatabaseAccessor.load(Unknown Source) at com.sybase.esp.cluster.impl.ConfigDatabaseManager.load(Unknown Source) at com.sybase.esp.cluster.impl.Node.initialize(Unknown Source) at com.sybase.esp.cluster.FactoryNode.factory(Unknown Source) at com.sybase.esp.cluster.FactoryNode.main2(Unknown Source)Caused by: com.sybase.esp.cluster.config.ConfigException: java.io.EOFException at com.sybase.esp.cluster.config.Config.readData(Unknown Source) ... 6 moreCaused by: java.io.EOFException at java.io.DataInputStream.readFully(DataInputStream.java:197) at java.io.DataInputStream.readLong(DataInputStream.java:416) ... 7 moreAug 15 2014 08:14:20.544 FATAL - CODE_700412 | Factory of new node failed", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3604080", "text": "Hi Bulut,I think I will need to see all of the config, log and XML files from your %ESP_HOME%\\cluster\\config\\esp1 directory. Can you zip them up and attach them here?Or email them to me (neal dot stack at sap dot com).Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "94.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3604080", "text": "Hi Bulut,I think this is being caused by the use of \"localhost.localdomain\". I could not get the cluster manager to communicate with the cluster database when the cluster database was started with either \"localhost.localdomain\" or just \"localhost\".If I kill the \"dbsrv\" process associated with \"esp_cluster_esp1_localhost.localdomain\", and then make the following changes it works:1) Edit the \"start_db.sh\" file and change the following line to have an actual host name:ESP_CLUSTER_DB_NAME=esp_cluster_esp1_archer2) Edit the \"cluster.cfg\" file and uncomment the \"ciper-file\" line as the \"esp_cluster_node\" command will need that line for some commands.3) Edit the \"cluster.xml\" file and change the ESP_HOSTNAME to be a fully qualified host name. If you don't use a fully qualified host name, remote clients won't be able to connect to ESP: <Macro name=\"ESP_HOSTNAME\" type=\"value\">archer.acme.com</Macro>4) Execute \"start_db.sh\" and use dblocate to confirm it is no longer using the localhost:source $ESP_HOME/sqla/bin64/*.csh (or .sh if using a different shell)dblocate5) Try deploying the cluster configuration to the cluster database:$ESP_HOME/bin/esp_cluster_node --config cluster.cfg --deploy --config-type file --file cluster.xmlWant to deploy config-version 5Failed to deploy version 5NOTE: If it says \"Failed to deploy\", the configuration changes may have still deployed but the cluster database versioning is out of sync. You can check the changes were saved (especially the ESP_HOSTNAME) by executing this command: $ESP_HOME/esp_cluster_node --config cluster.cfg --show6) Try starting the cluster manager:start_node.sh node1If this doesn't resolve it, you may want to reinstall ESP and when it prompts for the host name fill in a fully qualified host name.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.7", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3604080", "text": "Hi Neal,Yes, it works. I can start the node finally. Thank you very much.I have a last question  My Linux is RHEL 6 and running as a VM on my machine. I am trying to connect from my Windows machine. Actually, I tried to connect but I could not be successful because of user credentials. What should be the user name? I used my unix user and password but it didn't work. I chose Native OS during the installation and it is seen in the cluster xml as below: <Security><Authenticators><xi:include href=\"auth_native_unix.xml\" parse=\"xml\"/></Authenticators><Authorizer enabled=\"true\"/><KeyStore><Type expand=\"true\">JKS</Type><File expand=\"true\">${ESP_CLUSTER_KEYSTORE}</File><Password expand=\"true\" encrypted=\"true\">u7In3rk3v+bSnOEth8cOlCP6a691nh+TndcVnZkpmiUmH/iK</Password><Algorithm expand=\"true\">RSA</Algorithm></KeyStore>", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.8", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3604080", "text": "Hello,There are some post-installation tasks to make Native OS authentication work: Configuration and Administration Guide - SAP LibraryI forgot to mention that when I was talking about doing the \"grant\" permissions above.So:Copy the correct \"sybase-csi\" to the /etc/pam.d directoryIf the Linux user is local to the VM, make sure that the user starting the cluster manager has the proper permissions to the /etc/shadow file as this is where local user credentials are stored.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.9", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3604080", "text": "I copied correct \"sybase-csi\" to the /etc/pam.d and gave read permission to /etc/shadow file for my local linux user.Then to give permission as you said above I tried to connect cluster But, I could not login to cluster with espsysuser. Does it have a default password? I tried with with cluster password but I could not login?$ESP_HOME/bin/esp_cluster_admin --uri=esp://localhost:19011 --username=espsysusr --password=Password1", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.10", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3604080", "text": "The espsysusr password should be the same as the cluster password: http://help.sap.com/saphelp_esp51sp08lnx/helpdata/en/e7/a0b88e6f0f1014b13294f6f9e312ba/frameset.htmespsysusr - Configuration and Administration Guide - SAP LibraryDid you try \"sybase\"?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.11", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3604080", "text": "Yes, but it didn't work.I am trying example cluster which includes predefined user. Hope it will work.Thanks you very much again.Regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.12", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3604080", "text": "I can run example cluster with predefided user and can connect it from my Windows machine.I don't understand why I could not connect when NativeOS is the security type. I will investigate it when I have more idle time.Thanks again Neal.Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "94.13", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3604080", "text": "Hi Bulut,The password for the \"espsysusr\" is the same as the cluster password. The cluster password is defined in one of two ways:1) Directly on the command line:D:\\ESP51_SP8\\ESP-5_1\\cluster\\config\\esp1>esp_cluster_node --cluster-name=esp1 --cluster-password=Password1 --cluster-password-is-encrypted=false --file cluster.xml --node-name=node1 --jdbc-url=jdbc:sybase:Tds:localhost:19111 --jdbc-username=espdbadm --jdbc-password=Password1 --cipher-file=D:\\\\ESP51_SP8\\\\ESP-5_1\\\\cluster\\\\keys\\\\esp1\\\\cluster.key --node-name=node12) In the \"cluster.cfg\" bootstrap file (esp_cluster_node --config cluster.cfg --config-type=file --file cluster.xml --node-name=node1):cluster-name=esp1cluster-password=Password1cluster-password-is-encrypted=false#cipher-file=/sybase/ESP-5_1/cluster/keys/esp1/cluster.keySo in these two examples, the password for the \"espsysusr\" is the same as the cluster password which is \"Password1\".If you are not able to connect with \"espsysusr\", double check:1) There are no orphaned \"esp_cluster_node.exe\" processes running with a different password. If there are, kill them and restart.2) Make sure your esp_cluster_admin is using the proper \"--uri\" setting for your node. If your node is SSL enabled, use \"esps://hostname:port\". If your node is not SSL enabled, use \"esp://hostname:port\".3) Make sure to uncomment the \"cipher-file\" parameter out of your \"cluster.cfg\" file as it is required.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Deploying and Starting a Cluster in Linux", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-21 13:13:00", "resolve": true, "uid": "95", "title": "Windows 8 Support", "url": "http://scn.sap.com/thread/3607200", "text": "Hi all,In the Installation guide of 5.1 SP08, I showed ESP does not support Windows 8. Is ESP studio running on Windows 8 (may be in compability mode)?SAP Event Stream Processor runs on specific platforms and operating systems.PlatformSupported OSCompilerJDK VersionWindows (32-bit)Windows 7 (32-bit), SP1C SDK: MS Visual C++ 2010Java SDK: JDK 1.6, 1.7 and SAP JVM7.NET SDK: MSDEV 2010 SP1 (.NET 4.0), MSDEV 2005 (.NET 3.5 SP1)SAP JVM 7.1.011Windows (64-bit)Windows 2008 Server R2 (64-bit), SP1Windows 7 (64-bit), SP1C SDK: MS Visual C++ 2010Java SDK: JDK 1.6, 1.7 and SAP JVM7.NET SDK: MSDEV 2010 SP1 (.NET 4.0), MSDEV 2005 (.NET 3.5 SP1)SAP JVM 7.1.011Thanks.Bulut", "views": "301", "answers": 2, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-08-21 14:46:00", "resolve": "solution", "uid": "95.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3607200", "text": "Hi Bulut,ESP has not been certified and is not officially supported on Windows 8 or 2012.ESP won't install directly on 2012, I have not heard of anyone trying Windows 8 yet. The underlying \"InstallAnywhere\" installer software that ESP currently uses needs to be updated in order for it to install on Windows 2012 (and I assume Windows 8).I have heard that you can work around the installation issue by running the installer in Windows 7 compatibility mode but have not tried it myself.We have two outstanding requests for engineering to certify Windows 8 and 2012:769312 - Certify ESP on Windows 2012769505 - Certify ESP on Windows 8Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Windows 8 Support", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "95.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3607200", "text": "Hi Neal,Thanks for your response. I have intstalled ESP 5.1 SP08 on Windows 8 in Windows 7 compability mode and run projects on the server successfully. Windows 8 machine is development environment and for now it seems good.Best regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Windows 8 Support", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-19 18:23:00", "resolve": true, "uid": "96", "title": "SDK DLL Compatibility between service packs (sp04/sp08)", "url": "http://scn.sap.com/thread/3605976", "text": "Based on previous experience, I would expect the SP04 sdk dlls to work with an ESP server running SP08, is this correct? Certainly in the past you could.Beyond what is in the release notes. What work was done to the SDK between sp04 and sp08 (this is really only one sp, because of a jump from 04 to 08, correct?).This seems to be a very big change over all to the cluster, etc.", "views": "645", "answers": 2, "author": "David Rosenblum", "upvotes": 0, "type": "question", "tags": "esp_5.1.sdk_net"},
{"date_time": "2014-08-19 21:33:00", "resolve": "solution", "uid": "96.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3605976", "text": "Hi David,Engineering/QA does absolutely no backwards compatibility testing and makes no claims for compatibility between versions.The version jump from SP04 to SP08 was to bring ESP's version in line with HANA's version. So while this means there is only one service pack between these two releases, there were a lot of changes and features added to the product.Work was done in the SDK to make it compatible with the new features in SP08. For example, in SP08 a new type of stream was added: http://help.sap.com/saphelp_esp51sp08/helpdata/en/24/b7b5fdf02f47669e27bbf663594838/content.htmThis new stream replaces the deprecated delta stream. The SDK was enhanced to support/recognize this stream. So for example, if you called stream.getType() on a project containing a keyed stream, the API would correctly tell you the type of stream. If you made the same call from an SP04 SDK, it would not recognize the stream type and may return an error.The cluster configuration along with user role based authentication is stored in a cluster database (SQL Anywhere database). All services are now stored in the cluster database instead of the old \"service.xml\" file.User role based authentication is enabled by default in SP08 (as opposed to SP04 where by default every user had access to every resource). Role based authentication can be turned off but it is advised to keep it on for better security. A new \"security officer\" type of user exists in SP08 to grant regular users permission to resources. This user is named \"espsysusr\": http://help.sap.com/saphelp_esp51sp08cfa/helpdata/en/5d/487862b43d4692bd2d06b9911aa1fd/frameset.htmOnce you get past the authentication and configuration changes, the look and feel of SP08 is much the same as SP04.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SDK DLL Compatibility between service packs (sp04/sp08)", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "96.2", "author": "David Rosenblum", "url": "http://scn.sap.com/thread/3605976", "text": "Thank you Neal!", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SDK DLL Compatibility between service packs (sp04/sp08)", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-25 17:25:00", "resolve": false, "uid": "97", "title": "Code no longer compiles in SP08", "url": "http://scn.sap.com/thread/3609074", "text": "Hi, the following code compiles fine pre SP08 but will no longer compile?CREATE INPUT WINDOW pairsMapping SCHEMA (type1 string, type2 string) PRIMARY KEY (type1, type2) KEEP ALL ROWS;CREATE INPUT WINDOW inputStream SCHEMA (inputType string, inputValue integer) PRIMARY KEY (inputType) KEEP ALL ROWS;CREATE OUTPUT WINDOW allOfType2 PRIMARY KEY (type1, type2) KEEP ALL ROWS AS SELECT inputStream.*, pairsMapping.* FROM inputStream INNER JOIN pairsMapping ON pairsMapping.type2 = inputStream.inputType;CREATE OUTPUT WINDOW allOfType1 PRIMARY KEY (type1, type2) KEEP ALL ROWS AS SELECT inputStream.*, pairsMapping.* FROM inputStream INNER JOIN pairsMapping ON pairsMapping.type1 = inputStream.inputType;CREATE OUTPUT WINDOW typePairsAndValues PRIMARY KEY DEDUCED KEEP ALL ROWS AS SELECT allOfType1.inputType Type1Name, allOfType1.inputValue Type1Value, allOfType2.inputType Type2Name, allOfType2.inputValue Type2Value FROM allOfType1 INNER JOIN allOfType2 ON allOfType1.type2 = allOfType2.inputType GROUP BY allOfType1.inputType;The error I get is \"Element has a cycle in the data flow\". What has changed between SP04 and SP08 to cause this behavior?", "views": "268", "answers": 3, "author": "Garith Botha", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-08-25 17:51:00", "resolve": "", "uid": "97.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3609074", "text": "This sounds like a similar issue I hit in Sp08 when trying to union 2 streams - and it was/is a bug in SP08. Did you try running the project? In my case, although I got the compiler error message, the project would actually run just fine. Also, in the union case, the problem has been fixed in the upcoming SP08 patch - but we should check your code to ensure the same fix covers it.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Code no longer compiles in SP08", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "97.2", "author": "Garith Botha", "url": "http://scn.sap.com/thread/3609074", "text": "Compiling from the command prompt works, you just can't start or compile from the studio.When will the patch be available?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Code no longer compiles in SP08", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "97.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3609074", "text": "Hello,This is scheduled to be fixed for SP 09.The bug number for this is CR (Change Request) 769223.Thank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Code no longer compiles in SP08", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-26 16:49:00", "resolve": false, "uid": "98", "title": "Is there a way to get a trial of sp08?", "url": "http://scn.sap.com/thread/3609792", "text": "The current trial available is still sp04Thank you in advance.David", "views": "243", "answers": 1, "author": "David Rosenblum", "upvotes": 0, "type": "question", "tags": "esp_5.1"},
{"date_time": "2014-08-26 16:55:00", "resolve": "", "uid": "98.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3609792", "text": "I'm expecting (hoping?) that the trial download site will be updated to SP08 later this week.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Is there a way to get a trial of sp08?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-09-04 14:09:00", "resolve": false, "uid": "99", "title": "Unhandled exceptions from ESP", "url": "http://scn.sap.com/thread/3614455", "text": "Hello,From time to time I am getting unhandled exceptions from ESP (5.1 v4 using .NET interface). This is happening only for the high rates of updates (300 records/s). ESP is dying internally, I am not even able to catch exception.That is the exception from .NET Runtime:Application: AvidPublisher.exe Framework Version: v4.0.30319 Description: The process was terminated due to an unhandled exception. Exception Info: System.AccessViolationException Stack: at .SYBASE.Esp.SDK.EspPublisher.publish(SYBASE.Esp.SDK.EspPublisher*, SYBASE.Esp.SDK.EspPublishable*, SYBASE.Esp.SDK.EspError*) at SYBASE.Esp.SDK.NetEspPublisher.publish(SYBASE.Esp.SDK.NetEspMessageWriter, SYBASE.Esp.SDK.NetEspError) at FXDerivatives.Common.StreamingPlatform.EspHelper.Publish(System.String, System.Object[][], Int32) at FXDerivatives.Common.StreamingPlatform.EspHelper.PublishToStream(System.String, System.Collections.Generic.IEnumerable`1, Int32, PublishMode) at FXDerivatives.Common.Aleri.AleriLogWriter.PublishToAleri(System.String, System.String, System.String, FXDerivatives.Common.Aleri.AleriLogLevel, System.String, System.String, System.Collections.Generic.Dictionary`2) at FXDerivatives.Common.Aleri.AleriLogWriter.Write(FXDerivatives.Common.Aleri.AleriLogLevel, System.String, System.String, System.Collections.Generic.Dictionary`2) at FXDerivatives.Common.Aleri.AleriLogWriter.Write(FXDerivatives.Common.Aleri.AleriLogLevel, System.String, System.String, FXDerivatives.Common.MarketData.CurrencyPair, System.String) at AvidPublisher.Publishers.Publisher.LogToAleri(FXDerivatives.Common.Aleri.AleriLogLevel, System.String, System.String, System.String, System.String) at AvidPublisher.Publishers.Publisher.PublishAll(System.String, System.String, System.Collections.Generic.Dictionary`2) at AvidPublisher.Publishers.Publisher+<>c__DisplayClass2.b__0(System.Object, System.Collections.Generic.Dictionary`2) at FXDerivatives.Common.Utility.Bundler`2+DistributeEventHandler[[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089],[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]].Invoke(System.Object, System.Collections.Generic.Dictionary`2) at FXDerivatives.Common.Utility.Bundler`2[[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089],[System.__Canon, mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089]].DistributeEvents(System.Object, System.Timers.ElapsedEventArgs) at System.Timers.Timer.MyTimerCallback(System.Object) at System.Threading.TimerQueueTimer.CallCallbackInContext(System.Object) at System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object, Boolean) at System.Threading.ExecutionContext.Run(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object, Boolean) at System.Threading.TimerQueueTimer.CallCallback() at System.Threading.TimerQueueTimer.Fire() at System.Threading.TimerQueue.FireNextTimers() at System.Threading.TimerQueue.AppDomainTimerCallback() That is the Applciation error:Faulting application name: AvidPublisher.exe, version: 0.0.0.0, time stamp: 0x54083da6 Faulting module name: MSVCR100.dll, version: 10.0.40219.1, time stamp: 0x4d5f0c22 Exception code: 0xc0000005 Fault offset: 0x00010a5d Faulting process id: 0xd78 Faulting application start time: 0x01cfc82a6a680ae9 Faulting application path: D:\\FXDeriv\\Apps\\AvidPublisher\\AvidPublisher.exe Faulting module path: C:\\Windows\\system32\\MSVCR100.dll Report Id: 48d4d149-341f-11e4-ae8a-0050569a4c0f Can you please advise? Are you experiencing similar problems?", "views": "391", "answers": 5, "author": "Jacek Macura", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-09-04 15:06:00", "resolve": "", "uid": "99.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3614455", "text": "Hi Jacek,Can you share the esp_server.log file and the cluster log file? What does the project CCL look like? Where is the ESP project running - what environment? Would you be able to provide us with enough so that we can reproduce the problem?Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unhandled exceptions from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "99.2", "author": "Jacek Macura", "url": "http://scn.sap.com/thread/3614455", "text": "Hello,Please see attached file (exception occurred around 11:36 ).Version of ESP: 5.1 sp4.Environment: Linux esplni01 2.6.32-279.5.1.el6.x86_64 #1 SMP Tue Jul 24 13:57:35 EDT 2012 x86_64 x86_64 x86_64 GNU/LinuxIt is happening only for the high rates of updates. When reproducing on my PC I do not have specific scenario, it is happening randomly.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unhandled exceptions from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "99.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3614455", "text": "Hi Jacek,Also, can you tell me more about your application - is it publishing 300 records/s from a single publisher? Or does your application have multiple threads and each is publishing data that adds up to 300 records/s?Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unhandled exceptions from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "99.4", "author": "Jacek Macura", "url": "http://scn.sap.com/thread/3614455", "text": "Pardon, if I wasn't clear. there are many types of applications that are actually failing, so there is no specific scenario. I have around 20 separate applications which are listening for changes and 1 aplication which copy all data from Aleri to ESP. This app never fails, as it is basically publishing around 15 different datatables sequentially. But those 20 separate applications are failing randomly when trying to consume data, and then save data back to ESP if required. there is 1 more place when application is failing, when different threads are subscribing to stream, and ESP crashes when we call: _subscriber.connect(espError);", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unhandled exceptions from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "99.5", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3614455", "text": "Hi Jacek,There are no known issues for what you are describing. Please log a technical support case and provide a reproduction.Thank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Unhandled exceptions from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2014-09-09 09:54:00", "resolve": false, "uid": "100", "title": "Adding new user/password with esp_cluster_admin", "url": "http://scn.sap.com/thread/3616689", "text": "Hi,I'am trying at the moment to add the first workspace to my cluster.For this i used the tool esp_Cluster_admin with the default user \"espsysusr\". But the user has not the needed permissions.So i added a new user with the requiered permissions: grant permissions all to user admin1And here comes my Problem: How can i set a password for this new user \"admin1\"?With the tool \"keytool\" I also created a keystore for the user \"admin1\" and deployed it in esp_cluster_admin. Sadly without success.Thanks,Matthias", "views": "500", "answers": 1, "author": "Matthias Hanel", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-09-09 14:47:00", "resolve": "", "uid": "100.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3616689", "text": "Hello,espsysusr is like a security officer, it can only grant permissions to users. espsysusr can't do anything else like running a project or creating a workspace.If you selected \"Native OS\", RSA, Kerberos or \"SAP BI\" authentication scheme during installation (see Authentication) users and their passwords do not exist inside the ESP cluster. The users that you authenticate to ESP with need to be valid users per the authentication scheme you selected during the installation.So if you chose \"Native OS\" and installed on Linux, \"admin1\" would need to be a valid user on Linux. Also, on Linux there are some post-installation tasks that you need to complete for this to work: Configuring a Pluggable Authentication Module (PAM)If this is on Windows, the default configuration of the cluster makes it easiest (and in some cases required) to append the domain name on to the user you are authenticating:If you are authenticating a valid Windows user belonging to a Windows domain, the format is: username@domainIf you are authenticating a local Windows user who does not belong to a domain, the format is: username@pc_nameSo when you grant permission to the Windows user it looks like this:esp_cluster_admin --uri=esp://hostname:19011 --username=espsysusr --password=cluster_password> grant perm all to user username@domainThanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Adding new user/password with esp_cluster_admin", "type": "answer", "tags": "N/A"},
{"date_time": "2014-08-26 09:39:00", "resolve": true, "uid": "101", "title": "RPC2 error", "url": "http://scn.sap.com/thread/3609401", "text": "Hi all,Our team has a conncetion problem.That is http://localhost:44845/RPC2 error.We can insert data into ESP via wsp.But we cannot get data from ESP via JDBC, then upper message was occured.If you know this issu, please tell me the way to resolve it.Thank you in advance.Yusuke", "views": "511", "answers": 6, "author": "yusuke imamura", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-08-26 09:55:00", "resolve": "", "uid": "101.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3609401", "text": "Hi,This link does not work on our PC because the localhost is not the one on our machines.Are you by any change running it on localhost for the cluster instead of the machine name?>>That is http://localhost:44845/RPC2 error.Are you able to provide a little more information including exact version that you are running, the connection parameters or jdbc url, error details and what the setup is?Thanks,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:RPC2 error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "101.2", "author": "yusuke imamura", "url": "http://scn.sap.com/thread/3609401", "text": "Hi Ben,Your answer was our big help!Beacuse we have to resolve this problem quickly!We had the below error. .\"http://localhost:44548/RPC2 (Fail to read sever's responce: Communiction refused.)\"Upper URI is not link. Just a part of error message.We create node1.xml <ESP_HOSTNAME> is localhost.And .ccr parmeter <Cluster name=\"localhost:19011\" type=\"local\".", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:RPC2 error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "101.3", "author": "yusuke imamura", "url": "http://scn.sap.com/thread/3609401", "text": "For resolving this issue, we changed node1.xml and .ccr file and try again.But the issue wasn't resolved.node1.xml<ESP_HOSTNAME> 172.19.xx.xxx.ccr file<Cluster name=\"172.19.xx.xxx:19011\" type=\"local\">And we couldn't start this project...Then same error message was occured.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:RPC2 error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "101.4", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3609401", "text": "Hi, I still think we need a little more information.Are you using ESP SP04 or SP08 and how exactly are you trying to connect through JDBC?The error \"http://localhost:44548/RPC2 (Fail to read sever's responce: Communiction refused.)\"could just say there is nothing listening on that port.If you couldn't start the project then you can't connect to it either.Do you have the server log and cluster log stdstreams log, client logs?Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:RPC2 error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "101.5", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3609401", "text": "Hi,Connection error looks due to using localhost. If trying to coneect from a different machine then that can't work.Here is a reference:http://scn.sap.com/docs/DOC-42804 It is not clear to me how you are starting the project, but instead of editing the .ccr file, maybe you can start the cluster and then connect to it with the studio. Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:RPC2 error", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "101.6", "author": "yusuke imamura", "url": "http://scn.sap.com/thread/3609401", "text": "Hi Mr.Ben,Thank you for your answer and sorry for my late reply.It was as you say that my project didn't seem to start.I created new project and copied ccl program, so it did work well.Best regards,Yusuke", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:RPC2 error", "type": "answer", "tags": "N/A"},
{"date_time": "2014-09-09 20:42:00", "resolve": true, "uid": "102", "title": "ESP version for hana_out", "url": "http://scn.sap.com/thread/3617185", "text": "Hi team,I'm trying connecting ESP to HANA, but it didn't work well.If you know about hana output adapter, please give me some advices.The below is my situation.1) I created test.ccl file. please see the attachment file. (test.ccl.txt) * .txt extension is dummy for uploading.2) I compiled test.ccl file to test.ccx3) I started test project by using ccx file, but it failed4) I checked esp_server.log. I found the error, \"OutConnection HANA_Output1 is invalid: No connection with type hana_out for this version of the Sybase Event Stream Processor.\" Please see the attachment file.(esp_server.log) * .txt extention is dummy for uploading.5) I checked esp version by using esp utility commands (esp_server, esp_cluster_admin, esp_compiler). The version is 5.1.04.I have already set up the HANA Client, unixODBC, odbc.ini and service.xml.And I think there is no problem of ESP version.HANA version is 7.4(SuSE).Thank you in advance,Yusuke", "views": "580", "answers": 2, "author": "yusuke imamura", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-09-09 22:54:00", "resolve": "solution", "uid": "102.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3617185", "text": "Hi Yusuke,1. Stop the cluster.2. Check what version of unixODBC you installed - should be 2.3.1 or higher:$ cd $ESP_HOME$ odbcinst -jIt will return with the version it is using, e.g.unixODBC 2.3.2DRIVERS............: /usr/local/etc/odbcinst.iniSYSTEM DATA SOURCES: /usr/local/etc/odbc.iniFILE DATA SOURCES..: /usr/local/etc/ODBCDataSourcesUSER DATA SOURCES..: /usr/u/nstack/.odbc.iniSQLULEN Size.......: 8SQLLEN Size........: 8SQLSETPOSIROW Size.: 83. Then do:$ whereis libodbc.so.1It will return with something like this:libodbc.so: /usr/local/lib/libodbc.so.1 /usr/local/lib/libodbc.so.2/usr/local/lib/libodbc.soThen, set your LD_LIBRARY_PATH to include the directory where \"libodbc.so.1\" is found.4. What's in your .odbc.ini file? Set the Driver to the path for your libodbcHDB.so[archer_hana]Driver=/work/HANA_client/libodbcHDB.soservernode=archer:30015USER=SYSTEMPassword=<password>CHAR_AS_UTF8=true5. Restart the clusterThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP version for hana_out", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "102.2", "author": "yusuke imamura", "url": "http://scn.sap.com/thread/3617185", "text": "Hi Alice,Thank you for your quick and kind reply!I read your advice and tried again. Then my test project work well!The below is my checking point.2)[root@xx]# odbcinst -junixODBC 2.3.2DRIVERS............: /usr/local/etc/odbcinst.iniSYSTEM DATA SOURCES: /usr/local/etc/odbc.iniFILE DATA SOURCES..: /usr/local/etc/ODBCDataSourcesUSER DATA SOURCES..: /root/.odbc.iniSQLULEN Size.......: 8SQLLEN Size........: 8SQLSETPOSIROW Size.: 83)# whereis libodbc.so.1libodbc.so: /usr/local/lib/libodbc.so.2 /usr/local/lib/libodbc.soso I create libodbc.so.1 as symbolic link of libodbc.so.2.0.0libodbc.so: /usr/local/lib/libodbc.so.2 /usr/local/lib/libodbc.so /usr/local/lib/libodbc.so.1# echo $LD_LIBRARY_PATH/usr/sap/hdbclient:/usr/local/lib:and other path4) What's in your .odbc.ini file? Set the Driver to the path for your libodbcHDB.so[HANA_CON]Driver = /usr/sap/hdbclient/libodbcHDB.soServerNode = hanahost:30015Thank you very match!The test is very well, but my working ccl has onther error.\"Unable to get the number of columns for target DB table \"XXX.XXX\"\"Now I'm shooting this problem...Sincerely,Yusuke", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP version for hana_out", "type": "answer", "tags": "N/A"},
{"date_time": "2014-09-04 16:27:00", "resolve": false, "uid": "103", "title": "Does Generic DB Output Adapter write to Vertica?", "url": "http://scn.sap.com/thread/3614567", "text": "Can we use Generic DB Output adapter to write Vertica? Is it supported?Thanks,Bulut", "views": "505", "answers": 4, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-09-04 18:15:00", "resolve": "", "uid": "103.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3614567", "text": "Hi Bulut,According to the documentation: Database Input AdapterThe \"supported\"  databases for JDBC are SAP Sybase ASE, Microsoft SQL Server, IBM DB2, Oracle, and KDB. The \"supported\" databases for ODBC are SAP Sybase ASE, Microsoft SQL Server, IBM DB2, Oracle, SAP Sybase IQ, SQL Anywhere, TimesTen, MySQL 5.x, and PostgreSQL.These are just the databases that QA has tested.But since this is a generic database adapter, I would expect it to work with compliant ODBC drivers from other databases. It appears that Vertica has an ODBC driver: https://my.vertica.com/docs/4.1/HTML/Master/4137.htmI would say, give it a try and see if it works. If you get errors, we can always log a new feature request to add support for it.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Does Generic DB Output Adapter write to Vertica?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "103.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3614567", "text": "Hi Neal,I have tested Generic DB ouput adapter to connect to Vertica with ODBC and it works successfully. However, row by row insert into Vertica may cause some performance problem when data streams to Vertica in a high frequency. Therefore I am trying to load data to Vertica by exporting data to a file and then loading it into Vertica. This is similar to IQ load operation (IQ output adapter). To do this, I am developing custom adapter with toolkit. Currently, I can export data to a file. But my problem is getting a service information, which is under Data Services, from the toolkit. I don't want to get user/password information from adapter parameters. I search this in the docs which are located $ESP_HOME/docs/adaptertoolkit but I could not find something related. Do I have chance to get the database connection information from a service?Thanks and regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Does Generic DB Output Adapter write to Vertica?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "103.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3614567", "text": "Hi Bulut,You can use the Server.DataService class that is part of the ESP Java SDK (com.sybase.esp.sdk.Server.DataService).Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Does Generic DB Output Adapter write to Vertica?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "103.4", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3614567", "text": "Hi Bulut,Just curious, were you not able to use the batchLimit parameter on the output adapter to force it to write to Vertica in batches rather than one row at a time?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Does Generic DB Output Adapter write to Vertica?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-09-04 16:24:00", "resolve": true, "uid": "104", "title": "Connect ESP to SQL Any with OEM Authentication", "url": "http://scn.sap.com/thread/3614532", "text": "Hi Experts,we currently develop an Application based on ESP and SQL Anywhere based on the OEM licence model. For that the SQL Any DB is registered for an Application (as described here: DocCommentXchange). Noe all connected applications need to authenticate themselve when connection to that particular DB (see this: DocCommentXchange).And here is my problem, I could not find any hint in the ESP documents or in SDN on how to set this Option and when (during ESP-Startup? or Application Start?)Anyone had the same issue?Thanks in Advance,Magnus", "views": "523", "answers": 5, "author": "Magnus Leinemann", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-09-04 22:01:00", "resolve": "solution", "uid": "104.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3614532", "text": "Hi Magnus,ESP only has access to the SQL Anywhere ODBC Driver (I assume that is how you have ESP configured to connect to SQL Anywhere). The only way I see how you can do this is to configure the ODBC driver with the \"InitString\" property:DocCommentXchangeSo I created a DSN like this but I don't have a SQL Anywhere environment to test against: dbdsn -y -wu \"DENN_cluster2\" -c \"UID=espdbadm;PWD=Password1;DBN=esp_cluster;ServerName=esp_cluster_esp1_denn00530262a;INT=NO;InitString='SET TEMPORARY OPTION connection_authentication=''Company=MyCo;Application=MyApp;Signature=0fa55157edb8e14d818e'''\"If you are not able to use the \"InitString\" method, you should probably open a technical support case and we can log a new feature request for you.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect ESP to SQL Any with OEM Authentication", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "104.2", "author": "Magnus Leinemann", "url": "http://scn.sap.com/thread/3614532", "text": "Hi Neal,thanks for your answer, unluckily it did not work out. As it looks, the InitString option is used, but the Authentication then fails.Maybe there is a wrong charset, as there is an German Umlaut in the Authentication literal . When authenticating the DB I was able to set correct charset and do the authentication then. Is there another option to change the charset used in the odbc connection?I tested already with isql and iusql, but both failed. When I try iusql -v DSN then first message is \"[unixODBC][Sybase][ODBC Driver][SQL Anywhere]Authentication failed\", when using the non-authenticated DSN the same error raises when trying to set the authentication.In the ESP logs I could not find a corresponding message till now, but when I test the application, the SQL Insert fails due to Authentication Failure.Any further idea? Or shall I try the support?ThanksMagnus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect ESP to SQL Any with OEM Authentication", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "104.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3614532", "text": "Hello,Could you add \"Charset=UTF8;\" (or whatever character set is appropriate) to the command you use to create the ODBC DSN? Then you end up with something like this in your \".odbc.ini\" file:[DENN_cluster2]UID=espdbadmPWD=Password1DatabaseName=esp_clusterServerName=esp_cluster_esp1_denn00530262aIntegrated=NOCharset=UTF8InitString=SET TEMPORARY OPTION connection_authentication='Company=MyCo;Application=MyApp;Signature=0fa55157edb8e14d818e'Driver=libdbodbc16.soIf that doesn't do it for you, before you log a support case, you might try asking the SQL Anywhere community: SAP SQL AnywhereThey would be much more knowledgeable about the different combinations for the SQL Anywhere ODBC driver than anyone in the ESP community. If it comes down to the point where you can't find a configuration of the SQL Anywhere ODBC that works and you need a new feature added to ESP, feel free to log a technical support case.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect ESP to SQL Any with OEM Authentication", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "104.4", "author": "Magnus Leinemann", "url": "http://scn.sap.com/thread/3614532", "text": "Hi Neal,I gave it a try, but same result as before. So I will move to the SQL Anywhere group....Thanks for adviceMagnus", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect ESP to SQL Any with OEM Authentication", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "104.5", "author": "Magnus Leinemann", "url": "http://scn.sap.com/thread/3614532", "text": "The InitString Parameter in the ODBC.ini is the correct solution for this question. All other issues had been based on wrong character sets....", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connect ESP to SQL Any with OEM Authentication", "type": "answer", "tags": "N/A"},
{"date_time": "2014-09-22 18:44:00", "resolve": false, "uid": "105", "title": "Problem with input/output to/from ESP", "url": "http://scn.sap.com/thread/3624414", "text": "Hi,Our project has the following parameters:A large number of continuous data producing clients (devices), which constantly provide data that needs to be processed and partly saved in HANA.Several clients (users) that need the processed data for the application running on their machine. Input:Is there any way to connect a large number of clients delivering input constantly to an ESP project? Right now we use a server to accept the clients and consolidate all data into one queue which is then forwarded to ESP through a csv socket input adapter.Output:We need a snapshot of a window's content at a certain time (when queried). We tried the http output adapter, but it provides only a never ending stream of input, update or delete events. The same applies when connecting to a csv socket output adapter from a server and getting the window's content.It would be great if anyone can help us with these queries.Thanks,Bhumi Patel.", "views": "829", "answers": 8, "author": "Bhumi Patel", "upvotes": 0, "type": "question", "tags": "windows.adapter.esp"},
{"date_time": "2014-09-22 19:04:00", "resolve": "", "uid": "105.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3624414", "text": "Hi Bhumi,I will respond to the Output question, and I will let others chime in about the Input question. It is suggested to post separately for each question you have so that others can follow and find the information, please do start a new post for that one. Thanks!To get a snapshot of a window's content at a certain time, you could use esp_subscribe, and use the -S option to just get a snapshot.Here is the link to the ESP 5.1 SP08 document that describes esp_subscribe.esp_subscribe - Utilities Guide - SAP LibraryThank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Problem with input/output to/from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "105.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3624414", "text": "Other options for the snapshot query include:- HANA Smart data access: map the ESP window to HANA and query HANA- The \"other\" ESP http output adapter: this adapter is poorly named, but accepts queries via http and delivers a snapshot result- Us the ESP ODBC driver to run snapshot queries against ESP windowsAs for the question on input: Yes, you can have a large number of publishers that publish direct to ESP without having to implement a \"consolidator\". There are several options:1. Use the ESP Web Service Provider, REST interface, and have all publishers publish directly to that2. Use a message bus with either the ESP JMS or MQ input adapter, and have all publishers publish to the bus. If you are interested in other messaging (eg ActiveMQ or RabbitMQ - let me know - it's an area we are gathering requirements on).3. Use a messaging appliance, such as the one from Solace Systems, that provides very good scalability and connects to ESP using the standard ESP JMS adapter4. All publishers can connect directly to ESP using TCP Sockets and you can scale for large numbers of publishers by running a set of ESP \"gateway projects\" and then one or more ESP \"consolidation\" projects. You spread the publishers across the gateways. So, for example, if you assign 500 publishers to each gateway project, then running 10 gateway project instances will support 5,000 publishers.", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Problem with input/output to/from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "105.3", "author": "Bhumi Patel", "url": "http://scn.sap.com/thread/3624414", "text": "Hi Jeff,Thanks for your responses.We can try implementing one of the four options you have mentioned for input consolidator.Regarding snapshot query, we had tried using http output adapter. We used sample HTTPAdapterClient.html file provided under Sybase/ESP-5_1/adapters/http/examples to query the server, but it returns a stream instead of a snapshot. Is there any specific setting which we are missing?Please let me know.Thanks,Bhumi Patel.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with input/output to/from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "105.4", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3624414", "text": "That's a different adapter. There are two http output adapters. They are unfortunately named, which make it confusing. The http client output adapter publishes every output event to an http server, in real-time. The \"other\" http output adapter listens for http requests for snapshot queries. Check the doc for both/each", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with input/output to/from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "105.5", "author": "Bhumi Patel", "url": "http://scn.sap.com/thread/3624414", "text": "Oh ok, then we have to look again for both of those adapters.Thanks for clarification!Regards,Bhumi Patel.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with input/output to/from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "105.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3624414", "text": "Hello,Just curious with the CSV Socket Input Adapter, did you find some kind of limitation or bottleneck? I don't know if you used the example from the SAP Wiki site but I think this example could be expanded to have multiple queues that each have a connection to the project.I have seen several customers go with the Web Service Provider:http://help.sap.com/saphelp_esp51sp08ag/helpdata/en/e7/7715d36f0f101488e3b595ee582190/content.htm?frameset=/en/e7/74b2646f0f1014a48c9dfaf12c5d85/frameset.htm&current_toc=/en/e7/74b2646f0f1014a48c9dfaf12c5d85/plain.htm&node_id=617&show_children=falseSince this adapter maintains a pool of connections to the project it reduces the load on the cluster manager particularly for applications that are heavy connect/disconnect types.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with input/output to/from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "105.7", "author": "Bhumi Patel", "url": "http://scn.sap.com/thread/3624414", "text": "Hi Neal,I am not sure what kind of bottleneck you are thinking about, currently we are using an input consolidator which is basically taking all the requests from multiple clients and putting them in a queue, and we are piping that queue to the CSV Socket Input Adapter because I think each CSV Socket Input Adapter can receive input from just one client/server (CSV Socket Input Adapter can not handle data from multiple clients/sources). Is that correct or am I missing something here?Right now CSV Socket Input Adapter is working fine for us in above mentioned setup.But yes, we can look into Web Service provider you have mentioned.Thanks for the information!Regards,Bhumi Patel.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with input/output to/from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "105.8", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3624414", "text": "Hello,Yes, each instance of the CSV Socket Input Adapter in a project reads from (or writes to) the server it is connected to. This adapter acts as a client and connects to a server.I had mistakenly thought you might be using the CSV Socket Server example that we have on our wiki site here: SocketServerExample - SAP Event Stream Processor - SCN WikiThis is a server. It reads from each client that connects to it and puts that data into a queue that is then published to the project. In its current form it only maintains one connection to the project but since it is an example, it could easily be expanded to have multiple connections. In a sense, it would be acting like a connection pool similar to the WSP adapter shielding the ESP cluster manager from the connect/disconnect activity. This example is not as advanced as the WSP adapter so the WSP adapter may better suit your needs.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with input/output to/from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2014-09-24 14:49:00", "resolve": false, "uid": "106", "title": "Setup Cluster for Active-Active Deployment", "url": "http://scn.sap.com/thread/3625672", "text": "Hi all,I am trying to setup an ESP cluster with two Linux hosts. My ESP version is 5.1 SP08. My main target is to deploy project in active-active mode on these two hosts. But, from the guides (admin, docs in scn etc.), I could not understand the steps that I need to do for cluster setup with two hosts. I have a couple of questions that I could not find answers from docs.Do I need to run a single cluster database or run cluster database on each hosts?Do I need to start a cluster on one host and than add nodes to cluster?What sould be the hierarchy of the shared folders between the hosts?etc..If anyone who setup such a cluster summarize the steps, I will be grateful.Thank you very much.Bulut", "views": "417", "answers": 3, "author": "Bulut Altintas", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-09-24 19:39:00", "resolve": "", "uid": "106.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3625672", "text": "Hi Bulut,There can only be one active cluster database per cluster. You can set it up for high availability as documented here (in this case there are two cluster databases plus an arbiter but only one is ever active): Configuring SAP SQL Anywhere Server for High Availability - Configuration and Administration Guide - SAP LibraryThere is a multi-node cluster example in $ESP_HOME/cluster/examples/cluster_example.xml . See the readme \"cluster_example_readme.txt\" in the same directory.I have not had time to try this yet but I think you would:1) Start the cluster database on whichever node you choose. The cluster database always has to be started first. (See $ESP_HOME/cluster/config/esp1/start_db.sh).2) Start a cluster node (See $ESP_HOME/cluster/config/esp1/start_node.sh): start_node.sh node1 &3) On one of the other hosts start a second node: start_node.sh node2 &Which directories need to be shared? In the following link, search for \"Needs shared drive?\". On the following line it will say yes/no. The formatting is terrible and I have filed a documentation bug:File and Directory Infrastructure - Configuration and Administration Guide - SAP LibraryI include the link to the SP04 documentation because the formatting is better but note the directory structure changed slightly between SP04 and SP08: http://infocenter.sybase.com/help/topic/com.sybase.infocenter.dc01611.0514/doc/html/swa1308776088481.htmlYou mention active-active at the beginning of your post. A word of caution here... Active-active should only be used with projects that do not have adapters. In an active-active setup, both projects are live. The adapters running in these projects have no knowledge of each other. So for example, if you have a Generic Database Output adapter in the project, there would be two adapters running (one in each project) and they would both be simultaneously writing to the target database.Cold failover is the better (perhaps the only) choice for projects containing adapters.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Setup Cluster for Active-Active Deployment", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "106.2", "author": "Bulut Altintas", "url": "http://scn.sap.com/thread/3625672", "text": "Hi Neal,Thank you very much for your answer. As your said, I run only one database for my cluster. It is run on \"maslak\" node. I modified cluster_example.xml. Since I could not attach a file in a reply message, I am pasting it as text.I have two host machine. One of them is \"maslak\" and the other one is \"sariyer\". Cluster db is running on \"maslak\". I deploy the following xml file to database. Then, I start node1 and node3 on \"maslak\" and I start node2 and node4 on \"sariyer\" with $ESP_HOME/cluster/exemple/start_node.sh nodeX command. However, when I check cluster, I show that node1 and node3 run together on \"maslak\" while node2 and node4 are running together on \"sariyer\".Accordingly, when I deploy a project to a manager run on \"maslak\", then it is run on both node1 and node3 due to the HA mode. Similarly, when I deploy a project on \"sariyer\", then it is run on both node2 and node4.------------------------------------------------------------------------------\"maslak\":[sybase@maslak examples]$ $ESP_HOME/bin/esp_cluster_admin --uri=esp://maslak:19011 --username=sybase --password=sybase> get managersManager[0]: node1@http://maslak:19011Manager[1]: node3@http://maslak:19013> get controllersController[0]: node3@http://maslak:19013Controller[1]: node1@http://maslak:19011------------------------------------------------------------------------------\"sariyer\":[sybase@sariyer bin]$ ./esp_cluster_admin --uri=esp://sariyer:19012 --username=sybase --password=sybase> get managersManager[0]: node2@http://sariyer:19012> get controllersController[0]: node4@http://sariyer:19014Controller[1]: node2@http://sariyer:19012I don't understand why I could not see all nodes together. Do I missing something? Do you have any suggestion? ------------------------------------------------------------------------------cluster_example.xml<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?><Cluster> <Macros> <Macro name=\"ESP_HOME\" type=\"envar\">ESP_HOME</Macro> <Macro name=\"ESP_SHARED\" type=\"value\">/shared/Shared</Macro> <Macro name=\"ESP_STORAGE\" type=\"value\">${ESP_SHARED}/storage</Macro> </Macros> <SystemProperties/> <Manager/> <Controller> <ApplicationTypes> <ApplicationType enabled=\"true\" name=\"ha_project\"> <Class>com.sybase.esp.cluster.plugins.apptypes.HaProject</Class> <StandardStreamLogging enabled=\"true\"/> <Properties> <Property name=\"base-directory\">${ESP_HOME}/cluster/examples/projects</Property> <Property name=\"esp-home\">${ESP_HOME}</Property> <Property name=\"hostname\">${ESP_HOSTNAME}</Property> <Property name=\"ld-preload\">${ESP_HOME}/lib/libjsig.so</Property> <Property name=\"debug-level\">4</Property> </Properties> </ApplicationType> <ApplicationType enabled=\"true\" name=\"project\"> <Class>com.sybase.esp.cluster.plugins.apptypes.Project</Class> <StandardStreamLogging enabled=\"true\"/> <Properties> <Property name=\"base-directory\">${ESP_HOME}/cluster/examples/projects</Property> <Property name=\"esp-home\">${ESP_HOME}</Property> <Property name=\"hostname\">${ESP_HOSTNAME}</Property> <Property name=\"ld-preload\">${ESP_HOME}/lib/libjsig.so</Property> <Property name=\"debug-level\">4</Property> </Properties> </ApplicationType> <ApplicationType enabled=\"true\" name=\"toolkit_adapter\"> <Class>com.sybase.esp.cluster.plugins.apptypes.FrameworkAdapter</Class> <StandardStreamLogging enabled=\"true\"/> <Properties> <Property name=\"esp-home\">${ESP_HOME}</Property> <Property name=\"base-directory\">${ESP_HOME}/cluster/examples/adapters</Property> </Properties> </ApplicationType> </ApplicationTypes> </Controller> <ServiceProvider> <ServiceTypes> <ServiceType name=\"discovery\" enabled=\"true\"> <Class>com.sybase.esp.cluster.plugins.servicetypes.adapter.DiscoveryServiceImpl</Class> <StandardStreamLog enabled=\"true\"/> <Properties> <Property name=\"base-directory\">${ESP_HOME}/cluster/examples/discovery</Property> <Property name=\"cnxml-path\">${ESP_HOME}/lib/adapters</Property> <Property name=\"esp-home\">${ESP_HOME}</Property> <Property name=\"hostname\">${ESP_HOSTNAME}</Property> </Properties> </ServiceType> </ServiceTypes> </ServiceProvider> <Rpc> <Ssl enabled=\"false\"/> </Rpc> <Cache> <Persistence enabled=\"false\"> <Directory>${ESP_STORAGE}</Directory> <Limited enabled=\"true\"> <DataService enabled=\"true\"/> </Limited> </Persistence> <Multicast enabled=\"false\"/> </Cache> <Security> <Authenticators> <Authenticator> <Provider>com.sybase.security.core.PreConfiguredUserLoginModule</Provider> <Options> <Option name=\"username\">sybase</Option> <Option name=\"password\">{SHA-256:96rO7HHy5J0=}3xLgcVQsskbwazcBo097Ggr6sJC9c7oBHqqxkIBT3aQ=</Option> </Options> </Authenticator> </Authenticators> <Authorizer enabled=\"false\"/> <KeyStore> <Type>JKS</Type> <File>${ESP_HOME}/cluster/examples/cluster_example.jks</File> <Password encrypted=\"true\">yhEtAqBrEY7FM1kO0V590/d2Imq0qVvf1wJoJa3+JwuwF6Ti</Password> <KeyPassword encrypted=\"true\">yhEtAqBrEY7FM1kO0V590/d2Imq0qVvf1wJoJa3+JwuwF6Ti</KeyPassword> <Algorithm>RSA</Algorithm> </KeyStore> </Security> <Nodes> <Node enabled=\"true\" name=\"node1\"> <Macros> <Macro name=\"ESP_HOSTNAME\" type=\"value\">maslak</Macro> </Macros> <SystemProperties/> <Manager enabled=\"true\"/> <Controller enabled=\"true\"> <ApplicationTypes/> </Controller> <ServiceProvider enabled=\"true\"> <ServiceTypes/> </ServiceProvider> <Rpc> <Host>${ESP_HOSTNAME}</Host> <Port>19011</Port> </Rpc> <Cache> <Host>${ESP_HOSTNAME}</Host> <Port>19001</Port> </Cache> </Node> <Node enabled=\"true\" name=\"node2\"> <Macros> <Macro name=\"ESP_HOSTNAME\" type=\"value\">sariyer</Macro> </Macros> <SystemProperties/> <Manager enabled=\"true\"/> <Controller enabled=\"true\"> <ApplicationTypes/> </Controller> <Rpc> <Host>${ESP_HOSTNAME}</Host> <Port>19012</Port> </Rpc> <Cache> <Host>${ESP_HOSTNAME}</Host> <Port>19002</Port> </Cache> </Node> <Node enabled=\"true\" name=\"node3\"> <Macros> <Macro name=\"ESP_HOSTNAME\" type=\"value\">maslak</Macro> </Macros> <SystemProperties/> <Manager enabled=\"true\"/> <Controller enabled=\"true\"> <ApplicationTypes/> </Controller> <Rpc> <Host>${ESP_HOSTNAME}</Host> <Port>19013</Port> </Rpc> <Cache> <Host>${ESP_HOSTNAME}</Host> <Port>19003</Port> </Cache> </Node> <Node enabled=\"true\" name=\"node4\"> <Macros> <Macro name=\"ESP_HOSTNAME\" type=\"value\">sariyer</Macro> </Macros> <SystemProperties/> <Manager enabled=\"false\"/> <Controller enabled=\"true\"> <ApplicationTypes/> </Controller> <Rpc> <Host>${ESP_HOSTNAME}</Host> <Port>19014</Port> </Rpc> <Cache> <Host>${ESP_HOSTNAME}</Host> <Port>19004</Port> </Cache> </Node> </Nodes></Cluster>------------------------------------------------------------------------------By the way, thank you very much for your comments on \"active-active\" deployment. I understand that when I use input adapters in my project and deploy it in active-active mode, both projects connect to sources seperately. I was thinking that primary instance connects to data sources and streaming data is passed to secondary instance through the protocol between the instances. In this case, active-active deployment is not so usefull. Based on your experience, what kind of projects can run for active-active?Thanks and regards,Bulut", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Setup Cluster for Active-Active Deployment", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "106.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3625672", "text": "Hi Bulut,I don't see anything obviously wrong with your cluster configuration. I used the same example cluster configuration file and started two nodes. Since I didn't have a \"log4j.properties\" when I started the nodes, all of the logging went to stdout but in this logging I can see it took awhile (almost 2 minutes) for the nodes to discover each other:Sep 26 2014 07:24:02.253 INFO hz._hzInstance_1_esp_multi.cached.thread-5 com.sybase.esp.cluster.impl.CacheService - CODE_700102 | Membership listener...memberRemoved Member [127.0.0.1]:19001Sep 26 2014 07:24:02.254 INFO hz._hzInstance_1_esp_multi.cached.thread-5 com.sybase.esp.cluster.impl.CacheService - CODE_700103 | Membership listener cleaning up member Member [127.0.0.1]:19001Sep 26 2014 07:25:56.546 INFO hz._hzInstance_1_esp_multi.cached.thread-3 com.sybase.esp.cluster.impl.CacheService - CODE_700101 | Membership listener...memberAdded Member [10.7.119.177]:19003 thisSep 26 2014 07:26:02.557 INFO hz._hzInstance_1_esp_multi.cached.thread-3 com.sybase.esp.cluster.impl.CacheService - CODE_700101 | Membership listener...memberAdded Member [127.0.0.1]:19001It may have taken two minutes because I am working remotely on a VPN today I'm not sure. I'll be traveling for the next week so I won't be able to investigate further.If you don't see anything obvious in each node's stdout logging, you may need to modify your start_node.sh/start_node.bat to be more like the one in $ESP_HOME/cluster/config/esp1 where it uses a \"log4j.properties\" type file and change all of the \"info\" references to \"debug\":% grep LOG start_node.shESP_CLUSTER_LOG_PROPERTIES=cluster.log.propertiesESP_CLUSTER_NODE_LOG_FILE=$ESP_CLUSTER_NODE_NAME.log\"$ESP_HOME/bin/esp_cluster_node\" -p$ESP_CLUSTER_LOG_PROPERTIES -f$ESP_CLUSTER_NODE_LOG_FILE --config $ESP_CLUSTER_CONFIG --node-name $ESP_CLUSTER_NODE_NAMEOnly a wild guess, you might check your two Linux boxes to see if they have a proxy between them that would prevent easy from communicating:% env | grep proxyhttp_proxy=http://proxy.acme.com:8080https_proxy=http://proxy.acme.com:8080ftp_proxy=http://proxy.acme.com:8080no_proxy=archer.acme.com,localhost,127.0.0.1,archer2.acme.com,archer,10.7.119.177As for when to use active-active? Maybe you have a project that performs some complex calculations and stores the results in a WINDOW. This project does not write the data anywhere but there are clients that subscribe to the WINDOW. You want the clients to always be able to subscribe to this window. One project goes down, the other is still running with an exact copy of the data.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Setup Cluster for Active-Active Deployment", "type": "answer", "tags": "N/A"},
{"date_time": "2014-10-03 16:28:00", "resolve": true, "uid": "107", "title": "ESP project memory leaks : diagnosing", "url": "http://scn.sap.com/thread/3630307", "text": "Hello,I have an ESP project that grows in its memory footprint far beyond what I expect and/or can tolerate.I suspect I am not managing memory properly in my FLEX components (I have two of them, where mostof my heavy lifting is being done, each with several input windows).Where does one begin to identify where the leaks are?Thanks,Michael", "views": "1010", "answers": 6, "author": "Michael Scharber", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-10-06 17:54:00", "resolve": "", "uid": "107.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3630307", "text": "Hi,Flex code is difficult to debug and the most usefull statement might be the print statement.Is there any reason that you suspect the Flex components for the memory leak?Do you for example see a large difference if you comment out all flex code and ouput fixed or random data from the flex?What version of ESP are you exactly using, do you have the version string?Without knowing the flex code.One problem with memory was, I believe, forgetting to reset vectors.If you have a vector then you always have to explictly resize it back to zero, always, like at the end before you re-use it.vector(...) v_stack;..resize(v_stack, 0);With higher debug levels (7 or higher) you could see some memory usage details in the log file, but you might not see much of your flex. But you can't do this with high load because the log file will explode.For example run the project a while and then stop the input.With the esp_client connect to your project and add to the commandline the following to enable logging: \"logelevel 7\"Add some manual input that will be processed by your flex and afterwards stop the project.The esp_server.log file should now contain some information on queue sizes and memory data that you can analyze.Hopefully this will give some direction.Thanks,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project memory leaks : diagnosing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "107.2", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3630307", "text": "Hi Ben,First of all, thanks for the response. Second, I no longer suspect anything special regarding my use (or misuse) of Flex. The behavior I'm seeing (using top -b -p <pid> on a Unix command-line) is evident in a brand new, very simple project with no Flex at all. I have 4 input windows with a primary key defined for each, and an ALL retention policy. Each window is tied to a schema defined globally, and is bound to an input adapter of type \"db_in\".What I am witnessing is a steady growth of both VIRT and RES memory for the pid associated with my ESP project.My question is why? I gather that I am not grasping something fundamental about ESP. With windows, having a primary key......I assumed they would fill up, reach a steady state, and then keep my project memory footprint constant. I guess not. What am I not doing?We're running ESP 5.1 SP04 on RHEL 6 (studio : Version: 5.1.04.00/20131119.1/SP04 PL00/winnt/x86_64/64-bit/OPT/Tue, Nov 19, 2013 4:06:09 AM) (server : ESP 5.1.04.00).Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project memory leaks : diagnosing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "107.3", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3630307", "text": "Quickly following up on my last post. After explicitly setting the \"memory\" option in my project configuration file (.ccr) to \"2048\" (megabytes) and redeploying my project, and watching the same accumulation of memory.....the cluster stopped and restarted my project (breaking connections to ESP Studio where I am watching the contents of the windows) precisely when the VIRTUAL memory hit 2048.Have you seen this before?Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project memory leaks : diagnosing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "107.4", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3630307", "text": "Hi Michael,I noticed that you are using ESP 5.1 SP04. There was a memory leak bug that got fixed in ESP 5.1 SP04 PL03. Please try upgrading to at least that version of ESP, if not to the latest version which is ESP 5.1 SP08 PL01.Thank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project memory leaks : diagnosing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "107.5", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3630307", "text": "Alice,I upgraded last evening from SP04 to SP04 PL03. The leaks are history. For a patch installationit was a little bumpy (I had to restore service.xml and keystore_rsa.jks from my backup after the installation), with questions that should not be asked (like naming the cluster, setting passwords, etc)but those potholes were mentioned in the cover letter for EBF 23062.Turns out we are using the generic database adapter (ODBC) extensively to poll our sources and that seems to have gotten right to the heart of the leak we were witnessing.Thanks again,MichaelMessage was edited by: Michael Scharber (corrected target patch level).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project memory leaks : diagnosing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "107.6", "author": "Pauli Gandhi", "url": "http://scn.sap.com/thread/3630307", "text": "Michael,From your description I can't say how many windows you are sending to the Window. With your simple model where you have 4 input Windows with a KEEP ALL policy the only way that I can see the memory continuously growing is when you have only inserts flowing into the Windows. Can you try set a retention policy say KEEP 100 ROWS and see if memory still grows?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project memory leaks : diagnosing", "type": "answer", "tags": "N/A"},
{"date_time": "2014-10-06 09:40:00", "resolve": true, "uid": "108", "title": "Send data from ESP to remote Oracle 11g database", "url": "http://scn.sap.com/thread/3630834", "text": "Hi, Please help me with one sample ESP application that takes some data as input from a static file and then sending some calculated data to remote Oracle 11g database. Let say that we got two numbers from one excel sheet and perform addition/multiplication and send this data to remote Oracle DB.Thanks", "views": "532", "answers": 9, "author": "Adesh Sachan", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-10-06 23:28:00", "resolve": "", "uid": "108.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3630834", "text": "Hello,I don't know if you are on ESP 5.1 SP04 or SP08?I don't know if you are using JDBC or ODBC to connect to Oracle?Regardless, I think there is some setup information missing from the documentation. I have filed adocumentation bug here: 771896 - Documentation missing JDBC setup informationIf you are using JDBC, be sure to get the JAR file from Oracle. I copied the Oracle thin client \"ojdbc6.jar\" to $ESP_HOME/libj and defined my connection string like this: jdbc:oracle:thin:@//archer.acme.com:1521Then I created a database service entry named \"oracle_archer\".Then I created a project with the following CCL to perform a calculation and insert some data to Oracle:ATTACH INPUT ADAPTER File_Hadoop_CSV_Input1 TYPE toolkit_file_csv_input TO InputStream PROPERTIES csvExpectStreamNameOpcode = FALSE , dir = '/tmp' , file = 'some_data.csv' ;CREATE INPUT STREAM InputStream SCHEMA ( Column1 long , Dt BIGDATETIME, Column2 integer , Column3 float , Column4 bigdatetime , Column5 string );CREATE OUTPUT STREAM OutputStream SCHEMA ( Column1 long , Dt BIGDATETIME, Column2 integer , Column3 float , Column4 bigdatetime , Column5 string ) AS SELECT INST.Column1, INST.Dt, (INST.Column2 + 2) AS Column2, (INST.Column3 * 1.5) AS Column3, INST.Column4, INST.Column5 FROM InputStream INST;ATTACH OUTPUT ADAPTER Generic_DB_Output1 TYPE db_out TO OutputStream PROPERTIES service = 'oracle_archer' , table = 'HR.HISTORY_' ;I ran the project and checked the result in Oracle.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "108.2", "author": "Adesh Sachan", "url": "http://scn.sap.com/thread/3630834", "text": "Thanks Neal for quick and accurate reply.Here I am going to give you more info on my current set up1. I am using latest ESP 5.1 [SP08]2. I want to connect database using ODBC. [JDBC as well]3. I am on 64bit windows 7.4. I am not clear with the Driver library to be used. !!=> I have followed your steps to for JDBC connection like I got the ojdbc6.jar from oracle site and kept it at the  $ESP_HOME/libj directory.Then I have navigated to ESP home/Bin folder and added one more service entry say MyDbService along with the existing ones.Added Service in service.xml-> <Service Name=\"MyDbService\" Type=\"DB\">  <Parameter Name=\"User\">testuser</Parameter> <Parameter Name=\"Password\">testpass</Parameter> <Parameter Name=\"Database\">testDatabase</Parameter> <Parameter Name=\"ConnectString\">jdbc:oracle:thin:@//testserver.abc.com:1521</Parameter></Service>So before doing anything I thought like It would be better if I test this database connection from ESP IDE.I have started one project -> navigated to Data Service View tab-> I can see all the service names here defined in service.xml ->Selected MyDbService and right click to Descover.But I could not reach to this service as it says not enough parameters. !!", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "108.3", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3630834", "text": "Hi Adesh,SP08 does not use the services.xml in the bin location anymore, so there is no point to put the parameters into services.xml.You need to add the parameters in the Data Services tab.When authoring, if you are in the ESP Authoring tab in the server:port you should see your service and when you select it, you should see the properties in the Properties view and check it's values.You need to add them to the right server:port , you could have a local development cluster and a remote Linux cluster.Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "108.4", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3630834", "text": "Two more notes:services.xml can be migrated into the cluster with the esp_cluster_util; is that what you have tried to do?So what does the properties view show?If you connect with the studio on windows, for example for discovering a schema, then you are also creating a database connection on locally on Windows, which is a different database connection then the server running on Linux will have.BP", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "108.5", "author": "Adesh Sachan", "url": "http://scn.sap.com/thread/3630834", "text": "Thanks Ben,As you said that service.xml is not used in ESP SP08 onwards and service.xml can be migrated using esp_cluster_util.But I have not tried that.So the Oracle database that I am trying to connect from ESP studio is running on remote Linux Machine.I have explored Data Service Tab in ESP Authoring view but I do not see any parameter kind window, All it asks is to right click on any of data service and select Discover.And these data services are same services that are defined in service.xml.For the demo purpose I have added one more service tag in service.xml that is using one dsn to connect HANA database. Now from ESP studio after right click->Discover , I am able to connect this Hana database.Same thing I want to achieve with Oracle with or without DSN !!Thanks With RegardsAdesh", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "108.6", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3630834", "text": "Hi,You need to check the properties view, probably already open at the right edge of the studio, after clicking on a dataservice.It should show the parameters that has been used to connect or you need to edit this view to put the right parameters.Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "108.7", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3630834", "text": "Hello,You may need to go under the \"Window\" menu -> \"Show View\" -> Properties. Sometimes the Properties view is small and hidden by other tabs. When you click on an existing \"service\" or add a new one and then click on \"newservice\" you can edit the properties.You also mention using ODBC. On Linux, there is a bit of setup. You need to make sure that you have the latest version of the unixODBC driver manager installed: http://help.sap.com/saphelp_esp51sp08cfa/helpdata/en/e7/8d0f156f0f1014a048880d763bd299/content.htm?frameset=/en/ed/56b0f46013439481854ec45c8bc1aa/frameset.htm&current_toc=/en/e7/74a95d6f0f1014947f8d8c1d099113/plain.htm&node_id=64&show_children=falseSome Linux boxes come with old versions of unixODBC that can cause ESP to crash so search for and uninstall old versions of unixODBC with Linux command such as \"whereis libodbc.so.1\" and rpm:rpm -qa | grep -i unixodbcunixODBC-2.2.11-7.1", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "108.8", "author": "Adesh Sachan", "url": "http://scn.sap.com/thread/3630834", "text": "Thanks Neal for extremely clear response.I have started the data view and Properties view as well but I do not see any thing like your screen.Is it because of Evaluation version of ESP SP08 ??I have not licensed version of ESP, could It be the reason like I am not able to see these options ??ThanksWith RegardsAdesh", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "108.9", "author": "Adesh Sachan", "url": "http://scn.sap.com/thread/3630834", "text": "Hi Neal,Can we have small discussion session of 10-15 minutes.I think we can resolve the problem asap.My main problem statement is oracle database connection with my product[LMS] which is using ESP SP08 at Linux platform.Thanks", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Send data from ESP to remote Oracle 11g database", "type": "answer", "tags": "N/A"},
{"date_time": "2014-10-07 18:13:00", "resolve": false, "uid": "109", "title": "file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "url": "http://scn.sap.com/thread/3631810", "text": "Folks,Has anyone experienced the breakage of both file_csv_input and file_csv_output adapters following an upgrade to a higher patchlevel? This strikes me as a fairly simple interface, yet my project components using the adapters no longer function following the patch.Looking for a place to start.Thanks,Michael", "views": "601", "answers": 13, "author": "Michael Scharber", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-10-07 18:45:00", "resolve": "", "uid": "109.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3631810", "text": "Hello,I'm not clear on which adapters you are using. Are you using the \"toolkit_file_csv_input\" adapters? File/Hadoop CSV Input and Output AdapterIf so, I would look for two log files in your project's working/run-time directory:\"esp_server.log\" will show us any errors specific to the project\"frameworkadapter.log\" will show us adapter specific errorsFile and Directory InfrastructureThanks,Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.2", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3631810", "text": "Hi Neal,Apologies. I am indeed using the toolkit_file_csv_input and toolkit_file_csv_output adapters.The relevant fragment from esp_server.log is the following :2014-10-07 02:20:59.275 | 28649 | container | [SP-3-148005] (1.093) sp(28521) ConnectionReader(IndexBetaIN) error reading from Connection(IndexBetaIN_CSV): 2014-10-07 02:20:59 The execution command \"/local/sw/esp5.1/ESP-5_1/adapters/framework/bin/start.sh\" \"/local/sw/esp5.1/ESP-5_1/adapters/framework/instances/file_csv_input/adapter_config.xml\" \"-DFileInputTransporterParameters.Dir=/local/working/data/iv\" \"-DFileInputTransporterParameters.File=IndexBeta.csv\" \"-DFileInputTransporterParameters.DynamicMode=\" \"-DFileInputTransporterParameters.PollingPeriod=600\" \"-DFileInputTransporterParameters.RemoveAfterProcess=false\" \"-DFileInputTransporterParameters.ScanDepth=\" \"-DCsvStringToEspFormatterParameters.Delimiter=,\" \"-DCsvStringToEspFormatterParameters.DateFormat=YYYYMMDD\" \"-DCsvStringToEspFormatterParameters.TimestampFormat=\" \"-DCsvStringToEspFormatterParameters.HasHeader=true\" \"-DCsvStringToEspFormatterParameters.ExpectStreamNameOpcode=false\" returned code: 127. 0 records consumed, 0 read, 0 bad, 0 good.2014-10-07 02:20:59.275 | 28649 | container | [SP-4-148003] (1.093) sp(28521) ConnectionReader(IndexBetaIN) exiting.frameworkadapter.log is not being written to....for my project, but used to be (prior to the patch).Does this shed any light?Greatly appreciated (as usual).Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3631810", "text": "Hello,It looks like it is trying to start the adapter with the \"/local/sw/esp5.1/ESP-5_1/adapters/framework/bin/start.sh\" script but it fails with error code 127. If it is unable to start, nothing will be written to the \"frameworkadapter.log\".If you \"ls -l $ESP_HOME/adapters/framework/bin/start.sh\", does the user who started the ESP cluster manager have permission to read & execute this file?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.4", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3631810", "text": "Hi Neal,The user does have rights to read/execute that script. I ran the command in it's entirety from the command-line and it does cough up more information :10-07-2014 19:04:56.955 INFO [main] (Framework.main) start /local/sw/esp5.1/ESP-5_1/adapters/framework/instances/file_csv_input/adapter_config.xml10-07-2014 19:04:57.471 INFO [main] (XmlUtils$1.resolveResource) /local/sw/esp5.1/ESP-5_1/adapters/framework/config/parametersdefine.xsd10-07-2014 19:04:57.536 INFO [main] (XmlUtils$1.resolveResource) /local/sw/esp5.1/ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd10-07-2014 19:04:57.944 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...10-07-2014 19:04:57.945 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.10-07-2014 19:04:58.188 INFO [main] (AdapterController.init) Address 45.32.82.94:19082 is used to accept the control command.10-07-2014 19:04:58.225 INFO [main] (AdapterController.sendCommand) start /local/sw/esp5.1/ESP-5_1/adapters/framework/instances/file_csv_input/adapter_config.xml10-07-2014 19:04:58.405 INFO [Thread-0] (Server.doStart) jetty-7.6.1.v2012021510-07-2014 19:04:58.441 INFO [Thread-0] (ContextHandler.startContext) started o.e.j.s.ServletContextHandler{/,null}10-07-2014 19:04:58.489 INFO [Thread-0] (AbstractConnector.doStart) Started SelectChannelConnector@45.32.82.94:1908210-07-2014 19:04:59.404 INFO [main] (AdapterController.executeStart) Adapter controller is started.10-07-2014 19:04:59.404 INFO [main] (AdapterController.executeStart) Starting adapter10-07-2014 19:04:59.435 INFO [main] (ModuleWrapper.initQue) Buffer Size for module MyInStream_Publisher is 10240.10-07-2014 19:04:59.436 INFO [main] (ModuleWrapper.initParallelParameters) Parallel setting of module MyInStream_Publisher is true.10-07-2014 19:04:59.436 INFO [main] (EspPublisher.init) EspPublisher is initializing10-07-2014 19:04:59.438 ERROR [main] (EspConnectorWrapper.init) Error code:400842, Severity : 3 (Error)Error message:The stream name is not configured.Error description:The stream name is not configured.10-07-2014 19:04:59.441 INFO [main] (ContextHandler.doStop) stopped o.e.j.s.ServletContextHandler{/,null}", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.5", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3631810", "text": "Hello,OK, those errors would be expected because if you try to run the adapter in unmanaged mode (manually outside of a project), you have to edit the \"/local/sw/esp5.1/ESP-5_1/adapters/framework/instances/file_csv_input/adapter_config.xml\" file and uncomment two lines: <!--Uncomment the following 2 elements when you use 'start_adapter[.bat|.sh]' --> <!--ProjectName>EspProject1</ProjectName--> <!--StreamName>BaseInput</StreamName-->And also fill in the server/project URI, username and password: <Uri>esp://localhost:19011/sample_workspace/file_csv_input</Uri> <Security> <User></User> <Password encrypted=\"false\"></Password>Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.6", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3631810", "text": "p.s.You would leave \"ProjectName=EspProject1\" and change \"Streamname=\" to the stream/window you want it to publish to.You could go ahead and try this and see if it gets further and raises any additional errors. If no errors, make sure to change everything back to the way it was.Some other things to try/check:1) Make sure there are no stray adapter processes. \"ps -ef | grep java\" and see if there are any running out of the ESP directory path.2) You could get an strace while trying to start the adapter... a) You could do a \"ps -ef | grep esp_server\" and look for the PID of the esp_server process belonging to your project. It would have some command line arguments similar to \"--cluster-container --cluster-container-id Id_107_1412629980721\". b) strace -f -o esp_strace.out -p <esp_server_PID> c) In ESP Studio you can expand the plus sign next to the window/stream the adapter is attached to and then right click the adapter and try starting it. d) Send us the \"esp_strace.out\".", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.7", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3631810", "text": "Neal,From the command-line, following your advice on changing (for testing purposes only) adapter_config.xml, the contents of my CSV file were successfully published into the receiving window of my running ESP project!Now what? Wondering if it isn't just a simple configuration pertaining to the adapter that got muffed.What else do you need from me? Very eager to get this resolved and feels like we are very close.Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.8", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3631810", "text": "Hello,There weren't any stray/hung esp_server or java processes running at the time of upgrade? Or when you run the project? I have seen upgrades fail when there were running processes on Windows because the installer couldn't overwrite everything it needed to. I haven't seen the same thing happen on Linux but I thought I should raise the question.Can you try the \"strace\" instructions? In the strace, I would look for where it tries to execute \"start.sh\" and follow on from there looking for errors.If you don't feel comfortable posting that here, could you open a technical support case and attach the diagnostics to it?Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.9", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3631810", "text": "Hi Neal,I have confirmed from my notes, and my command history that (as I normally do on any ESP full recycle procedure) I confirmed no orphaned or running processes associated with \"esp\".Also recall that toolkit_file_csv_output is also no longer functional.I'll continue to troubleshoot a bit and then look for alternatives to my CSV in/out problem.Thanks,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.10", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3631810", "text": "Hi Michael,Yes, I understand that the adapter is no longer functional. The \"strace\" diagnostics I suggested getting could really shed a lot of light on the problem.As long as the project itself can run, you can start \"strace\" on the esp_server PID belonging to the product.Once the strace is running, you can go into Studio and right click on the adapter (see the red arrow in the picture) and tell it to start:The strace then would capture the start-up process and what went wrong.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.11", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3631810", "text": "Hi Neal,I had these CSV adapters in a big, complicated (to me) project....so it dawned on me to make a brand new project (from Studio) and put just one of these into it (the input version) and see what happens. I did this from Studio, deployed from Studio, started from Studio and it worked fine, to my amazement.Then, I took the \"stock\" .ccr file generated by Studio (and which got deployed to the server) and replaced the .ccr file I had been using for months with my other project, with that one. It broughtthe two instances of my CSV adapters back to life. So now I am trying to isolate exactly which configuration parameter in my real project is suddenly causing all of this strife for the CSV adapters.I should have this information shortly.Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.12", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3631810", "text": "Neal,This project configuration option is causing my  toolkit_file_csv_input and toolkit_file_csv_output adapters to hang/fail : <Option name=\"memory\" value=\"4096\"/>This is from the <Configuration><Deployment><Project><Options> hierarchy. I had set it last weekafter battling the memory leak caused by the generic db input adapters....to protect my host from being eaten alive memory-wise. Now that the leak(s) are gone (one hopes) I suppose I could comment this option outbut it seems backwards to have to do so. At least, maybe you can use this information to test on your endwith a simple project having one instance of a toolkit_file_csv_input adapter.....and set this option in yourproject deployment...and see what happens.Let me know what you think.Cheers,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "109.13", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3631810", "text": "Hello,How much memory does the adapter use when you run it on your server? I set the memory value to 4096 in my CCR and ran the project but the adapter still started.Setting the memory option is essentially setting the ulimit/limit for memory use to prevent an application from using more than that limit. If it tries to malloc() more than what it is allowed (or what is available), malloc() will fail with ENOMEM.Is your CSV file large? Are there a large number of columns in the file (and associated window/stream)?For my simple test I don't see the \"java\" adapter process using very much memory: PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND  4623 nstack 20 0 1674m 87m 13m S 2 0.4 0:04.98 java  4549 nstack 20 0 841m 50m 23m S 0 0.2 0:00.38 esp_serverIf I set the memory setting below 1674 MB, the adapter fails to start: <Option name=\"memory\" value=\"1500\"/>I would consider this expected behavior. If the adapter can't get enough memory to do it's job, it will fail. If esp_server calls malloc() and gets ENOMEM, it will fail (most likely crash).The \"memory\" setting is not like setting a pool and telling ESP to use only what is in the pool. It is like setting a roof and when ESP hits the roof, bad things happen.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:file_csv_input : adapter breaking following 5.1 SP04 PL03 upgrade", "type": "answer", "tags": "N/A"},
{"date_time": "2014-09-26 23:22:00", "resolve": true, "uid": "110", "title": "how can toolkit_file_csv_input use a directory relative to the project", "url": "http://scn.sap.com/thread/3627373", "text": "The deprecated csv_in adapter could use a dir setting like ../../exampledata or ../data, so that you wouldn't need to have the entire path. This would make the project easily portable.I can't seem to do this with toolkit_file_csv_input, and all the studio examples are still using the deprecated adapters. I am not interested in the non-managed invocation.I don't get any error.2014-09-26 15:43:22.856 | 13616 | container | [SP-3-150004] (0.527) sp(10836) Connection(standingdata_in/standingdata):: http://localhost:97862014-09-26 15:43:22.856 | 13616 | container | [SP-3-150004] (0.527) sp(10836) Connection(standingdata_in/standingdata):: esp://localhost:9786/default/algostrategies32014-09-26 15:43:22.856 | 13616 | container | [SP-3-150004] (0.527) sp(10836) Connection(standingdata_in/standingdata):: standingdata2014-09-26 15:43:22.859 | 17580 | container | [SP-3-150004] (0.530) sp(10836) Connection(baskets_in/baskets):: http://localhost:97862014-09-26 15:43:22.859 | 17580 | container | [SP-3-150004] (0.530) sp(10836) Connection(baskets_in/baskets):: esp://localhost:9786/default/algostrategies32014-09-26 15:43:22.859 | 17580 | container | [SP-3-150004] (0.530) sp(10836) Connection(baskets_in/baskets):: basketsHow do I use a relative directory with the toolkit_file_csv_input adapter (managed).Or I should use the deprecated adapters?", "views": "2298", "answers": 3, "author": "David Rosenblum", "upvotes": 0, "type": "question", "tags": "esp_5.1"},
{"date_time": "2014-10-01 22:49:00", "resolve": "solution", "uid": "110.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3627373", "text": "Hi David, To make an adapters properties for the project be configurable/portable, use the project's CCRfile to set any or all properties for the particular adapter you are configuring. So, for example, I used ESP Studio to take the (unmanaged) example provided for the toolkit_file_csv_input adapter and changed the project so that it uses a managed csv input adapter.Here's how I did it: Set up a new project that will be called file_csv_input_managed: copy C:/sybase/ESP-5_1/adapters/framework/instances/file_csv_inputto C:/sybase/ESP-5_1/adapters/framework/instances/file_csv_input_managedOpen the new project in Studio:File->Open->ESP ProjectFor Select root directory,browse to C:/sybase/ESP-5_1/adapters/framework/instances/file_csv_input_managed,click OK, and if you want to, check the checkbox Copy project into workspace,click Finish.In the Project Explorer, expand the file_csv_input_managed project folder.In the folder, right-click on model.ccl, choose Rename, change the name to file_csv_input_managed.ccl, click OK.In the folder, right-click on file_csv_input_managed.ccl, choose Open.Click to change focus to the file_csv_input_managed.ccl that is now open in the Authoring Perspective.Click on the Switch to Visual icon (or use F6)Add a File Hadoop CSV Input adapter to the visual diagram of the projectEdit the adapters properties: in the Basic tab:set the Stream name, opcode expected to FALSEset the Directory to C:/sybase/ESP-5_1/adapters/framework/instances/file_csv_input_managed/dataset the File to input.csvclick OKConnect the adapter to the BaseInput window.Save the project.Create a new CCR Project Configuration:File->New->CCR Project Configuration, set File name to file_csv_input_managed, click FinishYou should now be in the Authoring Perspective with the CCR file open for editing:Click on the Adapter Properties tabClick on Add from CCL  this will set up the property set for the File/Hadoop CSV Input based on the adapter properties in the CCL file.Save the CCR fileGo back into the visual diagram of the projectedit the adapters propertiesselect Usenamedpropertysetchoose File/Hadoop CSV Input from the dropdown so that the project will use the property set we just finished setting up in the CCR filedelete/eliminate all the values that are in the Basic tab - the adapter will not need these to be in the CCL file since it is using the settings that are in the CCR fileclick OKSave the diagramYou should now be able to successfully run the project from Studio and open a streamview to see that the csv data is input into the BaseInput window.View the frameworkadapter.log for any adapter errors  since you are running the project in the Studio's (local) cluster, the log file is located in <your ESP studio workspace directory>\\projects\\default.file_csv_input_managed.0\\logs Give it a try  Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:how can toolkit_file_csv_input use a directory relative to the project", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "110.2", "author": "David Rosenblum", "url": "http://scn.sap.com/thread/3627373", "text": "Thanks Alice,Is there a way I can mark this as correct answer?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:how can toolkit_file_csv_input use a directory relative to the project", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "110.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3627373", "text": "Hi David,Yes, I believe that there is a way, though I am not able to see these myself (I assume because it is available only to non-SAP employees).I went to the Getting Started link that I found in the upper right hand corner of the page:On the Getting Started page, I foundOn the How to Give Feedback on SCN Content page, it says:Message RepliesYou can reply to discussion threads and comment on blog posts and documents. Simply click Reply or Comment.Message replies on discussion threads can be marked as \"helpful\" or correct.\" This is important in helping others identify the right answers and closing open threads.Comments and messages can be \"liked\" if members find them useful.Hope that helps,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:how can toolkit_file_csv_input use a directory relative to the project", "type": "answer", "tags": "N/A"},
{"date_time": "2014-10-21 17:06:00", "resolve": true, "uid": "111", "title": "(RFC-Output-)Adapter works only unmanaged", "url": "http://scn.sap.com/thread/3639155", "text": "Hello,my esp-project writes data to an sap-table with an RFC-Adapter.The Problem is: The adapter works only if I run $ESP_HOME\\adapters\\framework\\bin\\start.bat ..adapter_config.xml.But I prefer the managed mode. So I add a RFC-Output-Adapter to the CCL: ATTACH OUTPUT ADAPTER sap_adapter TYPE rfcoutplugin TO to_sap PROPERTIES config = 'C:/Sybase/ESP-5_1/adapters/rfc/esp_to_sap/adapter_config.xml' , mapFilePath = 'C:/Sybase/ESP-5_1/adapters/rfc/esp_to_sap/mapping.xml' , host = 'ec1' , systemNumber = '00' , client = '100' , user = 'SAPuser' , password = 'pw' ;A few seconds after I start the project the adapter is switching to status 'DEAD'. With no work done.Here is the cluster_conifg.xml:<?xml version=\"1.0\" encoding=\"utf-8\"?><Adapter> <Name>RFC Output Adapter</Name> <Description>This output adapter retrieves data from an ESP stream and sends it to an SAP system through RFC</Description> <Log4jProperty>./log4j.properties</Log4jProperty> <Modules> <Module type=\"espconnector\"> <InstanceName>sap_adapter</InstanceName> <Name>EspSubscriber</Name> <Next>RFCOutputTransporter</Next> <Parameters> <EspSubscriberParameters> <ProjectName>esp_to_sap</ProjectName> <StreamName>to_sap</StreamName><!-- <GDMode>false</GDMode> <GDKeyColumnName>gdKey</GDKeyColumnName> <GDOpodeColumnName>gdOpcode</GDOpodeColumnName> <GDBatchSize>5</GDBatchSize> <GDPurgeInterval>300</GDPurgeInterval> <GDControlStream>W1_truncate</GDControlStream>--> </EspSubscriberParameters> </Parameters> </Module>  <Module type=\"transporter\"> <InstanceName>RFCOutputTransporter</InstanceName> <Name>RFCOutputTransporter</Name> <Parameters> <RFCOutputTransporterParameters> <Host>ec1</Host> <SystemNumber>00</SystemNumber> <Client>100</Client> <SAPUser>SAPuser</SAPUser> <SAPPassword encrypted=\"false\">pw</SAPPassword> <Keystore>keystore.jks</Keystore> <KeystorePassword>password</KeystorePassword> <BatchSize>0</BatchSize> <RFC> <Function>Z_MAHA_ESP_IMPORT_RFC</Function> <Mapping>mapping.xml</Mapping> </RFC> </RFCOutputTransporterParameters> </Parameters> </Module> </Modules>  <EspProjects> <EspProject> <Name>esp_to_sap</Name> <Uri>esp://localhost:19011/default/esp_to_sap</Uri> <!--can specify multiple uris --> <Security> <User>ESPuser</User> <Password encrypted=\"false\">pw</Password> <AuthType>user_password</AuthType> <!--  <RSAKeyStore>/keystore/keystore.jks</RSAKeyStore> <RSAKeyStorePassword>Sybase123</RSAKeyStorePassword> --> <!-- <KerberosKDC>KDC</KerberosKDC> <KerberosRealm>REALM</KerberosRealm> <KerberosService>service/instance</KerberosService> <KerberosTicketCache>/tmp/krb5cc_user</KerberosTicketCache> --> <EncryptionAlgorithm>RSA</EncryptionAlgorithm> </Security> </EspProject> </EspProjects> <GlobalParameters/></Adapter>and mapping.xml:<?xml version=\"1.0\" encoding=\"UTF-8\"?><mappings> <rfc name=\"Z_MAHA_ESP_IMPORT_RFC\"> <mapping> <import> <fieldMapping name=\"IF_WERT\" espField=\"if_wert\"/> </import> </mapping> </rfc></mappings>Someone with a cloue, why the adapter refuses to work in managed mode?With kind regards,Matthias", "views": "370", "answers": 2, "author": "Matthias Hanel", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-10-22 20:42:00", "resolve": "", "uid": "111.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3639155", "text": "Hi Matthias,Some thoughts:Are there any clues in the adapter's log file?Are you able to start any other adapters?Are you running the project in the Studio's cluster or are you running the project from a non-Studio cluster?What version of ESP are you using?Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:(RFC-Output-)Adapter works only unmanaged", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "111.2", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3639155", "text": "Hi Matthias,In your adapter_config.xml file, I noticed that the Mapping element's value is just the filename.Please modify it to use the full filepath.Meaning, if your mapping.xml file is located here:C:/Sybase/ESP-5_1/adapters/rfc/esp_to_sap/mapping.xmlThen, change \"<Mapping>mapping.xml</Mapping>\" in your adapter_config.xml file from:<RFC>  <Function>Z_MAHA_ESP_IMPORT_RFC</Function> <Mapping>mapping.xml</Mapping></RFC>to<RFC>  <Function>Z_MAHA_ESP_IMPORT_RFC</Function> <Mapping>C:/Sybase/ESP-5_1/adapters/rfc/esp_to_sap/mapping.xml</Mapping></RFC>Please let me know if that helps or not.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:(RFC-Output-)Adapter works only unmanaged", "type": "answer", "tags": "N/A"},
{"date_time": "2014-10-23 02:04:00", "resolve": false, "uid": "112", "title": "Consuming HTTP Adapter output via Javascript/ JQuery", "url": "http://scn.sap.com/thread/3639913", "text": "Hello,I see example in HTTP Adapter that allows me to connect (via HTML and Form POST) to HTTP output adapter, and I can see streams coming out of the browser: <form name=\"input\" action=\"http://<esp_server>:<esp_port>/start\" method=\"post\"> SQL query: <input type=\"text\" name=\"sql\" size=\"60\" value=\"select * from Stream1\"> <input type=\"submit\" value=\"Submit\"> </form>Do you have working example on how to do this as jQuery / ajax?I'm having issues consuming it, plain vanilla $.post would have CORS issue (ESP server is different from my client), I tried xhr but to not much success either.A working example would really help as I need to consume this in real-time via browser, and update a field on <div></div> section.Thank you,Chin", "views": "596", "answers": 1, "author": "Chin K Ling", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-10-23 03:19:00", "resolve": "", "uid": "112.1", "author": "Chin K Ling", "url": "http://scn.sap.com/thread/3639913", "text": "To clarify , when I try to convert to using $.post, I'm getting:XMLHttpRequest cannot load http://<esp_server>:<esp_http_port>/start. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'null' is therefore not allowed access. Usually if I have control over coding of HTTP server, I can fix this via header, but in this case, its inside the JAR.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Consuming HTTP Adapter output via Javascript/ JQuery", "type": "answer", "tags": "N/A"},
{"date_time": "2014-10-27 07:23:00", "resolve": false, "uid": "113", "title": "ESP Java Client Failover Handling", "url": "http://scn.sap.com/thread/3641137", "text": "Dear all,I want to ask if I am using JAVA SDK to connect to a ESP cluster, Should I specify all the manager host during the URI creation? If so , how is the format looks like? currently I am using something like \"Uri uri = new Uri.Builder(\"esp://localhost:19011/gujing_cluster_workspace/test_sdk\").create();\" to connect to my project. if I have another manager \"19012\", how to specify it?Or I just need to give any of the manager and it can do auto failover for me?Thanks", "views": "168", "answers": 0, "author": "Richard Gu", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-11-05 13:26:00", "resolve": false, "uid": "114", "title": "How to set http header in HTTP Client Output Adapter?", "url": "http://scn.sap.com/thread/3646038", "text": "We want to set the header field Content-Type=application/json. How can this be done for the HTTP Client Output Adapter?Or is there another way to send OData request ?ThanksFrank", "views": "954", "answers": 1, "author": "Frank Albrecht", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-11-17 08:50:00", "resolve": "", "uid": "114.1", "author": "Jian-dong Pei", "url": "http://scn.sap.com/thread/3646038", "text": "Hi Frank,There is no interface set to Content-Type=application/json in the HTTP Client Output Adapter. (Cannot change the Content-Type, currently is set to \"Content-Type=text/plain\") Maybe we will support it in the future.ThanksJiandong Pei", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to set http header in HTTP Client Output Adapter?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-10-23 20:03:00", "resolve": false, "uid": "115", "title": "How does one make wise use dictionaries in ESP?", "url": "http://scn.sap.com/thread/3640343", "text": "Folks,I have a project with several Flex windows, wherein I have a significant dependency on use of dictionaries.In most cases I am modifying the contents of the dictionaries on a frequent basis to maintain a notionof \"most recent\" information. This information is then used to enrich, map or derive other content on theway through the Flex window.My project grows in memory fast.....out of control actually. I suspect [now] that I am being wrecklesswith my dictionary use. What rules of thumb should I follow? Do I need to do some kind of periodic\"cleanup\" of my dictionaries (copy, delete, recreate)?Looking for advice on best practices here from people who have been there and faced this.Thanks,Michael", "views": "1972", "answers": 4, "author": "Michael Scharber", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-10-23 23:57:00", "resolve": "", "uid": "115.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3640343", "text": "Hi Michael,Have you looked at using the Event Cache data structure? From your description, you might find that to be a better choice.Here are some links to information about Event Caches:Event Caches - Programmers Reference - SAP Libraryhttp://scn.sap.com/docs/DOC-32212#jive_content_id_What_is_an_EventCachehttp://scn.sap.com/community/developer-center/esp/blog/2013/06/26/creating-a-custom-aggregation-using-event-cacheEvent Cache - Examples Guide - SAP Libraryhttp://scn.sap.com/community/developer-center/esp/blog/2013/09/12/sorting-data-in-esp-windowsThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How does one make wise use dictionaries in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "115.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3640343", "text": "I agree with Alice - you may want to have a look at Event Cache. You can also reference the output window that a Flex is creating from within the Flex - to look at previous values, for example.As for using dictionaries, yes you do need to do clean up - and remember that the memory isn't released until the flex 'exits'. So if you create and delete lots of dictionaries in the flex, the delete won't take effect until the flex completely finishes processing the event.Also: don't just keep adding things to the dictionary without ever deleting - or you will have an infinitely growing dictionary.If you thing you are following all those rules and still having problems, give us more details or share a sample of the CCL. Or conversely, describe what you need to do and someone may be able to show you an example of a \"safe\" (and efficient) way to do it.", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:How does one make wise use dictionaries in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "115.3", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3640343", "text": "Thanks Jeff. I have stayed with dictionaries for now (just too far down the road to rework using Event Cache strategy) and I am being a better citizen about adhering to use of \"remove\" functionon dictionary members prior to replacing them. I've also moved as much as I can away from windows and toward use of streams.Lastly, I've upgraded to ESP 5.1 SP04 PL03 on the server side of things (but not my Studio on Windows) and am getting messages about copyRecord being deprecated. What's the replacement for this function going forward?Thanks,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How does one make wise use dictionaries in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "115.4", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3640343", "text": "Hi Michael,Please start a new post for your copyRecord question, as it is a totally different topic. That way if anyone else has the same question, they will be able to search for it easily.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How does one make wise use dictionaries in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-11-21 15:48:00", "resolve": true, "uid": "116", "title": "Has copyRecord been deprecated?", "url": "http://scn.sap.com/thread/3656024", "text": "I've upgraded to ESP 5.1 SP04 PL03 on the server side of things (but not my Studio on Windows) and am getting messages about copyRecord having been deprecated. I understand these are likely warnings, as my project still compiles, runs and does what I want it to do. However, I've struggled to find a replacement for this function going forward?What should I use, going forward, to make a copy of a SPLASH record (not a copy of the variable) if copyRecord is deprecated?Thanks,Michael", "views": "154", "answers": 2, "author": "Michael Scharber", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-11-21 17:02:00", "resolve": "solution", "uid": "116.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3656024", "text": "Hi Michael,This error message is, as you suspected, just a warning.The replacement for this is to use the assignment operator. You can assign a record to another record, for example:rec2 := rec1;Making a copy of the variable is the same as making a copy of the record.I've created 2 change requests, one to modify the error message and the other to clarify the documentation.CR 774878 - copyRecord function is deprecated - make changes to error message 161298CR 774880 - copyRecord function is deprecated - make changes to documentationThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Has copyRecord been deprecated?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "116.2", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3656024", "text": "That makes sense....fixing the documentation, that is.Thanks for the help. Greatly appreciated.Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Has copyRecord been deprecated?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-03-10 16:30:00", "resolve": false, "uid": "117", "title": "File/Hadoop CSV input : Discovery of file fails", "url": "http://scn.sap.com/thread/3517029", "text": "Hello ,I'm trying to make the project as described in -\"Hands-on Tutorial: Building a Simple SAP Sybase ESP Project\" for SAP Sybase ESP version 5.1 SP04.I create a project where I add an input adapter of type - File/Hadoop CSV input.Then in edit properties I enter the directory and the file name . In advanced tab I also set Has Header = TRUE.Then I click on Schema Discovery and this raises error - \"Failed to parse discovery file : parse of file failed \".I've imported the sample \"towermon \"project from SCN and this shows the same error !I've done this before on SP02 and it used to work . Of course the File/Hadoop CSV input adapter did not exist in that release.Can't quiet figure out what I'm doing wrong . Is this a bug in the software ?Any ideas how to fix this ?Best regards,Saty", "views": "3171", "answers": 7, "author": "Satyadeep Dey", "upvotes": 0, "type": "question", "tags": "esp_5.1.esp_tutorial.esp_studio.esp_usage"},
{"date_time": "2014-03-13 18:42:00", "resolve": "", "uid": "117.1", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3517029", "text": "Hello,Two things to check:1) I don't know which file you are using from the \"towermon\" project. One of the CSV files (input-streams.csv) prepends the stream name and opcode:isSensorStream,i,2011-06-30T17:00:00.000,32.835,-114.188,Tower,Yuma T70,1,104,0The other CSV files do not. So you will have to toggle the \"csvExpectStreamNameOpcode\" parameter to true/false (the default is true).2) There is a bug in the adapter discovery mechanism where it will return the error Failed to parse discovery file : parse of file failed \": 749503 - Schema discovery does not work for toolkit adapters when unnecessary properties are listed on the adapter.So for example, in text authoring mode, if you have this:ATTACH INPUT ADAPTER File_Hadoop_CSV_Input1 TYPE toolkit_file_csv_input PROPERTIES csvExpectStreamNameOpcode = TRUE , dir = 'c:/temp' , file = 'input-streams.csv' , dynamicMode = '' , removeAfterProcess = FALSE , csvDelimiter = '' , csvDateFormat = '' , csvTimestampFormat = '' , csvHasHeader = FALSE , pollingPeriod = 0 , scanDepth = 0 ;You have to delete the unnecessary properties:ATTACH INPUT ADAPTER File_Hadoop_CSV_Input1 TYPE toolkit_file_csv_input PROPERTIES csvExpectStreamNameOpcode = TRUE , dir = 'c:/temp' , file = 'input-streams.csv' ;Then switch back to visual authoring mode and try discovery again.Hope this helps.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File/Hadoop CSV input : Discovery of file fails", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "117.2", "author": "Satyadeep Dey", "url": "http://scn.sap.com/thread/3517029", "text": "Hello Neal,Tried this . Doesn't work .Regards,Satya", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File/Hadoop CSV input : Discovery of file fails", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "117.3", "author": "Neal Stack", "url": "http://scn.sap.com/thread/3517029", "text": "Hello Satya,Perhaps you could give us more information so we could help you? Like maybe tell us which file you were trying to discover from the \"towermon\" example? Or provide us with sample data?If you would like to share you screen with me, I can also see what is going on that way.Thanks, Neal", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File/Hadoop CSV input : Discovery of file fails", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "117.4", "author": "Satyadeep Dey", "url": "http://scn.sap.com/thread/3517029", "text": "Hello Neal ,Just downloaded the towermon example again from SCN . I was getting this problem with Adapter1 . This works now with the latest files (weather-sensor-inventory.csv).Thanks,Satya", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File/Hadoop CSV input : Discovery of file fails", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "117.5", "author": "Bhumi Patel", "url": "http://scn.sap.com/thread/3517029", "text": "Hello,I had the same problem you have mentioned here.If you have any space in your directory path for example, '/ESP Hands-on Tutorial_Sample Code/towermon3/data', it won't work and will give you error \"Failed to parse discovery file: parse of file failed...\"You have to give some path like '/ESP_Hands-on_Tutorial_Sample_Code/towermon3/data' (basically you need to handle space characters in your directory path)Thanks,Bhumi Patel.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File/Hadoop CSV input : Discovery of file fails", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "117.6", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3517029", "text": "I checked with the development team, and confirmed that the file toolkit adapter can support spaces in the path and/or filename. The user can simply specify the names with spaces, but remember NOT to surround with quotes. That's the trick", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File/Hadoop CSV input : Discovery of file fails", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "117.7", "author": "Ameya Suvarna", "url": "http://scn.sap.com/thread/3517029", "text": "Hello,I too got the same error. It worked for me, by placing the files in a folder with no space and no capital letters. e.g.: \"c:\\xyz\\data\\\"Thanks,Ameya", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:File/Hadoop CSV input : Discovery of file fails", "type": "answer", "tags": "N/A"},
{"date_time": "2014-12-01 17:03:00", "resolve": true, "uid": "118", "title": "How to transport a long String(Base64) from ESP to HANA?", "url": "http://scn.sap.com/thread/3661900", "text": "Hi everyone,I work at a project where we need to handle pictures in base64-code. The code of every picture has 70,000+ chars.In ESP we are using \"String\"-datatype for the pictures, which makes no problem.Now we need the Stirngs in our HANA-databse.We tried to use the standard HANA-Output-Adapter. But the HANA-varchar-datatype has a maximum of 5,000 chars. So we can not use varchar.If whe use CLOB in HANA i can manualy inserte the whole String into the table.But the standard HANA-Output-Adapter dose not work with CLOB. It says: \"Unsupported Datatype\".Is there a \"workaround\" out there or do we have to write a specific adapter to solve the problem?With kind regards,Matthias", "views": "313", "answers": 1, "author": "Matthias Hanel", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-12-02 20:52:00", "resolve": "solution", "uid": "118.1", "author": "Andrzej Kucharczyk", "url": "http://scn.sap.com/thread/3661900", "text": "Hi Matthias,Unfortunately HANA output adapter does not work with clob and blob data types. For performance reasons HANA output adapter pre-allocates memory required for all rows it buffers that are waiting to be transferred. This could be dozens of millions of rows depending on your adapter properties such as bulkInsertArraySize and threadCount. On start up the adapter asks HANA for maximum size of every column in your target table. This works fine for types such as varchar or integer with well defined maximum size but it does not work for clobs or blobs where maximum size could be 2GB.For future releases of ESP we are considering adding support of clobs, and blobs to HANA output adapter but this would not perform as fast as it currently does for tables with varchar or varbinar columns.For now as a workaround you can use a generic db_out adapter which supports mapping of ESP string to HANA clob. It is not as fast as HANA adapter because it is single threaded but it might be sufficient for your use case.Regards,Andrzej.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to transport a long String(Base64) from ESP to HANA?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-12-11 15:34:00", "resolve": false, "uid": "119", "title": "Socket Tutorial?", "url": "http://scn.sap.com/thread/3667516", "text": "Hi Folks, wondering if someone can help me out. I am trying to piece together what is required to use the socket input adapter. I have worked through the tutorial for using the File Input Adapter but wondering if we have something similar for the socket adapter. I have looked at the Adapter documentation which lists a bunch of properties but I cannot seem to find the documentation that outlines how to configure an end to end scenario for using the socket adapter.Can I use the socket adapter without having to use the SDK? Am I just required to create a Java Client that would open a socket and just start writing to it with data that matches the correct input format?Thanks,Scott", "views": "158", "answers": 1, "author": "Scott Dillon", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-12-11 20:35:00", "resolve": "", "uid": "119.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3667516", "text": "Scott - I'll have to defer to folks with deeper expertise to give you more specific guidance. I'm afraid we don't have a tutorial for using the socket adapter. But a few key points:1. In the current version, the socket adapter has to open the connection. (in earlier versions, either the adapter or the publisher/subscriber could open the connection, but to tighten up security, this was changed to only support \"outbound\" connections2. your java client does not need to use the SDK. It just needs to be able to accept the connection request from the adapter, and then write messages in the appropriate format (e.g. JSON, etc)Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Socket Tutorial?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-12-11 10:36:00", "resolve": true, "uid": "120", "title": "SAP HANA ESP doesn't start correctly", "url": "http://scn.sap.com/thread/3667238", "text": "Hi Experts,I newly installed SAP HANA SPS09 and install add-on component \"Event Stream Processor\",And it said installation is successfully finished.Even so, when I check \"HDB info\" with <sid>adm user,there's no entry of \"hdbstreamingserver\".Is there any bugs on this initial version?BRYoh", "views": "347", "answers": 5, "author": "YOH MAEKAWA", "upvotes": 0, "type": "question", "tags": "hana.event_stream_processing.sps09"},
{"date_time": "2014-12-11 14:26:00", "resolve": "", "uid": "120.1", "author": "YOH MAEKAWA", "url": "http://scn.sap.com/thread/3667238", "text": "Additional information.I noticed that in daemon.ini file, \"instances\" parameter is set to \"0\" by default.So, I change this parameter to \"1\".After that,daemon service try to start hdbstreamingserver.But it's terminated.\"daemon_<hostname>.30000.000.trc\" showsprocess hdbstreamingserver with pid 12080 exited normally with status 1child <hdbstreamingserver -hdb:instance=00 -hdb:hostname=<hostname> -p/usr/sap/HN4/HDB00/streaming/cluster/hn4/config/cluster.log.properties --config /usr/sap/HN4/HDB00/streaming/cluster/hn4/config/cluster.cfg> terminates during startup -> disabled\"streamingserver_<hostname>.30016.000.log\" showsDec 11 2014 22:11:47.102 FATAL - CODE_700265 | Node [<hostname>] not found in cluster configDec 11 2014 22:11:47.102 FATAL - CODE_700412 | Factory of new node failedI don't know why it can't find Node [<hostname>].andWhere the information should be located?What parameter name is it?If there's working environment, could you please tell me the correct information.BRYoh Maekawa", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP HANA ESP doesn't start correctly", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "120.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3667238", "text": "In your initial post above, you say that you \" installed SAP HANA SPS09 and install add-on component \"Event Stream Processor\". Did you mean to say that you installed HANA SPS09 and add-on component smart data streaming? Event Stream Processor is a completely separate product and cannot be installed on a HANA system1. Confirm that you downloaded the smart data streaming server package and installed it using the HANA installer2. Reference the smart data streaming installation guide3. Daemon modifications are not at all necessary when installing smart data streaming.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP HANA ESP doesn't start correctly", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "120.3", "author": "Joe Skrzypczak", "url": "http://scn.sap.com/thread/3667238", "text": "I suspect that the problem here is that you have installed the software, but you have not added the streaming host.Please note the section in the smart data streaming installation guide \"Adding a Smart Data Streaming Host using LCM Tools\".", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP HANA ESP doesn't start correctly", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "120.4", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3667238", "text": "From the screen shot that you attached I can see that you did install the Smart Data Streaming component. There is a 2nd step required which is to Add the Host to HANA system. This section of the documentation covers the steps for adding the streaming host using hdblcm:Add a Smart Data Streaming Host Using hdblcmhttp://http://help.sap.com/saphelp_hana_options_sds_inst/helpdata/en/34/a4ca31a17147b3bbc843ec1311a3a0/content.htm?frameset=/en/44/4224b0b15544aab0d521fbe7785970/frameset.htm&current_toc=/en/44/4224b0b15544aab0d521fbe7785970/plain.htm&node_id=28A couple of additional notes:1) ESP is a separate standalone product from the Smart Data Streaming option for HANA. As I mentioned above, I can see from the screenshot you attached that you really are installing Smart Data Streaming. I just wanted to clarify the difference for anyone else reading this thread - in particular, ESP is not installed or managed as part of the HANA system and therefore would not be included in \"HDB info\" output. Once you have added the streaming host, it will show up in HDB info output when HDB info is run on the streaming node. 2) I would recommend reverting the edit you made to the daemon.ini file before attempting to add the streaming host.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP HANA ESP doesn't start correctly", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "120.5", "author": "YOH MAEKAWA", "url": "http://scn.sap.com/thread/3667238", "text": "Hi AllThank you for your reply.As you mentioned, I didn't set up streaming host.That's the reason of my problem.BRYoh", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP HANA ESP doesn't start correctly", "type": "answer", "tags": "N/A"},
{"date_time": "2014-10-29 06:17:00", "resolve": false, "uid": "121", "title": "HANA SDA to ESP window", "url": "http://scn.sap.com/thread/3642506", "text": "Dear All,I am trying to use HANA SDA to connect to ESP server, but always get error \"SAP DBTech JDBC: [476]: invalid remote object name: can't get SQL Server Info: line 0 col 0 (at pos 0)\";I checked my ESP server and I saw the login success which came from the HANA.I am using something similar to below connection string:CREATE REMOTE SOURCE TEST_SDA_TO_ESP ADAPTER \"odbc\" CONFIGURATION 'Servername=XXXXXXX;Port=19011;Driver=libesp_psqlodbca_lib.so;Database=gujing_cluster_workspace/test_sdk;SSLmode=disable;'WITH CREDENTIAL TYPE 'PASSWORD' USING 'user=I053866;password=XXXXXX';Please help, thank you!", "views": "2625", "answers": 11, "author": "Richard Gu", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-10-30 09:24:00", "resolve": "", "uid": "121.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3642506", "text": "Hi,I really am not familiair with HANA SDA and can't help you with that.Just wanted to point out one thing that doesn't make any sense.Apparently you are trying to setup a connection through the ODBC interface.However you are getting back an error from the JDBC interface talking about Microsoft SQL Server; which is a completely different interface and completely different database and that just doesn't add up. Furthermore ESP doesn't have a Database parameter. Are by chance using a completely different connection string that doesn't have any resemblance at all with what you provided here?What is the REMOTE SOURCE designed to use for: ODBC or JDBC?Are you able to connect with a different datatbase through ODBC?Maybe you should specify an ODBC DSN parameter and check outside Hana if you can connect with that DSN if it connects successfully.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.2", "author": "Richard Gu", "url": "http://scn.sap.com/thread/3642506", "text": "Hi Ben,Thanks for the reply. This JDBC error is thrown from HANA studio and HANA studio connect to HANA server using JDBC. for HANA Server to connect to ESP only ODBC is supported. I think here the JDBC indicate nothing but an error happened in HANA studio. The real server side error is \"invalid remote object name: can't get SQL Server Info: line 0 col 0 (at pos 0)\".I could use ODBC DSN, but it doesn't work either.Anyway, thanks for your reply.Maybe I should ask the question in HANA forum.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.3", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3642506", "text": "This one might be obvious, but does TEST_SDA_TO_ESP  match the exact name of the window in the ESP project? Within an ESP project, window names are case sensitive. Does this name match the case of the name in the ESP project?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.4", "author": "Richard Gu", "url": "http://scn.sap.com/thread/3642506", "text": "Hi Robert, Thanks for the reply;the \"TEST_SDA_TO_ESP\" is the remote source name; The project name is \"gujing_cluster_workspace\" and the window name is \"test_sdk\"; the window name is specified in the connection string as \"Database=gujing_cluster_workspace/test_sdk\"; in ESP the project name and the window name here are all in lowercase.Do you mean the remote source name should be same as the window name?Or do you mean the connection string \"Database=gujing_cluster_workspace/test_sdk\" here is finally converted in uppercase so that can not be found in ESP?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.5", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3642506", "text": "There is a sample of creating a remote source using ESP on page 585 of the SP08 SAP HANA Adminstration guide that I'm looking at. According to the example, you need to specify the project name, workspace name and \"user\" in that order.Databasepath : <ESP Project Name>/<ESP Workspace Name>/userThe order in the docs seems a bit strange, but can you try changing your database parameter to be:Database=test_sdk/gujing_cluster_workspace/userIt then appears that you don't specify the window name until you run the CREATE VIRTUAL TABLE statement.", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.6", "author": "Richard Gu", "url": "http://scn.sap.com/thread/3642506", "text": "Hi Robert, In fact I tried this at very beginning but meeting similar error.In addition, I am very disappointed at this HANA document as some obvious mistakes there:If page 568, you have:<ESP PROJECT>/<ESP WORKSPACE>/userbut in page 569, in the example of connection string, we have:Database=ws1/proj2/userAnyway, none of them works.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.7", "author": "Diana Healy", "url": "http://scn.sap.com/thread/3642506", "text": "Hello Richard,The Knowledge Management Team is starting an initiative where we monitor this forum in order to identify areas of improvement for the product documentation. I read your feedback about the HANA Administration Guide. We will investigate how to make this topic more accurate, and more helpful.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.8", "author": "Dilip Sarmah", "url": "http://scn.sap.com/thread/3642506", "text": "Hi Richard,Give me a week or so - I will provide you the answer on this. I have not used this for a long time so need to check my old notes.For the time being, I would prefer you to move to SP09. HANA SP09 have Smart Data Streaming (SDS) which is closely integrated with HANA. It's life cycle is managed by HANA cluster, works with HANA users, can use DU, has monitoring views, integrated with HANA studio, SDS HANA adapter and CCL HANA reference table. I would suggest you to move SDS since this is where we ESP dev team will be putting more afford.Thanks,Dilip", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.9", "author": "Ashok Gopal Rao", "url": "http://scn.sap.com/thread/3642506", "text": "Hi,i'm facing a similar issue with the same error message.I tried connecting to a ESP project (running on remote Linux machine) using MS Excel as described in the utilities guide. Same error message with ODBC drivers shipped with ESP SP08 PL1 & PL2. The network connectivity is fine as i'm able to connect to the project using ESP Studio from my laptop (Win 7 64-bit).Parameters I used during DSN creation:- Workspace/Project- Server- port- SSL (set to disabled as ESP was installed without SSL)- username (Native OS user on server, used in Studio)- passwordPlease let me know if any solution is identified for this.Regds,Ashok", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.10", "author": "Guilherme Braccialli", "url": "http://scn.sap.com/thread/3642506", "text": "Hi Richard and Ashok,I was also facing very similar errors as yours, but I finally could make it to work!As Dilip Sarmah suggested, I tried with HANA SP9 and Smart Data Streaming, but, initially I got same issues. This time I decided to look deeper...Here I list the steps I followed to successful configure it in HANA SP9 + Smart Data Streaming: 1- Install HANA SP9 + HANA Smart Data Streaming 2- Download and install the latest version of unixODBC (http://www.unixodbc.org/download.html) tar -xvf unixODBC-2.3.2.tar.gz cd unixODBC-2.3.2 ./configure --prefix=/usr/local/unixODBC make make install 3- Create links to unixODBC libs below: cd /usr/local/unixODBC/lib ln -s libodbccr.so.2.0.0 libodbccr.so.1 ln -s libodbcinst.so.2.0.0 libodbcinst.so.1 ln -s libodbc.so.2.0.0 libodbc.so.1 4- Add unixODBC lib to streaming library path: vi /usr/sap/BBB/HDB00/streaming/STREAMING.sh (and add two lines below) LD_LIBRARY_PATH=\"/usr/local/unixODBC/lib\":$LD_LIBRARY_PATH export LD_LIBRARY_PATH 5- Add Smart Data Streaming host to your no_proxy environment variable (ESP odbc client have some issues with proxy settings, see: http://www.sdn.sap.com/irj/scn/go/portal/prtroot/docs/library/uuid/7079eef1-53b6-3010-98ae-90e172a82acb?QuickLink=index&overridelayout=true&59511066929382) vi /etc/profile.d/proxy_settings.sh export no_proxy=\"sap.corp,localhost,127.0.0.1,moo-repo,169.254.169.254,repo,mo-b1f55fc59,mo-e0ef78976\" 6- Create .odbc.ini file to check if the ODBC connection is OK (before creating Smart Data Access) su - bbbadm (your hana instance user) vi .odbc.ini (with contents below)[esp1]Driver=/data1/hana/shared/BBB/streaming/STREAMING-1_0/odbc/libstreamingpsqlodbca_lib.soDatabase=default/teste_espServername=mo-e0ef78976Port=30016Username=SYSTEMPassword=XXXXXSSLmode=enable 7- Test your odbc connection: /usr/local/unixODBC/bin/isql -v esp1 You must see isql prompt: +---------------------------------------+ | Connected! | | | | sql-statement | | help [tablename] | | quit | | | +---------------------------------------+ SQL> 8- Create SDA connection in your hana studio:CREATE REMOTE SOURCE esp1 ADAPTER \"odbc\" CONFIGURATION FILE 'property_esp.ini' CONFIGURATION  'Driver=/data1/hana/shared/BBB/streaming/STREAMING-1_0/odbc/libstreamingpsqlodbca_lib.so;Database=default/teste_esp;Servername=mo-e0ef78976;Port=30016;Username=SYSTEM;Password=XXXXXX;SSLmode=enable' WITH CREDENTIAL TYPE 'PASSWORD' USING 'user=SYSTEM;password=XXXXX'CREATE VIRTUAL TABLE summary AT esp1.\"default\".\"teste_esp\".\"summary\" select * from summaryTroubleshooting:Here are the list of issues I found out and how I fixed them. If you are facing errors, I suggest you checking your ODBC connection using isql before trying SDA commands.a- ODBC libsIf you receive error message below (file not found), check if you created links to unixODBC librarys:Error:[01000][unixODBC][Driver Manager]Can't open lib '/data1/hana/shared/BBB/streaming/STREAMING-1_0/odbc/libstreamingpsqlodbca_lib.so' : file not found[ISQL]ERROR: Could not SQLConnectSolution:cd /usr/local/unixODBC/libln -s libodbccr.so.2.0.0 libodbccr.so.1ln -s libodbcinst.so.2.0.0 libodbcinst.so.1ln -s libodbc.so.2.0.0 libodbc.so.1b- Library pathIf you receive error message below (file not found), check if you have unixODBC lib folder and ESP odbc folder in your LD_LIBRARY_PATHError:[01000][unixODBC][Driver Manager]Can't open lib '/data1/hana/shared/BBB/streaming/STREAMING-1_0/odbc/libstreamingpsqlodbca_lib.so' : file not found[ISQL]ERROR: Could not SQLConnectSolution:export LD_LIBRARY_PATH=/usr/local/unixODBC/lib:/data1/hana/shared/BBB/streaming/STREAMING-1_0/odbc/If you continue to receive file not found, check which one is missing in your LD_LIBRARY_PATH using command below:ldd /data1/hana/shared/BBB/streaming/STREAMING-1_0/odbc/libstreamingpsqlodbca_lib.soc- ProxyESP odbc client have some issues with proxy settings, see: http://www.sdn.sap.com/irj/scn/go/portal/prtroot/docs/library/uuid/7079eef1-53b6-3010-98ae-90e172a82acb?QuickLink=index&overridelayout=true&59511066929382Error: [08001][unixODBC]can't get SQL Server Info[ISQL]ERROR: Could not SQLConnectAnd the error below in strace:recvfrom(3, \"HTTP/1.1 403 Forbidden\\r\\nCache-Co\"..., 16384, 0, NULL, NULL) = 5392Solution:export no_proxy=$no_proxy,mo-e0ef78976d- Debug / straceisql seems to always show the same error message, doesnt matter what issue is happening:[08001][unixODBC]can't get SQL Server Info[ISQL]ERROR: Could not SQLConnectI couldnt find any log files. The way I found out to get a hint about the issue is to use strace command:strace /usr/local/unixODBC/bin/isql -v esp1It was with strace that I found out the proxy issue. Richard and Ashok,I think this tips can help you. If nothing works, try to send me your strace output from isql command.", "views": "N/A", "answers": "N/A", "upvotes": 3, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "121.11", "author": "Richard Gu", "url": "http://scn.sap.com/thread/3642506", "text": "Dear Braccialli,Many thanks for such a detailed explain, I will try follow your suggestion and using SP09.Any result, I will let you know.Thanks!", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:HANA SDA to ESP window", "type": "answer", "tags": "N/A"},
{"date_time": "2014-12-09 21:59:00", "resolve": false, "uid": "122", "title": "Setup ESP Cluster Nodes On Multiple Machines", "url": "http://scn.sap.com/thread/3666283", "text": "Hi,I am trying to setup two ESP Cluster nodes on two machines but not successful. Does anyone have instructions on how it can be done?I began my test by setting up the cluster_example to run on a single machine, and I was able to start all 4 nodes on a single machine. However, when I tried to modify the cluster_example to start two nodes on two physical machines, it failed. I was able to start the first node on the first machine, but the second node failed to start. And the error message seems to indicate that the problem is related to the security key on the second machine. Any help is much appreciated!Best regards,William", "views": "200", "answers": 1, "author": "William Woo", "upvotes": 0, "type": "question", "tags": "complex_event_processing.cep.esp_5.1"},
{"date_time": "2014-12-15 13:55:00", "resolve": "", "uid": "122.1", "author": "Diana Healy", "url": "http://scn.sap.com/thread/3666283", "text": "Hi William,It is important that all nodes in a cluster have the same cluster key file, which is used to encrypt SSL files and passwords in cluster configuration. Double check that you have copied the cluster_example.key from your first machine to use on your second machine.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Setup ESP Cluster Nodes On Multiple Machines", "type": "answer", "tags": "N/A"},
{"date_time": "2014-12-08 18:34:00", "resolve": true, "uid": "123", "title": "View Workspaces", "url": "http://scn.sap.com/thread/3665459", "text": "How can i view workspaces?http://localhost:9091/espws/restservice/workspacesWhen i create a new workspace will it by default get created in espws/restservice/workspaces? or do i have to do any additional steps to make this workspace available under this location.-AB", "views": "339", "answers": 6, "author": "Anil Bavaraju", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-12-09 01:16:00", "resolve": "", "uid": "123.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3665459", "text": "Once you add a workspace, it is available and you can start projects in it. You can create a new workspace on the cluster from the Studio (Run-Test Perspective) or using the command line tool: streamingclusteradmin --add_workspace <name>Similarly, you can see what workspaces are defined on the cluster from the Studio, server view or using the command line tool: streamingclusteradmin --get_workspacesYou can also see what workspaces are available, and deploy projects to workspaces, using the REST interface - see the WSP documentation.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:View Workspaces", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "123.2", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3665459", "text": "Jeff,Thanks a lot for your response.I am working on a POC on SAP Design Studio, HANA, ESP integration for one of our customer.When i pass this url in SAP Design Studio i get the below error, i entered host (localhost) and REST port (9091), and clicked on connect. <html><head><meta http-equiv=\"Content-Type\" content=\"text/html;charset=ISO-8859-1\"/><title>Error 404 </title></head><body><h2>HTTP ERROR: 404</h2><p>Problem accessing /espws/restservice/workspaces. Reason:<pre> Not Found</pre></p><hr /><i><small>Powered by Jetty://</small></i></body></html>I have a project running under default workspace, and it is exposed as a webservice.Help document does not give any additional information, all it says is ESP should be on SP9 and project should be running.Appreciate your help.-AB", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:View Workspaces", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "123.3", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3665459", "text": "Jeff,Now i am getting a different error with the same localhost and 9091 port<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/><title>Error 400 Invalid connection details</title></head><body><h2>HTTP ERROR 400</h2><p>Problem accessing /espws/restservice/workspaces. Reason:<pre> Invalid connection details</pre></p><hr><i><small>Powered by Jetty://</small></i><hr/></body></html>-AB", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:View Workspaces", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "123.4", "author": "Juan Wu", "url": "http://scn.sap.com/thread/3665459", "text": "Here is the link to Rest request of getting list of workspaces:View a List of Workspaces in a Cluster - SAP Event Stream Processor: Adapters Guide - SAP LibraryPlease make sure that you have the header set up correctly with base64 encrypted credential. And also make sure that in the wsp.xml configuration file the defaultCluster has been pointing to the cluster at localhost and port 9786. Then give it a try and let us know if there's any problem.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:View Workspaces", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "123.5", "author": "Diana Healy", "url": "http://scn.sap.com/thread/3665459", "text": "Hello Anil,The Knowledge Management Team is starting an initiative where we monitor this forum in order to identify areas of improvement for the product documentation. I read your comments about having to refer to three documents to get what you were looking for. We would simplify the process so that finding this information would be easier in the future.Would you mind sharing a little more about your search? Besides the REST documentation in the Adapters' Guide, where did you look? (One thing we could do, for example, is put references in these other documents, so that finding the information would be easier for other customers). Thanks in advance.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:View Workspaces", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "123.6", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3665459", "text": "Diana,To integrate ESP, HANA and Design Studio i had to refer too many documents, it is not like ESP or Design Studio document is incomplete. It is just that i wish there was just one document which had all the information.So, i created an overview demo, and i will be posting more blogs on this.Real-Time and Near Real-Time Streaming using SAP ESP, SAP HANA and SAP Design Studio-AB", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:View Workspaces", "type": "answer", "tags": "N/A"},
{"date_time": "2014-12-17 10:01:00", "resolve": true, "uid": "124", "title": "list of lists?", "url": "http://scn.sap.com/thread/3669919", "text": "So, ESP is added to HANA, which perfectly makes sense to me. A natural evolution.Now I'm wondering: is it already possible to receive list of lists (so a matrix) as a basic data type?", "views": "142", "answers": 2, "author": "Star buck", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-12-17 14:52:00", "resolve": "solution", "uid": "124.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3669919", "text": "Data types supported in events in smart data streaming (and ESP) are all scalar, but there are data structures in CCL (the event processing language used by SDS and ESP) that can be used to create a list of lists (dictionaries and vectors - and you can have, for example, a dictionary of dictionaries).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:list of lists?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "124.2", "author": "Star buck", "url": "http://scn.sap.com/thread/3669919", "text": "Tnx mate!So you can create lists of lists and other nightmares in CCL, but not digest them directly in an adapter without building the list of list structure first based on scalar types which are digested by the adapter.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:list of lists?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-12-17 17:03:00", "resolve": false, "uid": "125", "title": "Can an adapter come back from DEAD on its own?", "url": "http://scn.sap.com/thread/3670181", "text": "Hi Folks,I have a couple of ESP projects making heavy use of the generic database adapter (for INPUT). From timeto time one such connection will fail and throw the connector into a state of DEAD. In my experience, thereis no going back to IDLE, READY, CONTINUOUS, etc without admin intervention (by me) using the studio,or some other ESP command line utility to reset the adapter and bring it back to life.Am I missing something? Is there no retry configuration of any kind?Thanks,Michael", "views": "186", "answers": 2, "author": "Michael Scharber", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-12-18 17:48:00", "resolve": "", "uid": "125.1", "author": "Michael Scharber", "url": "http://scn.sap.com/thread/3670181", "text": "How about extrinsic inspection of status followed by controlled actions against a specific adapter/connection in a running ESP project? This must be a common need, so my question is how is this most effectively dealt with, while avoiding a full stop/start of the project.Thanks,Michael", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can an adapter come back from DEAD on its own?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "125.2", "author": "Beverly Duquette", "url": "http://scn.sap.com/thread/3670181", "text": "Michael,For your question, How about extrinsic inspection of status followed by controlled actions against a specific adapter/connection in a running ESP project? There are several ways to view the status against an adapter/connection in SP09.-Use the ESP Cockpit to monitor Connection Statistics or Adapter Statistics. More information can be found at:http://help.sap.com/saphelp_esp_51sp09_cp/helpdata/en/14/00f27b751e1014abd8d49a9dd69828/content.htm?frameset=/en/13/fe6b37751e1014b0c68638f8621e91/frameset.htm&current_toc=/en/13/f6cdc7751e1014b9b1acaf8560b4a8/plain.htm&node_id=76&show_children=false- Use the streamingsubscribe (formerly called esp_subscribe) utility and subscribe to the _ESP_Connectors. This will provide you with information about the state of your adapter. Information for monitoring metadata streams can be found in the Configuration and Administration Guide at:http://help.sap.com/saphelp_hana_options_sds_conf/helpdata/en/e7/9c64516f0f1014859dff22969aa393/frameset.htmFor starting and stopping an adapter, The streamingprojectclient (formerly called esp_client) has options to start and stop an adapter. Information on the streamingprojectclient can be found in the Utilities Guide at: http://help.sap.com/saphelp_esp_51sp09_util/helpdata/en/e7/95d0646f0f1014908b91ec9fc8942a/content.htm?frameset=/en/e7/749ff66f0f10149ee5d00627503229/frameset.htm&current_toc=/en/e7/749ff66f0f10149ee5d00627503229/plain.htm&node_id=15In the Studio, you can also start and stop an adapter:http://help.sap.com/saphelp_esp_51sp09_cp/helpdata/en/14/08a9b3751e10148f7bcffc02e72de9/content.htm?frameset=/Thanks,Beverly Duquette", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can an adapter come back from DEAD on its own?", "type": "answer", "tags": "N/A"},
{"date_time": "2014-12-03 17:46:00", "resolve": false, "uid": "126", "title": "Default Workspace Missing", "url": "http://scn.sap.com/thread/3663316", "text": "I had ESP 5.1 SP8 installed (in HANA Studio) and all the demo's we working fine. Last evening i uninstalled SP8 and did a fresh install of 5.1 SP9, now i am unable to run the project.There is no \"default\" under the localhost:9786, when i run the project i just see some flash of CMD screen and that's it nothing is happening.-AB", "views": "526", "answers": 10, "author": "Anil Bavaraju", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2014-12-03 18:03:00", "resolve": "", "uid": "126.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3663316", "text": "Hello,What version of HANA Studio are you using? Did you also upgrade that? And, please specify which demo's, just so that I can try to reproduce what you are seeing. Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.2", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3663316", "text": "Alice,I am on HANA SPS 08 (Version: 1.80.3), and i did not upgrade that.I just created a very simple demo, and it doesn't run in HANA Studio. However i am able to run a project when i use the SAP ESP Studio.-AB", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.3", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3663316", "text": "Below are the screenshots:", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.4", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3663316", "text": "Hi Anil,To install the ESP 5.1 SP09 Studio plugin into SAP HANA studio, you must have installed SAP HANA studio, with a minimum of Eclipse version 4.4. (Refer to this link: Install the SAP ESP Studio Plugin for SAP HANA Studio - SAP Event Stream Processor: Installation Guide for Windows - SAP)To find out what Eclipse version your HANA studio is using, check the contents of <hdbstudio-install-dir>/.eclipseproduct.So, for example, on my set-up that has HANA Studio 1.80, the contents of .eclipseproduct are:name=Eclipse Platformid=org.eclipse.platformversion=4.3.2However, on my set-up that has HANA Studio 1.90, the contents of .eclipseproduct are:name=Eclipse Platformid=org.eclipse.platformversion=4.4.0Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.5", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3663316", "text": "Thanks Alice!Yes, my Eclipse version is version is 4.3.2.I will update the eclipse version and will let you know.-Anil", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.6", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3663316", "text": "Alice,It still does not work, i tried with eclipse 4.4.0. I even tried it with the latest HANA Studio, still no luck.I am just using the SAP ESP Studio instead of ESP in HANA Studio. Do you see default workspace in your HANA 1.90?-AB", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.7", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3663316", "text": "Hi Anil,I am seeing the same issue as you are. We are investigating. I'll keep you posted.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.8", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3663316", "text": "Thanks Alice!I could not use the HANA studio, so I created a demo using the ESP Studio.http://visualbi.com/blogs/design-studio/real-time-near-real-time-streaming-using-sap-esp-sap-hana-sap-design-studio/Regards,-Anil Bavaraju", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.9", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3663316", "text": "I thought I'd offer an explanation here. It's most unfortunate that this change from ESP SP08 to SP09 did not get documented - as it has indeed caused some confusion. But here's what's going on:With the release of SAP HANA smart data streaming, we now deliver 2 different product packages from the same code line. SAP ESP is intended for use independently of HANA; when someone needs event processing with HANA we expect that they will use SAP HANA smart data streaming.The SAP HANA smart data streaming server runs as part of the SAP HANA landscape. It cannot run separately from the HANA system it is installed on.Now this brings me to the behavior of the ESP Studio and the Streaming plugin for HANA Studio.The ESP Studio gives you the ability to start and run a local ESP cluster very simply.The ESP plugin for HANA studio used to have the same capability. However, the ESP plugin for HANA Studio has been replaced by the Streaming plugin for HANA Studio. The new HANA Studio plugin does not have this capability, as it is intended to be used with SAP HANA smart data streaming. Therefore, to run a streaming project from HANA studio, you must be connected to a HANA streaming cluster.The ESP studio still has the ability to start a local cluster under the control of the Studio.Sorry for the confusion this caused.Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "126.10", "author": "Anil Bavaraju", "url": "http://scn.sap.com/thread/3663316", "text": "Thanks Jeff for sharing this information.-Anil", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Default Workspace Missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-01-13 10:02:00", "resolve": false, "uid": "127", "title": "Getting error \"internal error\" while starting esp sdk(c) using \"esp_sdk_start\"", "url": "http://scn.sap.com/thread/3679828", "text": "I am getting error \"internal error\" while starting esp sdk(c) using \"esp_sdk_start\". This is not repeating each and every time. This is happening occasionally. I need to know what may be the reason.", "views": "255", "answers": 1, "author": "Suhas Yalgude", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-01-13 17:22:00", "resolve": "", "uid": "127.1", "author": "Shubhra Biswas", "url": "http://scn.sap.com/thread/3679828", "text": "Hi Suhas,Could you please provide a bit more detail. Which version are you using? The platform and a snippet of your code would also helpThanks,Shubhra", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Getting error \"internal error\" while starting esp sdk(c) using \"esp_sdk_start\"", "type": "answer", "tags": "N/A"},
{"date_time": "2015-01-14 13:32:00", "resolve": false, "uid": "128", "title": "Link for downloading JAVA-SDK for SAP Event Stream Processor (ESP)", "url": "http://scn.sap.com/thread/3680700", "text": "Hello everybody,i can't find a link which leads to a download of ESPs JAVA-SDK.Can anybody tell me where to get the JAVA-SDK from?Thanks a lot in advance,Joh", "views": "213", "answers": 1, "author": "Johannes Wendel", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-01-14 15:19:00", "resolve": "", "uid": "128.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3680700", "text": "Hello Joh,It is part of the ESP Software Download Package.You can find the list of the required libraries for the Java SDK in the ESP docs at this link: Java SDK: Required Libraries - SAP Event Stream Processor: SDK Guide - SAP LibraryThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Link for downloading JAVA-SDK for SAP Event Stream Processor (ESP)", "type": "answer", "tags": "N/A"},
{"date_time": "2015-01-23 13:11:00", "resolve": false, "uid": "129", "title": "Starting multiple external JAVA Adapter", "url": "http://scn.sap.com/thread/3685317", "text": "Hi colleagues,our team is trying to run several (3+) different external Adapters in the same ESP Cluster simultaneously .We used the following provided JAVA libraries to write our Java Adapters :com.sybase.esp.adapter.api.Adaptercom.sybase.esp.adapter.api.AdapterControllerI want to highlight, that each of the adapters are completely different and also have different tasks. Now I have the problem that when I start one or more projects on my local cluster only one adapter is starting. The status of the other adapters is DEAD and When I try to start them manual with the start-command via command line I am getting the message \" ... Adapter status: {0}\".Additionally, the status-command is returning: \"... Adapter status: running\".It seems ESP cannot differentiate multiple adapters. Are you aware of this problem and could provide a solution? Maybe I am wrong in some points but I hope you can help me to clarify them. Thanks in advance and regards,Lukas", "views": "374", "answers": 5, "author": "Lukas Carullo", "upvotes": 0, "type": "question", "tags": "java.adapter.esp"},
{"date_time": "2015-01-23 15:04:00", "resolve": "", "uid": "129.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3685317", "text": "Hi Lukas - it's not obvious to me what the problem is, but you can certainly run multiple adapters on the ESP cluster. I'll be sure someone take a look at this and provides you with some troubleshooting tips.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Starting multiple external JAVA Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "129.2", "author": "Lukas Carullo", "url": "http://scn.sap.com/thread/3685317", "text": "Some more information: I followed the instruction given by the adapter example in the ESP installation folder %ESP_HOME%\\adapters\\sample\\README It would be also interesting where I can find the documentation of the used libraries e.g. com.sybase.esp.adapter.api ... . Thanks!Lukas", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Starting multiple external JAVA Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "129.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3685317", "text": "What version of ESP do you have? I have the current version, SP09 installed, and I don't have the samples directory you seem to have.The documentation for the Adapter Toolkit is here: Event Stream Processor Adapter Toolkit - SAP Event Stream Processor: Building Custom Adapters - SAP LibraryAnd the javadoc is in: %ESP_HOME%\\doc\\adaptertoolkit", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Starting multiple external JAVA Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "129.4", "author": "Lukas Carullo", "url": "http://scn.sap.com/thread/3685317", "text": "I am using SP08 and my exact path is ...\\Sybase\\ESP-5_1\\adapters\\sample\\README. Maybe these instructions have been removed from SP08 to SP09. I am aware of the adapter toolkit, but we use the Adapter Integration Framework - SAP Event Stream Processor: Building Custom Adapters - SAP Libraryand I cannot find the javadoc or a working example of this framework.In particular: where can I find a documentation of the following java libs:import com.sybase.esp.adapter.api.Adapter;import com.sybase.esp.adapter.api.AdapterController;import com.sybase.esp.adapter.api.AepUtils;import com.sybase.esp.adapter.api.AepUtilsFactory;import com.sybase.esp.adapter.api.I18NUtil;import com.sybase.esp.adapter.api.pubsub.SpUtils;Thanks and regards,Lukas", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Starting multiple external JAVA Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "129.5", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3685317", "text": "Let me provide a bit of an overview:The Adapter Integration Framework is not a Java API. It is a means of allowing adapters to run as \"managed adapters\" under the control of a CCL project and also to appear in the Studio palette and be configurable via Studio tools. It defines the formal of an xml file (.cnxml) that tells the studio and server how to start, stop and configure the adapter.Java adapters can be built in two ways:1. the easiest is to use the ESP Adapter Toolkit. The doc is here: Event Stream Processor Adapter Toolkit - SAP Event Stream Processor: Building Custom Adapters - SAP Library and the java doc is in %ESP_HOME%\\doc\\adaptertoolkit2. The other option is to use the Java SDK directly. The Adapter Framework uses this, but also does other work for you. But in some cases you may prefer to work at this level. The javadoc for the Java SDK is here: %ESP_HOME%\\doc\\sdk\\java. There is also info in the doc set: Java External Adapters - SAP Event Stream Processor: Building Custom Adapters - SAP LibraryNote: all of the above is for ESP SP09. There may be slight differences with SP08.I don't recognize the classes you list above. Did you leave out the \"sdk\" bit? They look like Java sdk classes, but those would be, eg. in the package: com.sybase.esp.sdk.adapter", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Starting multiple external JAVA Adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-02-05 05:34:00", "resolve": true, "uid": "130", "title": "Smart Data Streaming on HANA : Data service discovery not working when running SDS on multiple host", "url": "http://scn.sap.com/thread/3691399", "text": "Hi,I previously had set up SDS on HANA where streaming-server was running on one node and I was able to run ESP projects on that successfully. No I want to check how it works when there are multiple node as streaming node. So I did the following :I have three hosts, let's assume their DNS full names are hana, sds1 and sds2. I installed HANA and SDS in hana system and added sds1 and sds2 as streaming host../hdblcm - -action=add_hosts - -addhosts=< Smart_Data_Streaming _host_full_DNS>:role=streamingEverything works out pretty well and HANA system was up and running with two streaming host.Next I installed unixODBC driver in sds1 host, as mentioned in the admin and configuration guide of SDS and then created the symbolic link as stated there. Also added the line LD_LIBRARY_PATH=\"/usr/local/lib\":$LD_LIBRARY_PATH export LD_LIBRARY_PATH in the file /hana/shared/<SID>/streaming/STREAMING.sh as per the document. After that restarted the HANA system. Also created a datasource in the .odbc.ini file of /usr/sap/<SID>/home as mentioned in the document.Now I added the streaming host sds1 in the eclipse server view and then created a service using the datasource. When I try to discover schemas from that service, it throws an error(see the attached image).While setting up the same for one host which I did previously, I followed exactly the same steps and it worked! Is there something that I am missing here ?Also my intention of setting up multiple streaming server was to create a streaming cluster and see how the load balancing and failover works. I saw in the document that ESP cockpit can be opened in web browser with the link as https://<sds1>/cockpit It does not work for me. What all needs to be done for this cluster configuration ? I have followed the steps mentioned in the document regarding running the cockpit.sh file. Even after that the link does not work for me.Regards,Subhankar", "views": "544", "answers": 6, "author": "Subhankar Chattopadhyay", "upvotes": 0, "type": "question", "tags": "sap_hana.sps_09.smart_data_streaming"},
{"date_time": "2015-02-06 17:49:00", "resolve": "", "uid": "130.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3691399", "text": "Hi Subhankar,I was able to test this today. I started with a working HANA SDS system with a working ODBC data service. The system initially had a single streaming node. I added the 2nd streaming node/host then tested stopping & starting a project and running Discover against the existing ODBC data service. For my system everything is working cleanly. Note that at this point, I haven't even configured the ODBC connection on the 2nd node. Given the test I just did, I expect that you have an ODBC configuration issue that is independent of using multiple SDS nodes in a cluster. As a diagnostic step you may want to try removing the 2nd streaming host and verifying whether or not your ODC Data Service discovery works on this system with a single streaming host.Thanks", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming on HANA : Data service discovery not working when running SDS on multiple host", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "130.2", "author": "Subhankar Chattopadhyay", "url": "http://scn.sap.com/thread/3691399", "text": "Hi Robert,Thank you for your reply. I have removed the 2nd host and checked. But the 1st host discovery didn't work. However I had some doubt regarding the LD_LIBRARY_PATH configuration so I reverted that and now discovery works!  Which means that the host is getting connected and I only have .odbc.ini file in /usr/sap/<SID>/home having the service configured, but I don't have the LD_LIBRARY_PATH configured as per the document.Could you please tell me when is this LD_LIBRARY_PATH configuration necessary ?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming on HANA : Data service discovery not working when running SDS on multiple host", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "130.3", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3691399", "text": "If you followed the instructions in the product documentation or in the Configuring a HANA ODBC Connection for Smart Data Streaming in SPS09 document here on the SCN for installing the ODBC Driver Manager, then the ODBC Driver Manager will be located in the /usr/local/lib directory. That location is not in the LD_LIBRARY_PATH by default. The instructions to update the LD_LIBRARY_PATH setting the STREAMING.sh are there to make the /usr/local/lib directory part of that path and hence make the ODBC Driver Manager visible to the Streaming server. If you already have an ODBC Driver Manager installed on the system and/or you place the ODBC Driver Manager in a different directory location that is already included in the LD_LIBRARY_PATH then you would not need to edit the STREAMING.sh to add the /usr/local/lib directory to the path.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming on HANA : Data service discovery not working when running SDS on multiple host", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "130.4", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3691399", "text": "For your second question on using ESP Cockpit, check out the documentation on Starting SAP ESP Cockpit - SAP HANA Smart Data Streaming: Configuration and Administration Guide - SAP LibraryThe ESP Cockpit is not started automatically so you will need to start the process before you can connect from the browser. Also note that SAP ESP Cockpit is listening on an SSL connection so the default URL will have the form: https://<hostname>:4283/cockpit", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming on HANA : Data service discovery not working when running SDS on multiple host", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "130.5", "author": "Subhankar Chattopadhyay", "url": "http://scn.sap.com/thread/3691399", "text": "I am following the same guide for this. Briefly, I did the following :1. First I logged in to HANA host as <sid>adm user and logged in to streamingcluster admin utility as described in the document. Screenshot for the whole operation is below.2. Next I logged in to the 1st streaming host again as <sid>adm user and execute ./cockpit.sh as per the document. See the screenshot below.After this I am trying to open the following url :https://<first sds host dns full name>:4283/cockpitBut this url is not accessible. Am I missing something here ?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming on HANA : Data service discovery not working when running SDS on multiple host", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "130.6", "author": "Subhankar Chattopadhyay", "url": "http://scn.sap.com/thread/3691399", "text": "This was a proxy issue and thanks to Robert, I was able to resolve it.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming on HANA : Data service discovery not working when running SDS on multiple host", "type": "answer", "tags": "N/A"},
{"date_time": "2015-02-10 16:30:00", "resolve": true, "uid": "131", "title": "performance of db_out adapter", "url": "http://scn.sap.com/thread/3694286", "text": "Hi,I need help on performance esp adapter db_out . [ESP 5.1 SP08]I have a problem statement like-\"I have one esp model that gets continuous data from ibm message queues. these continuous messages are processed by esp dynamically and results are written into 40 different output windows. then esp model send the content of these 40 output windows to oracle 11g database using db_out continuously.This whole thing works fine for limited time but when I keep pumping the data for longer time then these output windowsslow down while sending data to oracle 11g database. for example initially these output windows/adapters sends data by say 500 records per second but after some time this reducesto say 20-30 records per second.I have referred the esp client monitors log and seen that their[output windows] queue is completely filled.[max 1024]Means ESP is processing data faster then the output windows send data back to database.because of this in my esp model their is logjam kind of condition.esp model is not able to take any further data from ibm mq's till it sends its output windows data to oracle 11g database.\"Now I need to improve this logjam kind of condition so that Data can be sent to database quickly and esp should not be facing any logjam condition.Please help me with your inputs and suggestions.RegardsAdesh", "views": "178", "answers": 3, "author": "Adesh Sachan", "upvotes": 0, "type": "question", "tags": "sap_sybase_event_stream_processor.adapter.stream_processing"},
{"date_time": "2015-02-11 16:55:00", "resolve": "solution", "uid": "131.1", "author": "Andrzej Kucharczyk", "url": "http://scn.sap.com/thread/3694286", "text": "Hi Adesh,db_out adapter performs best when it can consistently send large batches or rows. If your incoming data has frequent opcode changes (from insert to delete to update etc) new batch is started for everyone opcode change and data is likely transferred in small number of rows at a time. If you can control the order of your incoming data please arrange it in way that groups rows with same opcode together. For example first do all inserts, then any updates, then any deletes if at all possible without affecting the end result.Another issue that often affects overall performance is that some publishers perform SDK commit operation too frequently. This causes entire project to block while all the queues are drained. That blocks all publishers that feed the data. Try doing commits less frequently. This will give adapter a chance to fully fill in their batches and transfer more data at a time.Regards,Andrzej.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:performance of db_out adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "131.2", "author": "Adesh Sachan", "url": "http://scn.sap.com/thread/3694286", "text": "Hi Andrzej,How can I make grouping in esp model file as per the operation types[update,inserts etc].I have looked at the esp server log and find out that the order of execution/update or insert is pretty non linear . Like I am having almost 40 something output windows which sends data to database.I tried to make an order of execution but its like there are n numbers of db_out operations written to database at a time.how to make grouping as per the operation type ??thanksregardsAdesh", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:performance of db_out adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "131.3", "author": "Andrzej Kucharczyk", "url": "http://scn.sap.com/thread/3694286", "text": "Hi Adesh,Actually what I had in mind is having the publishers that feed the model try to group their operations. That would be most efficient way since doing it in Java or C is faster than in CCL/Splash.If that's not possible then another option would be to create a flex stream between window and the adapter. The flex stream would have some splash logic to for example collect updates in a vector (for lets say 2 minutes or for some maximum size) and only let inserts through while you collect updates. Then every 2 minutes or when your desired max size is reached let the updates through by iterating through your vector and then clearing it. Similarly for deletes. You would only have to do that for windows that get most traffic and where you see slow performance. Be aware that this approach will consume more memory. You might have to limit how long you collect your updates and vary it depending on traffic level you get in each window.Also for each adapter make sure your batchLimit property is set to a large value. I would start with 10000. Then try increasing it to see if it makes a difference. Be aware that having large batch size might affect your latency. Same with collecting rows in flex stream.Regards,Andrzej.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:performance of db_out adapter", "type": "answer", "tags": "N/A"},
{"date_time": "2015-02-18 09:19:00", "resolve": false, "uid": "132", "title": "Smart data streaming : adapter not running/failing", "url": "http://scn.sap.com/thread/3699540", "text": "Hi,My SDS project was running fine in the streaming server. I was doing some change and deploying the new content. After few of those attempts, now my project adapters are not starting. I saw the frameworkadapter.log and found the following :02-18-2015 08:12:58.284 WARN [main] (AdapterController.executeStart) The adapter could not be started because another instance of the adapter is running.02-18-2015 08:12:58.314 INFO [main] (AdapterController.init) Address 10.97.17.175:19084 is used to accept the control command.02-18-2015 08:12:58.338 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-18-2015 08:12:58.348 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-18-2015 08:12:58.375 INFO [main] (AdapterController.sendCommand) start /hana/shared/K9G/streaming/STREAMING-1_0/adapters/framework/instances/jms_csv_input/adapter_config.xml02-18-2015 08:12:58.400 WARN [main] (AdapterController.executeStart) Another adapter framwork is running whose enviroment variable $STREAMING_HOME value is different with current instance. Please set enviroment variable of $STREAMING_HOME with same value!02-18-2015 08:12:58.469 WARN [main] (AdapterController.executeStart) Another adapter framwork is running whose enviroment variable $STREAMING_HOME value is different with current instance. Please set enviroment variable of $STREAMING_HOME with same value!02-18-2015 08:12:58.475 INFO [main] (AdapterController.init) Address 10.97.17.175:19082 is used to accept the control command.02-18-2015 08:12:58.536 INFO [main] (AdapterController.sendCommand) start /hana/shared/K9G/streaming/STREAMING-1_0/adapters/framework/instances/file_csv_input/adapter_config.xml02-18-2015 08:12:58.598 WARN [main] (AdapterController.executeStart) Another adapter framwork is running whose enviroment variable $STREAMING_HOME value is different with current instance. Please set enviroment variable of $STREAMING_HOME with same value!02-18-2015 08:14:19.926 INFO [main] (Framework.main) start /hana/shared/K9G/streaming/STREAMING-1_0/adapters/framework/instances/file_csv_input/adapter_config.xml02-18-2015 08:14:20.304 INFO [main] (XmlUtils$1.resolveResource) /hana/shared/K9G/streaming/STREAMING-1_0/adapters/framework/config/parametersdefine.xsd02-18-2015 08:14:20.312 INFO [main] (XmlUtils$1.resolveResource) /hana/shared/K9G/streaming/STREAMING-1_0/adapters/framework/config/standard_module_parametersdefine.xsd02-18-2015 08:14:20.631 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) Sandbox is set to allow only data in these folders can be processed:02-18-2015 08:14:20.632 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/streaming/STREAMING-1_0/adapters/framework02-18-2015 08:14:20.632 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/streaming/STREAMING-1_0/adapters/framework/-02-18-2015 08:14:20.633 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/data_streaming/cluster/projects/k9g/default.final.002-18-2015 08:14:20.633 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/data_streaming/cluster/projects/k9g/default.final.0/-02-18-2015 08:14:20.634 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/streaming/STREAMING-1_0/adapters/rfc02-18-2015 08:14:20.635 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/streaming/STREAMING-1_0/adapters/rfc/-02-18-2015 08:14:20.635 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/streaming/STREAMING-1_0/adapters/webservices02-18-2015 08:14:20.637 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/streaming/STREAMING-1_0/adapters/webservices/-02-18-2015 08:14:20.637 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/streaming/STREAMING-1_0/lib/jre02-18-2015 08:14:20.637 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/streaming/STREAMING-1_0/lib/jre/-02-18-2015 08:14:20.638 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/data_streaming/adapters/default02-18-2015 08:14:20.638 INFO [main] (DirectorySandbox$StreamingPolicy.addPermissions) /hana/shared/K9G/data_streaming/adapters/default/-02-18-2015 08:14:20.711 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ...02-18-2015 08:14:20.714 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.02-18-2015 08:14:20.790 INFO [main] (AdapterController.init) Address 10.97.17.175:19082 is used to accept the control command.02-18-2015 08:14:20.834 INFO [main] (AdapterController.sendCommand) start /hana/shared/K9G/streaming/STREAMING-1_0/adapters/framework/instances/file_csv_input/adapter_config.xml02-18-2015 08:14:20.906 WARN [main] (AdapterController.executeStart) Another adapter framwork is running whose enviroment variable $STREAMING_HOME value is different with current instance. Please set enviroment variable of $STREAMING_HOME with same value!Seems like there is another instance of the adapters running. I copied the code in a different project and ran that but even the new project also has the same problem. Let me know what should be done to get rid of this problem.Regards,Subhankar", "views": "178", "answers": 0, "author": "Subhankar Chattopadhyay", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-02-17 12:42:00", "resolve": false, "uid": "133", "title": "SAP HANA Output Adapter requires an ODBC connection to function?", "url": "http://scn.sap.com/thread/3699027", "text": "Hi,Version ESP SP08 latest PL (but same in SP09).Version: 5.1.08.04/20150106.1/SP08 PL04/winnt/x86_64/64-bit/OPT/Tue, Jan 06, 2015 8:35:48 PM What is required to be able to connect to HANA with the HANA output adapter?The SP08 Manuals says:Make sure that the Data Service has the ODBC Driver Library set correctly. Always use esp_db_odbc_lib for Windows (regardless of version). On other platforms, use esp_db_odbc64_lib if you are working with the HANA adapter. If not, the choice of driver library depends on the size of SQLLEN in the driver manager. If SQLLEN is 4 bytes, use esp_db_odbc_lib. If SQLLEN is 8 bytes use esp_db_odbc64_lib.6.2 Loading a Data ServiceHowever when I use esp_db_odbc_lib I'm gettin a architexture mismatch error from WindowsWith esp_db_odbc64_lib the generic db_in and db_out seem to work but the HANA output adapter gives error:>>>| 3580 | container | [SP-3-148011] (2.182) sp(4952) ConnectionWriter(HANA_Output1) connection reset error: 2015-02-17 09:49:30 The service name in the adapter properties is not configured as an ODBC service. The SAP HANA Output Adapter requires an ODBC connection to function.Unable to get connection to the database.<<<What could be the problem of this error message?", "views": "272", "answers": 3, "author": "Ben Pluijm", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-02-17 15:14:00", "resolve": "", "uid": "133.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3699027", "text": "Do you have the HANA database client installed on the ESP server and an ODBC connection defined?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP HANA Output Adapter requires an ODBC connection to function?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "133.2", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3699027", "text": "Yes,The generic db_in and db_out database adapters are able to conect using the same odbc DSN, butnot the HANA output adapter ; that fails.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP HANA Output Adapter requires an ODBC connection to function?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "133.3", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3699027", "text": "Which version of the HANA Client do you have installed? The 64-bit version or the 32-bit version?It is important that the HANA Client version matches your ESP install version in terms of being 64-bit or 32-bit. Basically the 64-bit version of ESP can't work with a 32-bit DSN and a 32-bit version of ESP can't work with a 64-bit DSN. In testing this, I initially had the 32-bit HANA ODBC driver and 64-bit ESP, which wouldn't work. After installing the 64-bit HANA Client and creating a 64-bit DSN using the Windows ODBC Administrator 64-bit, then I was fine. Interestingly, either version of the Driver Library worked - esp_db_odbc_lib or esp_db_odbc64_lib worked for Discovery once I was using a 64-bit DSN.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP HANA Output Adapter requires an ODBC connection to function?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-01-20 22:29:00", "resolve": false, "uid": "134", "title": "Exception using .Net SubscriberCallback Example", "url": "http://scn.sap.com/thread/3683623", "text": "Hi,I tried the SubscriberCallback Example for .Net. When I run the compiled program, it subscribes to the data, sends it to the screen, waits the number of seconds in the Thread.Sleep. Then when it hits the finally of the try/catch/finally, there is an exception on rc = s_sdk.stop(espError); When I comment this line out, the exception goes away.I wanted to use the example as a basis for something I was developing. To that end, it would be nice if this example worked more like esp_subscribe or like the java example.VS 2010ESP 5.1 SP08Win 7 64 bitCompiling for 64 bit executable.Thank you,David", "views": "507", "answers": 3, "author": "David Rosenblum", "upvotes": 0, "type": "question", "tags": "esp_5.1"},
{"date_time": "2015-01-26 16:11:00", "resolve": "", "uid": "134.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3683623", "text": "Hi David,I've reproduced this issue and am investigating. I'll post back here when I've got an update.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Exception using .Net SubscriberCallback Example", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "134.2", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3683623", "text": "Hi David,This should eliminate the exception:After thesubscriber.disconnect(espError);Add:subscriber.close(espError);Thread.Sleep(1000);// must do sleep here, otherwise the subscriber callback routine may not have enough time to closeRegarding the suggestion for providing an example that worked more like esp_subscribe or like the java example, please contact Jeff Wootton.Thank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Exception using .Net SubscriberCallback Example", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "134.3", "author": "David Rosenblum", "url": "http://scn.sap.com/thread/3683623", "text": "While this may help with the example, we are still getting an exception with this addition in our code.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Exception using .Net SubscriberCallback Example", "type": "answer", "tags": "N/A"},
{"date_time": "2015-02-25 18:16:00", "resolve": true, "uid": "135", "title": "How do I use the streamingupgrade utility", "url": "http://scn.sap.com/thread/3703666", "text": "ENV: ESP 5.1 SP09 PL 00 on Win 7 64 bit. Upgraded from SP08.These are the steps I have tried so far.The Release Guide says to use streamingupgrade, but when I check the utilities guide, the utilities guide says6.2 streamingmigratedatetypeUse this command-line utility to migrate CCL files from ESP version 5.1 SP08 and earlier.Syntaxstreamingmigratedatetypes -i <input CCL File> -o <output CCL File>But that isnt the executable name. Is that the correct usage? When I try to use the name that exists streamingupgrade , nothing happens, it appears to be waiting for some input.C:\\software\\sybase\\ESP-5_1\\bin>streamingupgrade -i C:\\Users\\xxxx\\Documents\\SybaseESP\\5.1\\workspace\\PortfolioValuation\\PortfolioValuation.ccl I was able to get the -v option to work. I also tried to cd to \\software\\sybase\\ESP5.1\\bin and run from there, same results. C:\\Users\\xxxx\\Documents\\SybaseESP\\5.1\\workspace\\PortfolioValuation>%ESP_HOME%\\bin\\streamingupgrade -vSAP Event Stream Processor Upgrade 5.1.09.00/20141116.1/SP09 PL00/winnt/x86_64/64-bit/OPT/Sun, Nov 16, 2014 5:54:00 PMCopyright 2014 SAP AG or an SAP affiliate company. All Rights Reserved.No part of this publication may be reproduced or transmitted in any formor for any purpose without the express permission of SAP AG. Theinformation contained herein may be changed without prior notice.", "views": "239", "answers": 1, "author": "David Rosenblum", "upvotes": 0, "type": "question", "tags": "sps_09"},
{"date_time": "2015-02-26 16:29:00", "resolve": "solution", "uid": "135.1", "author": "Alex Wilson", "url": "http://scn.sap.com/thread/3703666", "text": "streamingmigratedatetypes and streamingupgrade are different utilities. Is streamingmigratedatetypes.exe not in your %STREAMING_HOME%\\bin directory?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How do I use the streamingupgrade utility", "type": "answer", "tags": "N/A"},
{"date_time": "2015-02-26 15:02:00", "resolve": false, "uid": "136", "title": "How to RFC with both import- and export-parameters?", "url": "http://scn.sap.com/thread/3704250", "text": "Hello,we are at a point where we want to use a ERP-RFC witch hast some import- and export-parameters.The import-parameters coming from a stream, shoud be transported to ERP and the results shoud be published in a nother stream.Lets take the RFC \"stfc_string\" for example:CALL FUNCTION 'STFC_STRING' \"EXPORTING question = \" string IMPORTING myanswer = \" string . \" STFC_STRINGWe already managed export a static value to ERP with a import-adapter and publish the export-parameter to a stream. That works fine.(..\\adapter\\rfc\\example\\polling_import\\..)mapping.xml:<rfc name=\"STFC_STRING\">  <input>  <import>  <parameter name=\"QUESTION\">How are you</parameter>  </import>  </input>  <mapping>  <export>  <fieldMapping name=\"MYANSWER\" espField=\"MYANSWER\"/>  </export>  </mapping> </rfc>And to export a dynamic value from a stream to ERP with a output-adapter.(..\\adapter\\rfc\\example\\output\\..)So how can we use a value from a stream, export it to a ERP-RFC and get the export-parameters from this RFC in ESP?like: stream1 -> ERP -> stream2 import exportI hope you can help me a bit.With kind regardsMatthias", "views": "308", "answers": 2, "author": "Matthias Hanel", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-03-02 06:51:00", "resolve": "", "uid": "136.1", "author": "Kim Choy", "url": "http://scn.sap.com/thread/3704250", "text": "Hi Matthias,What you are describing cannot be done over a single RFC, as the data flow between the stream and RFC adapter is only one-way, for output adapter it is from the stream to adapter. The export parameters it receives from an RFC does not percolate back to the stream.You can try break it up into two RFCs such that an output adapter would push data from stream1 to the ERP, and have the result stored in ERP. Then have an input adapter invoke another RFC to retrieve the result from ERP to stream2.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to RFC with both import- and export-parameters?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "136.2", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3704250", "text": "Hi Matthias,It would be interesting to get a better idea of what you are trying to do here. What's the use case?Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to RFC with both import- and export-parameters?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-03-09 12:38:00", "resolve": true, "uid": "137", "title": "streaming and multitenancy", "url": "http://scn.sap.com/thread/3709304", "text": "hii am thinking about using a Streaming architecture for multiple Clients.does ESP and/or Hana Streaming Function Support multiple Clients (Multitenancy as in the hana database)?is there any related documentation on this ?many thanksjoerg", "views": "355", "answers": 1, "author": "J\u00f6rg Knaus", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-03-09 12:42:00", "resolve": "solution", "uid": "137.1", "author": "Pauli Gandhi", "url": "http://scn.sap.com/thread/3709304", "text": "SDS currently does not support multi tenancy. Although, we are actively working on supporting multi- tenancy.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:streaming and multitenancy", "type": "answer", "tags": "N/A"},
{"date_time": "2015-02-26 17:55:00", "resolve": false, "uid": "138", "title": "Error starting Streamingstudio", "url": "http://scn.sap.com/thread/3704398", "text": "When I started streaming studio I get an error.An error has occurred. See the log fileC:\\Users\\xxxx\\My Documents\\SybaseESP5.1\\workspace\\.metadata\\.log", "views": "271", "answers": 3, "author": "David Rosenblum", "upvotes": 0, "type": "question", "tags": "esp_studio"},
{"date_time": "2015-03-04 21:28:00", "resolve": "", "uid": "138.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3704398", "text": "This would appear to be the key information in the log file:___________________!ENTRY org.eclipse.core.resources 2 10035 2015-02-26 11:42:02.801!MESSAGE The workspace exited with unsaved changes in the previous session; refreshing workspace to recover changes.___________________Has the issue persisted, or has it been resolved?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error starting Streamingstudio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "138.2", "author": "David Rosenblum", "url": "http://scn.sap.com/thread/3704398", "text": "Occasionally it happens, and it has been happening since ESP began. There was a trick, a line to put in a file to flush things so that it doesn't happen, but I don't remember what that was.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error starting Streamingstudio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "138.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3704398", "text": "Hi David,I think the \"trick\" you were referring to is to add the -clean option to the studio ini file. The -clean option is now part of the installed ini file.Is the Studio you are using a new installation of Studio that is using workspaces/projects from a previous installation of Studio? Sometimes this is the cause of what you are experiencing.You might want to move the workspaces/projects away and then import the ones you need, like so:1 - exit from the Studio application2 - rename your C:\\Users\\xxxx\\My Documents\\SybaseESP5.1\\workspace directory to something like C:\\Users\\xxxx\\My Documents\\SybaseESP5.1\\workspace-bak3 - open Studio - this will cause a brand new workspace directory to be created4 - import your project(s) into the (new) workspace from the old workspace-bak directory - instructions for how to do this are here: Importing Multiple Projects - SAP Event Stream Processor: Studio Users Guide - SAP LibraryThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Error starting Streamingstudio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-03-11 17:48:00", "resolve": true, "uid": "139", "title": "esp_studio fails silently and won't open", "url": "http://scn.sap.com/thread/3710946", "text": "ESP SP08 Win7 x64Worked yesterday, applied Microsoft patches last night, now it won't open and fails silently.Should I be able to see something in C:\\Users\\rosenblum\\Documents\\SybaseESP\\5.1\\workspace\\.metadata\\.log ?Any ideas?Eclipse Kepler still works fine.I will reinstall and see if that fixes anything.", "views": "603", "answers": 1, "author": "David Rosenblum", "upvotes": 0, "type": "question", "tags": "esp_studio"},
{"date_time": "2015-03-11 20:01:00", "resolve": "solution", "uid": "139.1", "author": "David Rosenblum", "url": "http://scn.sap.com/thread/3710946", "text": "Wiped my workspace and reinstalled, now it works again.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:esp_studio fails silently and won't open", "type": "answer", "tags": "N/A"},
{"date_time": "2015-03-14 15:21:00", "resolve": false, "uid": "140", "title": "Comparsion of VC objects between systems", "url": "http://scn.sap.com/thread/3712428", "text": "Hi all,I have a small request, Is there any way we can compare VC objects between different systems (Development & Production)..The aim is to make sure all the developed VC objects are moved to Production systems without fail on their Release Date.Thanks!Br,Vignesh", "views": "212", "answers": 1, "author": "vignesh ram", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-03-16 15:05:00", "resolve": "", "uid": "140.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3712428", "text": "Did you mean to post this in the Smart Data Streaming developer center? What are \"VC objects\"? Perhaps this quesiton was intended for a different forum", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Comparsion of VC objects between systems", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-01 02:02:00", "resolve": false, "uid": "141", "title": "I cant run wsp.bat", "url": "http://scn.sap.com/thread/3721147", "text": "hi!!i have this error when i try run wsp.batCould you please help me to solve the problem", "views": "339", "answers": 3, "author": "Antonio de Jes\u00fas Flores Olivares", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-04-01 09:49:00", "resolve": "", "uid": "141.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3721147", "text": "Hi,You are getting net bind errors because the sockets are already in use.It will try to use following ports according to the xml file:Starting the ESP Web Service Provider and configuring the SOAP server and REST server...Set the WebSocket connector port: 9092Set the SOAP connector protocol and port: http, 9090Set the REST connector protocol and port: http, 9091Check for example with \"netstat -ao\" which proces has these ports in use and stop those.It could also be that you are trying to start it for the second time whie the first one is still running.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:I cant run wsp.bat", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "141.2", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3721147", "text": "thank you Ben, i have identifed a port used by other program, i have changed this port and ready!", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:I cant run wsp.bat", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "141.3", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3721147", "text": "Great.It might also be possible to change the ports ESP is using by changing the xml files and redeploy.But if it works, then it works,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:I cant run wsp.bat", "type": "answer", "tags": "N/A"},
{"date_time": "2015-03-23 17:48:00", "resolve": false, "uid": "142", "title": "project.get_model_stream_names(streamingError) throws exception", "url": "http://scn.sap.com/thread/3716796", "text": "Hi,I am looking for some guidance here.Win 7 x64 , ESP SP08. .Net SDKI connect to ESP using Direct Access (will Callback help?).I then connect to a project/workspace like this project = server.get_project(workspace, projectName, projoptions, streamingError); if (project != null) { rc = project.connect(streamingError); if (rc != 0) { msgText.Text = msgText.Text + \"Project \" + projectName + \" \";  print_error_and_exit(streamingError); } else { msgText.Text = msgText.Text + \"Project Connected\" + Environment.NewLine; isConnected = true; Thread.Sleep(1000); } } else { msgText.Text = msgText.Text + \"Project \" + projectName + \" \"; print_error_and_exit(streamingError); }If I leave out the thread sleep in red above the call below throws an exceptionmodelstreamnames = project.get_model_stream_names(streamingError);How do I know how long to wait before calling get_model_stream_names?Should I use the Project Callback and wait for a specific event?", "views": "236", "answers": 2, "author": "David Rosenblum", "upvotes": 0, "type": "question", "tags": "esp_5.1"},
{"date_time": "2015-03-24 16:15:00", "resolve": "", "uid": "142.1", "author": "Shubhra Biswas", "url": "http://scn.sap.com/thread/3716796", "text": "You shouldn't need to wait at all. In direct access mode, once connect returns successfully you should be able to get the stream names. Could you verify that you indeed are connecting in direct mode? If yes then this could be a bug and we will need to investigate.Do you have the details of the exception thrown? Best regards,Shubhra Biswas", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:project.get_model_stream_names(streamingError) throws exception", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "142.2", "author": "David Rosenblum", "url": "http://scn.sap.com/thread/3716796", "text": "If I post an example, will you look at it? I would rather send you a link.The entire .Net Project?Let me know.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:project.get_model_stream_names(streamingError) throws exception", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-01 16:32:00", "resolve": true, "uid": "143", "title": ".Net-Subscriber on studio local cluster", "url": "http://scn.sap.com/thread/3721684", "text": "Hello,I want to test the event stream processor with the .NET SDK. Therefore I simply used a .NET-Subscriber like the example code.I also would like to run the project only on the studio local cluster (so only over the localhost). To get connection to the project with my .NET programm I have to choose the name of the used workspace, but the localhost doesn't seems to have a workspace. Or I don't recognised them. So here's my question:Does the localhost have an standard workspacename or can I get connection to the esp project with the .Net SKD without the workspace?", "views": "759", "answers": 4, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-04-01 22:06:00", "resolve": "", "uid": "143.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3721684", "text": "Hello,If you run the project in the studio's local cluster, what do you see in the Server view of the Run-Test perspective? You most likely are using the default workspace name, which is \"default\", similar to this snapshot:", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net-Subscriber on studio local cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "143.2", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3721684", "text": "Hello Alice,thank you for your fast answer .By me it looks like this:So I would say I don't have a workspace, right?Is there a possibility to add one for the localhost with HANA Studio or does I need to add them via commandline with the streamingclusteradmin tool?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net-Subscriber on studio local cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "143.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3721684", "text": "Hi Stefan,Yes, correct, you do not have a workspace since you are using HANA Studio.It is no longer possible to start and run a local ESP cluster from HANA Studio (since ESP 5.1 SP09). You can use the ESP Studio if you want to start and run a local ESP cluster.Otherwise, as you said, you would need to add a workspace and the project to a remote (non-studio) cluster via the commandline using the streamingclusteradmin tool.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net-Subscriber on studio local cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "143.4", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3721684", "text": "Hi Alice,thank you ver much. While using the ESP Studio my problem is resolved!", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.Net-Subscriber on studio local cluster", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-11 09:30:00", "resolve": false, "uid": "144", "title": "RFC Output adapter not executing the RFC", "url": "http://scn.sap.com/thread/3726123", "text": "Hi,I am trying to use a \"RFC Output adapter\" to call a Function Module in the R/3 system and right now I have no clue why its not working ! Here is my model,The schema discovery worked and from there I was able to pick the RFC from the r/3 system, which then created mapping files. I also added the import variables to it.Then, I compiled the project without any errors, and when I executed the project it went to the SAP ESP Run-Test perspective and this is what I see,Every time I right click on the SAP RFC adapter and start it, the state change from READY-> CONTINUOUS->DONE->DEADTried putting a external break point in ABAP prog to see if the program is being called. But the control is not coming that far.I do not see any log written! Could you please suggest where I could be going wrong. Thanks,Suresh", "views": "251", "answers": 0, "author": "Suresh Devaiah", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-03-18 01:05:00", "resolve": false, "uid": "145", "title": "credentials ESP in Design Studio", "url": "http://scn.sap.com/thread/3714119", "text": "when i write the credentials for use a ESP Datasource show Error Network or NOt Found, the host and port is localhost:9786 the same that show in ESP, the credentials are the same that i wrote in the installation", "views": "1154", "answers": 16, "author": "Antonio de Jes\u00fas Flores Olivares", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-03-18 14:38:00", "resolve": "", "uid": "145.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3714119", "text": "Hello,Beginning with ESP version 5.1, SP09, the Event Stream Processor plugin for SAP HANA Studio does not have the capability to start and run a local ESP cluster. In order to run an ESP project from the SAP HANA studio, you must be connected to an ESP remote cluster. With the standalone ESP Studio, you still have the ability to start and run a local cluster, but you cannot configure the local cluster for a remote connection.(This is a Known Issue, see Known Issues for SAP Event Stream Processor Studio - SAP Event Stream Processor: Release Notes for Windows - SAP Library.)Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.2", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3714119", "text": "Hi Alice,i have a local cluster, I don't use Hana the design studio and ESP are installed in my laptop", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3714119", "text": "Hi Antonio,There's a bit more set-up required to connect to an ESP project from Design Studio. It looks like you are using the ESP server started by the Studio. This is generally not recommended, as it is intended to be a sandbox used to easily test projects from the studio, but by default it doesn't allow external connections. You can, however, change that: in the Server View, in the run test perspective, right click on the local cluster and change the password. User will always be \"Studio\". You can then use these credentials to connect.But you also need to be running the ESP Web Service Provider, which you will need to start from the command line - see the Adapters guide for instrucitons. And it will probably be more complicated to configure this to connect to the Studio cluster than just starting a \"proper\" ESP cluster from the command line. and then start WSP.Also note that your ESP project needs to have the \"Enable Web Services\" property set. I'll see if we can get some instructions together - I didn't realize that they hadn't been published. Jeff", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.4", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3714119", "text": "Hello,At this page: Official Product Tutorials  SAP BusinessObjects Design Studio 1.x Have a look at the demo for:NEW for 1.4 Connect to a streaming data source Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.5", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3714119", "text": "i change the password i connect the server and Run ESP project(local Cluster)and I try connect with this, but show \"Error: Not Found\"", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.6", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3714119", "text": "Did you also start the Web Service Provider on the ESP server?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.7", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3714119", "text": "could you say me how i can do this? please", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.8", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3714119", "text": "Hi Antonio,Look here for how to do this:Exposing a Project as a Web Service Using the Web Services Provider - SAP Event Stream Processor: Studio Users Guide - S", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.9", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3714119", "text": "I enabled the web service in Advanced tab, but i cant connect", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.10", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3714119", "text": "It sounds like you still need to start the Web Service Provider itself. The WSP supports SOAP, REST and Websocket connections. Details are in the SAP Event Stream Processor: Adapters Guide. I haven't had a chance to look at which of those protocols Design Studio is specifically using, but there are basic instructions on starting the WSP in the \"Configuring the SAP Event Stream Processor REST Provider\" section:Configuring the SAP Event Stream Processor REST Provider - SAP Event Stream Processor: Adapters Guide - SAP Library", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.11", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3714119", "text": "i running the wsp_deploy.bat and the bat created http://localhost:9090/espws/services/wsplocalhost9786_default_WSPtowermon3iwWeatherStationReference?wsdl but , i cant connect the SAP Design Studio with the cluster of ESP Studio", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.12", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3714119", "text": "any suggestion more?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.13", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3714119", "text": "Try testing your ESP configuration without Design Studio. This can narrow down the problem to help you know if it's with the ESP setup or with the Desing Studio set up.For example use the \"Advanced REST client\" extension for Google Chrome to try to send an event to an ESP Project via HTTP. If it works, then you know that ESP WSP is working properly and credentials are set up properly - so issue is probably with the Design Studio configurtion.If you send me an email, I can send a short doc that has detailed instructions on setting up WSP and testing it with the Google Chrome extension.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.14", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3714119", "text": "Hi Antonio,You mentioned earlier that you are running wsp_deploy.bat. Please try with running wsp.bat instead.Also, make sure that you have edited the wsp.xml in the <DefaultCluster> section to use 9786 for the <port> setting (since you are using the ESP Studio to run the project, and that uses port 9786), and <SslEnabled> needs to be set to false (since your project is running in \"esp://<server>:<port>\" and not \"esps://<server>:<port>\").Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.15", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3714119", "text": "i still having problems", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "145.16", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3714119", "text": "I'm afraid at this point I would suggest that you open a support case via customer support. It doesn't look like the community is going to be able help you troubleshoot this via the forum.Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:credentials ESP in Design Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-08 09:08:00", "resolve": true, "uid": "146", "title": "SAP RFC Output Adapter Error.", "url": "http://scn.sap.com/thread/3724343", "text": "Hi,I am new to ESP, and trying to call a function module from ESP to write data to R3. Initially I was getting some errors related to JCO connector which I was able to fix using some information given in another thread.Now I am facing a different issue when I tap on the schema discovery button, (Attached the screenshot) Please let me know if you have an answer for this.Regards,Suresh", "views": "615", "answers": 6, "author": "Suresh Devaiah", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-04-08 09:37:00", "resolve": "", "uid": "146.1", "author": "Krishnaiah Kammari", "url": "http://scn.sap.com/thread/3724343", "text": "Hi Suresh,could you please provide the more details to look into this. Regards,Krishna", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP RFC Output Adapter Error.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "146.2", "author": "Suresh Devaiah", "url": "http://scn.sap.com/thread/3724343", "text": "Hi Krishna, Thanks for looking into this. Here is the complete model,What I am trying to do here is, from the CSV file get the sensor ID and sensor value, then filter it out to get those sensor values which are greater than 20 and execute the RFC output adapter.I have put in the required config and mapping files and all other details (which I have removed here)Now when I tap on the schema discovery button I get the above error.The ESP server is running locally on my laptop and R/3 system is on another server.Let me know if you need any other information.Regards,Suresh", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP RFC Output Adapter Error.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "146.3", "author": "Krishnaiah Kammari", "url": "http://scn.sap.com/thread/3724343", "text": "Hi Suresh,Have you created any RFC for ESP server in R/3 system? Please check and let us know.Regards,Krishna", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP RFC Output Adapter Error.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "146.4", "author": "Suresh Devaiah", "url": "http://scn.sap.com/thread/3724343", "text": "Hi Krishna, Yes, the RFC is in the R/3 system.I was able to solve the problem. In the RFC adapter settings I was not providing the full path of the server and hence it was not working. Thanks,Suresh", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP RFC Output Adapter Error.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "146.5", "author": "Krishnaiah Kammari", "url": "http://scn.sap.com/thread/3724343", "text": "Hi Suresh,Thank you very much and great to hear .Regards,Krishna", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP RFC Output Adapter Error.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "146.6", "author": "Claudia Gosav", "url": "http://scn.sap.com/thread/3724343", "text": "Hi Suresh,Could you please clarify which setting you did not specify a full path in? And was it in the Studio or within the adapter configuration file?For example, here are topics for configuring the adapter to run in unmanaged mode (starts/stops with the project):http://help.sap.com/saphelp_esp_51sp09_adapt/helpdata/en/e7/84df616f0f1014b1aeea1117e5a178/content.htm?frameset=/en/e7/74b2646f0f1014a48c9dfaf12c5d85/frameset.htm&current_toc=/en/e7/74b2646f0f1014a48c9dfaf12c5d85/plain.htm&node_id=469and managed mode (starts/stops on separately from the project):http://help.sap.com/saphelp_esp_51sp09_adapt/helpdata/en/e7/8afd746f0f1014a566bad1ea5ca819/content.htm?frameset=/en/e7/74b2646f0f1014a48c9dfaf12c5d85/frameset.htm&current_toc=/en/e7/74b2646f0f1014a48c9dfaf12c5d85/plain.htm&node_id=472&show_children=falseI want to make sure that the docs are clear on this.Thanks,Claudia", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP RFC Output Adapter Error.", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-15 16:32:00", "resolve": false, "uid": "147", "title": "Smart Data Streaming Roadmap", "url": "http://scn.sap.com/thread/3728057", "text": "Where will I find a roadmap for HANA SDS? I looked under HANA roadmaps and ESP roadmaps.Thank youDavid", "views": "311", "answers": 2, "author": "David Smith", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-04-15 17:45:00", "resolve": "", "uid": "147.1", "author": "Deepak Chodha", "url": "http://scn.sap.com/thread/3728057", "text": "Hi David,Thanks for posting but for external communities we don't have specific component since SDS is now an integral part of SAP HANA. However you will find few liners about SDS in SAP HANA roadmap.Happy HANA, Deepak.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming Roadmap", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "147.2", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3728057", "text": "Hi David,Smart Data Streaming and Event Stream Processor continue to be developed together, including new feature development. Detailed roadmap information for both product packages is covered in the current (2015Q1) published SAP Event Stream Processor roadmap available at: https://websmp201.sap-ag.de/~form/handler?_APP=00200682500000002672&_EVENT=DISPLAY&_SCENARIO=01100035870000000122&_HIER_Page 19 of the SAP Event Stream Processor roadmap doc discusses the relationship between SDS and ESP including these points:Beginning with SP09, we now deliver the core event stream processing capabilities of SAP ESP in two different product packagesSame engine and cluster framework in bothIdentical feature set at the project level  though longer term smart data streaming is expected to leverage additional HANA features", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming Roadmap", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-23 08:44:00", "resolve": false, "uid": "148", "title": "Getting error \"internal error\" while starting esp sdk(c) using \"esp_sdk_start\"", "url": "http://scn.sap.com/thread/3731917", "text": "I am getting error \"internal error\" while starting esp sdk(c) using \"esp_sdk_start\". This is not repeating each and every time. This is happening occasionally. I need to know what may be the reason for this.", "views": "228", "answers": 0, "author": "Suhas Yalgude", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-04-24 11:40:00", "resolve": true, "uid": "149", "title": "Average", "url": "http://scn.sap.com/thread/3732661", "text": "Hi,I am using a Window which keeps 5 rows with one field called 'Value\". Is there a way I can take the average of these five values and pass it to the next stream?Regards,Suresh", "views": "299", "answers": 2, "author": "Suresh Devaiah", "upvotes": 1, "type": "question", "tags": ""},
{"date_time": "2015-04-24 12:21:00", "resolve": "solution", "uid": "149.1", "author": "Pauli Gandhi", "url": "http://scn.sap.com/thread/3732661", "text": "You can just aggregate by a dummy constant to group all the rows. For exampleCREATE INPUT WINDOW In1 SCHEMA (Value integer) PRIMARY KEY (Value) KEEP ALL;CREATE OUTPUT WINDOW AvgPRIMARY KEY DEDUCEDKEEP ALLAS SELECT 1 DummyKey, avg(In1.Value) AvgVal FROM In1 GROUP BY 1;", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Average", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "149.2", "author": "Suresh Devaiah", "url": "http://scn.sap.com/thread/3732661", "text": "Thanks", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Average", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-28 16:07:00", "resolve": false, "uid": "150", "title": "ESP project enabled as web service: Invalid Connection Detail", "url": "http://scn.sap.com/thread/3734340", "text": "Hello Colleagues, I am just starting with ESP. I tried the example on the help protal (Example: Sending a JSON Request Using a REST Web Service Client - Adapters Guide - SAP Library), which is only to create a project with an input window, enable the project to be web-service, start the service, and then send a POST request to push one row into the table. Service is started: http://localhost:9090/espws/services/ESPWebService?wsdlBut retrieving metadata from or sending JSON request to the web service both failed with '400 Invalid Connection Detail' error. This is the POST request header I send to get metadata:http://localhost:9091/espws/restservice/stream/window1?action=get&workspace=default&project=rest_json_01And the request body:{ \"connectionDetails\": { \"clusterName\": \"localhost\", \"port\": \"19011\", \"authentication\": { \"type\": \"user\", \"data\": \"username:password\", \"sslEnabled\": \"true\" } }}I have been struggling with this for a couple of days now. Did I use the correct credentials, what \"username/password\" shall be used? Could you please help me to make this work?Thanks a lot for your help. Best regards,Tao", "views": "471", "answers": 4, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-04-28 23:06:00", "resolve": "", "uid": "150.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3734340", "text": "If you are trying to retrieve the metadata for the project then you need to use a GET instead of a POST:View the Metadata of a Project - Adapters Guide - SAP LibraryThat contrasts with inserting an event to a stream where you would use a POST method. To make it a little simpler to test the initial connection, I would suggest just trying to get a list of the workspaces in the project:View a List of Workspaces in a Cluster - Adapters Guide - SAP LibraryMake sure you use the Base64 encoded version of your own user name and password.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project enabled as web service: Invalid Connection Detail", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "150.2", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3734340", "text": "Hello Robert,thanks a lot for spending time analyzing the problem with me. I finally got it working. Just like you suggested, I changed the port in connectionDetails to '9786', and user data un-encoded.Although, it is still confusing to me what port number to be used in the connectionDetails. And, isn`t it unsafe to send credentials un-encoded?Anyway, I am happy to have a running web-service, however simple it is.Thanks again,Tao", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:ESP project enabled as web service: Invalid Connection Detail", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "150.3", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3734340", "text": "Hi Tao,Yes you should definitely encode the credentials in a production environment. Starting with the unencoded credentials makes the initial configuration and testing easier while working in your development environment. Note that ESP and Smart Data Streaming both support granular user permissions. For example you can create a user that only has permissions to insert events to a single stream. Take a look at the Cluster Administration Tool as the starting point for understanding user permissions:Cluster Administrative Tool - SAP Event Stream Processor: Configuration and Administration Guide - SAP Library", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project enabled as web service: Invalid Connection Detail", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "150.4", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3734340", "text": "Thanks, very helpful!Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP project enabled as web service: Invalid Connection Detail", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-30 08:06:00", "resolve": false, "uid": "151", "title": "how to arrange function point into ccl file in ESP?", "url": "http://scn.sap.com/thread/3735358", "text": "hello everyone: I have questions to ask. In a ESP project ,we develop many function point in a project ,whether we can place all function points into one ccl file. In this way above, what problems are existed ? If there are problems ,how can we resolve them? This is an another question? what is the best practice in developing CCL project?", "views": "439", "answers": 6, "author": "zhang xiao", "upvotes": 0, "type": "question", "tags": "cep.esp_developer"},
{"date_time": "2015-04-30 15:34:00", "resolve": "", "uid": "151.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3735358", "text": "I'm not quite sure what you mean by function points - whether your are referring to user-defined functions or stream/window operators. But either way:- you can define custom functions in CCL using CCL Script- these function definitions can be in the main project ccl file or they can be in one or more ccl files that get imported- the same can be true for stream/window operators or modulesSo in building a streaming project, while you can have everything in one CCL file, for largeer projects, or where you have re-use between projects, it can be useful to break the project out into multiple CCL files and use the CCL IMPORT statement to include other CCL files into the main project file.Modules and functions are excellent candidates for re-use: you can define re-usable functions and modules in one or more ccl files that are then shared among multiple projectsIn terms of \"best practices\", it really doesn't matter what approach you take: it's really just structuring your projects in a way that makes them easy for you to manage.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:how to arrange function point into ccl file in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "151.2", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3735358", "text": "Hi,The term function point might be a term from the \"custom application development industry\" here.It is sort of a unit of work or task indicating estimated amount of work and complexity of the application, i.e. it will take 5 fp's to implement this feature and 3 fp's to implement that feature. Function Point analysis would then give an indication how much would be required to develop an application and could also be used to compare tools (showing if an application would be easier to implement in this tool that in that tool). The term might be more closer to the term \"man hour\" but is more oriented towards describing the task with it's complexity and size to be done than to the amount of time to be spent.If a large project is being developed, putting everything in one large .ccl file doesn't look the way to go. ESP has modules, my preference would be a logical partitioning that also allows the modules to be separately tested\\developed. But it is also lean developed like in RAD. Developing a large framework in ccl does not look appealing either, and not just for efficiency, might be a trap one can fall into.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:how to arrange function point into ccl file in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "151.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3735358", "text": "Thanks Ben - that's good insight. And after reading your comments, one other thing occurred to me to mention:Beyond breaking a large project up into multiple CCL files, for very large projects you may also want ot consider implementing them as a \"network\" of projects rather than a single project.Let me explain:Above, Ben and I were focused on the ability to define blocks of CCL in several different files that are then combined into a single project at compile time using the CCL IMPORT statement. This is very useful for maintainability of the source, for re-use across projects, and for team development. But it still results in a single, large project.You also have the ability with SDS and ESP to run multiple projects that interconnect using bindings: an input on a project gets \"bound\" to the output of another project. This has several benefits:- A single project runs on a single host. The project is thus constrained by the capacity of the host. Whereas projects can bind across machien boundaries - so if a project is running up against the capacity of a host, you can break the project into two or more inter-connected projects and run them on a multi-node cluster, with each project running on a different host in the cluster. - You also have the ability to stop/start/restart individual \"sub-projects\" (though take care that you understand the impage this will have on the connected project(s) that will still be running", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:how to arrange function point into ccl file in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "151.4", "author": "zhang xiao", "url": "http://scn.sap.com/thread/3735358", "text": "Thank you very much.But I also have a question.In a project ,I define several ccl files, such as file1.ccl,file2.ccl,input.ccl and output.ccl. File1.ccl and file2.ccl import the input file.ccl . Output.ccl imports the file1.ccl and file2.ccl .In this situation, how to avoid redefinition", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:how to arrange function point into ccl file in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "151.5", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3735358", "text": "If you want to import a ccl file more than once into a project, then you need to create a module. Using the CCL CREATE MODULE statement, you can encapsulate a section of CCL within a module. The module can then be instantiated multiple times within the parent project.So what you describe above won't work without using modules, because if file1 and file2 both import input.ccl, and then are both imported by the same parent, you will now have duplication - i.e. in a CCL project all streams/windows need to have unique identifiers. But, if you enclose the contents of input.ccl within a module, and have file1 and file2 each create instances of the module (using different identifiers) then you can import both into output.ccl.", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:how to arrange function point into ccl file in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "151.6", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3735358", "text": "Perhaps provide your ccl and/or diagram of logic and data flow. It may help with determining alternatives.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:how to arrange function point into ccl file in ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-05-06 16:15:00", "resolve": true, "uid": "152", "title": "ESP Rest Provider, how to poll data from another web service?", "url": "http://scn.sap.com/thread/3737855", "text": "Hello colleagues, I have enabled a ESP project as a web service, with HTTP POST request, events are pushed into ESP (input_window_1). When specific event (for example, file download) occurs, I will need additional information from another web service (SRV2), data should be polled into input_window_2 and joined with input_window_1 on the same event. How do I achieve this, polling data from another web service, only when specific event occurs?I am still new on streaming, would be very grateful if a concrete example could be provided. Thanks a lot for your expertise. Regards,Tao", "views": "422", "answers": 7, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-05-06 17:42:00", "resolve": "solution", "uid": "152.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3737855", "text": "Hi Tao,I'm afraid right now there is not a way to do this - or at least not easily. There is no way, using our existing web service adapters, to do event-driven requests to the web service.You can use the Web Service input adapter to poll a web service on a scheduled basis and load the returned data into a CCL input window, where it is then available within your data model (eg you could join an incoming event to this window). But this probably won't help you if you need to poll the Web Service for data related to the event, and if the data set held by the web service is too large to pre-load into a CCL window.It is possible to do this if the data you needed was held in a database instead of a web service. The CCL getdata() function lets you run event-driven queries against an external ODBC or JDBC database. But we don't have the same thing for Web Services (or ODATA sources). If we saw a need for this, it could be added to the roadmap.Finally, to my earlier comment that there's no way to do it - at least not easily. There is one way, if you're a programmer. ESP does have an interface that lets you link external C++ or Java function libraries. You could write a C++ or Java function to call the web service and return the result, and then link this library to your CCL project and call the function from a CCL Flex operator. But clearly: this is a lot of work involved. Also note that the external function library interface in ESP is disabled by default, because it represents a security risk, but you can enable it and accept the risk, since you would be creating the external function. Also note that support for external function libraries is only available in ESP and is not available in HANA SDS (because of that security risk).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Rest Provider, how to poll data from another web service?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "152.2", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3737855", "text": "Hello Jeff, thank you, your reply is extremely helpful, as always. We are still prototyping, so I take your advise, create a table in HANA with the additional informations, and add a flex window with the CCL getdata() function. It works. I post my code here, could you please take a look if this is clean enough? In the case of assigning values to the outrecoutrec := [id = window1.id; ...]is there a simple way to assign all values of window1 to outrec, then plus the 2 new column values?Thanks and regards,TaoCREATE INPUT WINDOW window1 SCHEMA ( id long ,  pdf integer , url string ,  wma integer ) PRIMARY KEY (id) ;CREATE Flex pdf_flexIN window1OUT OUTPUT WINDOW window2 SCHEMA( id long ,  pdf integer ,  url string ,  wma integer , volume integer, price float) PRIMARY KEY (id)BEGIN DECLARE typeof(window2) outrec; typedef[integer pdf;|integer volume; float price;] datarec; vector(datarec) pdfdata; END; ON window1 { if(isnull(pdfdata)) pdfdata :=new vector(datarec);  if(window1.pdf=0 OR window1.pdf=2) { getData(pdfdata,'ana_odbc','select pdf, volumn, price from zhangta.pdfdata where pdf = ?',window1.pdf);  for(rec in pdfdata) outrec := [id = window1.id; pdf = window1.pdf; url = window1.url; wma = window1.wma; volume = rec.volume; price = rec.price]; output setOpcode(outrec,insert); }  else { outrec := window1; output setOpcode(outrec,insert); }  resize(pdfdata,0); };END;", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Rest Provider, how to poll data from another web service?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "152.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3737855", "text": "Hi Tao,Your question is great, but please do start a new thread so that others who are searching will be able to find it and follow it.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Rest Provider, how to poll data from another web service?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "152.4", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3737855", "text": "Hi Alice,thanks for the reminder. I will pay more attention to it in the future.Regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Rest Provider, how to poll data from another web service?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "152.5", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3737855", "text": "Your code looks fine (but I just gave it a quick look...). As for your question: is there a simple way of assigning all values of window1 to outrec and then adding the additional fields? sure. it's just like you did in the else statement. CCL will \"coerce\" the schema where it can. So just say:outrec := window1;outrec.volume := rec.volume;outrec.price := rec.price;output setOpcode(outrec, insert);", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Rest Provider, how to poll data from another web service?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "152.6", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3737855", "text": "Hi Jeff,I tried this syntax already, but got compiler error: no stream named rec.Regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Rest Provider, how to poll data from another web service?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "152.7", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3737855", "text": "Actually, after I posted my last reply, I realized that I was too focused on your specific question about how to set the values in outrec easily - and I missed a much bigger point (couldn't see the forest for the trees?).A much simpler, and more performant approach to what you want to do is just join window1 with a CCL REFERENCE element that points to your HANA table. This has a couple of benefits:1. it's simpler to set up than a flex - it's just a slightly modified SQL statement2. it will perform MUCH, MUCH better. Here's why:- getdata() will execute a query on HANA every time an event with pdf = 1 or pdf = 2 arrives. - the REFERENCE element has optional caching that will save the values retrieved from HANA and reuse them until they expire from the cache.Here, it looks liek you are only pulling two values from HANA - and you are probably using them for multiple events.If I get a chance later, I can show you a complete example, but it's basically just:CREATE REFERENCE X (point it to zhangta.pdfdata table in HANA)...<set your caching properties to on, and set an age as appropriate>CREATE OUTPUT WINDOW Window2...Select...From Window1 OUTER JOIN X where window1.pdf = x.pdf", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP Rest Provider, how to poll data from another web service?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-05-06 11:05:00", "resolve": true, "uid": "153", "title": ".net sdk for own adapter - problem with row.set_msdate", "url": "http://scn.sap.com/thread/3737634", "text": "Hello,I have a problem with the .net sdk for building an own adapter.I build a timestamp and now want to use the method \"row.set_msdate(...); to publish the date to esp and to get in into HANA\".Unfortunally I didn't find something about this method in the documentation.The method wants an parameter with an long value as timestamp value, but if I for Example write \"row.set_msdate(20150506, streamingError);\" then I got a strange date in the database. I also tried to use \"DateTime.Now.Ticks\" or \"DateTime.Now.ToFileTime\", but also no success to get todays date into the database.So my question is, how does the long value have to look to get the right date into the database?Thanks in AdvanceBest RegardsStefan", "views": "446", "answers": 3, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-05-06 16:30:00", "resolve": "solution", "uid": "153.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3737634", "text": "Hi Stefan,The value you would use would represent the total milliseconds since midnight, January 1, 1970 UTC.Try this:long now_msdate = (long)((DateTime.UtcNow - new DateTime(1970, 1, 1)).TotalMilliseconds);row.set_msdate(now_msdate, streamingError);Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.net sdk for own adapter - problem with row.set_msdate", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "153.2", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3737634", "text": "Hi Stefan,I logged Internal Incident 1570299347 to get this information added to the set_msdate() function's documentation and similarly to the other set_* functions (set_bigdatetime, set_msdate, set_seconddate, set_time, set_fixeddecimal).Thank you,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.net sdk for own adapter - problem with row.set_msdate", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "153.3", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3737634", "text": "Hi Alice,thank you, the two rows code solve my problem Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:.net sdk for own adapter - problem with row.set_msdate", "type": "answer", "tags": "N/A"},
{"date_time": "2015-05-07 17:58:00", "resolve": false, "uid": "154", "title": "Building windows based on timestamps", "url": "http://scn.sap.com/thread/3738520", "text": "Hi all,let's assume in an ESP scenario with guaranteed delivery/zero data loss, my ESP project has an input stream receiving messages containing live sensor data together with a timestamp (resulution: 1 second). The incoming data may not be in the right order when beeing sent to ESP. The intervall in which ESP receives the data may also vary.Is it possible to create windows (or whatever is suitable) that always collect e.g. 5 subsequent seconds of sensor data based on the timestamp provided in the incoming data. A window should only be sent towards the output adapter when all 5 subsequent seconds of data have been received (in other words: the 5 second window is complete).Additionally: Is it possible to make sure that the windows are sent towards the output adapter in the correct order, again based on the timestamp.Thanks a lot,Patrick", "views": "418", "answers": 2, "author": "Jan Patrick Klein", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-05-07 19:04:00", "resolve": "", "uid": "154.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3738520", "text": "Yes, you can do this, but it's a bit more complicated than simply defining a CCL Window with a KEEP 5 Seconds clause - because that will always be based on arrival time. Also: that doesn't give you the batching capability - i.e. only publish once you have 5 values.You will need to set this up as a Flex operator and your \"window\" won't actually be a CCL window (as in CREATE OUTPUT WINDOW...) but you'll want to use either a vector or eventCache to collect the 5 most recent values based on timestamp, and it's easy enough to only output once you have 5 values. EventCache is probably easier, since it can maintain a sorted bucket, allowing you to easily publish the 5 events in correct timestamp order, once you have 5 events.But there are some behaviors that you'll need to think about and define:1. If you start to accumulate events, and then you get an event where the timestamp is more than 5 seconds \"newer\" than the oldest event in your \"window\", then presumably you add the new one to the window and remove the old one.- but if you are waiting to product output until you have 5 events in your window, if this most recent one was only, say, the 3rd event since the \"old\" one, then you will push out th old one and still have not collected 5 - is that what you want?- what if you recieve an event with a timestamp older than the oldest timestamp in yoru window? Do you just throw it away? What do you do with it?- and what if, after pushing out the old one, you receive one with a timestamp earlier than the event that caused the old one to be pushed out? at this point the one you removed from the window is lost. Is that ok?- is the window a jumping window or a rolling window? Once you have 5 events in the window, all within timestamps in a since 5 second interval, and you publish them, do you remove them from the window or leave them? I'm guessing you are removing them, and now collecting a new group of 5...", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Building windows based on timestamps", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "154.2", "author": "Ashok Gopal Rao", "url": "http://scn.sap.com/thread/3738520", "text": "Hi Jan,What Jeff mentioned is accurate. I faced the same challenges (column based data retention, data arriving in unsorted manner, volume etc) in a recent PoC. I'm trying to pull out my model from customer site and will share if I manage. I was planning to request for this feature anyway (custom datetime column based retention).Based on my experience during the PoC:- use flex operator for this retention window- create a dictionary of vector- dictionary key is time and the actual record is pushed into vector. ESP natively converts seconddate to int. So you can use the number of seconds from EPOCH time (1st Jan 1970) as the dictionary key. This is very easy for dictionary maintenance.- You can maintain data for 6 seconds and when data for 7th second arrives, process seconds 1-5 and delete the dictionary entries in a rolling or jumping manner. This will provide your system 1 additional second grace period for the 5th second data to arrive. But, if 5th second data comes in after 7th second data has started, what do you want to do? (as Jeff had asked)- you need to maintain a vector of time with 5 entries i.e. 5 seconds that need to be processed when 7th second data arrives. Correlate this and the dictionary to send data out in a particular order. There might be a better way, like a coalesced eventcache or custom record type based vector, do explore.- you will also need a log store and dictionary rebuild logic (from the Flex Window) in a restart scenario for GD.few points as I had observed in my PoC:- using dictionary and \"removing\" key entries will be faster than eventcache, as you need to loop through the records and use deleteCache. The expireCache function is not applicable as data is not being maintained using system time. You will have to delete from the flex window in any case (using output setopcode).- Do note the data processing, no matter how small, when 7th second record arrives (or after subsequent new second data) will create a backlog (queuedepth > 0). don't worry about it and it will get cleared soon. Partition the flex operator using hash on sensor id or similar column.- This will work great if you just want to pass on the data downstream. I would recommend doing custom aggregation on this flex, if required, rather than a downstream aggregation window. This flex will throw out data faster than agg window can process.What are your data volumes and velocity by the way?Regds,Ashok", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Building windows based on timestamps", "type": "answer", "tags": "N/A"},
{"date_time": "2015-05-08 10:57:00", "resolve": false, "uid": "155", "title": "Q: How to establish connection between web server and ESP?", "url": "http://scn.sap.com/thread/3738820", "text": "Dear colleagues, we started a project web-click stream analysis for '.com' sites. We configured a ESP project as rest provider, use piwik to capture the clicks and send HTTP POST to ESP to push click event into ESP. My questions are: 1.does each POST call initiate a complete new connect? If yes, it cannot be performant, what shall I do to keep the connection between the website webserver and ESP, so that the connection is established when the webserver is ab and running, each POST call does not re-connect? 2. is socket-connection better suited for my use case? If yes, could someone please provide an example?Thanks and regards,Tao", "views": "1579", "answers": 1, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-05-08 17:10:00", "resolve": "", "uid": "155.1", "author": "Shubhra Biswas", "url": "http://scn.sap.com/thread/3738820", "text": "Hi Tao,WSP does not reconnect on every request - the connection is cached.I would need a bit more detail about your use case to make suggestions on the best way forward. Some things to consider - would you be connecting over WAN? How many clients are you expecting to connect? Also do you expect the connections to be long lived?Regards,Shubhra", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Q: How to establish connection between web server and ESP?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-05-20 11:42:00", "resolve": true, "uid": "156", "title": "WSP don't starts - Java_HOME is not set", "url": "http://scn.sap.com/thread/3744301", "text": "Hello,I have a problem with starting the web service provider from my local esp installation.I ould like to connect design studio with the event stream processor to get my visualisation in realtime. Therefore I need to start the web service provider.But every time I try to execute the file \"wsp.bat\" it only says \"JAVA_HOME is not set\".I also tried to execute the \"STREAMING.bat\" again to set all Environment Variables, but still got the same error message when I try to execute \"wsp.bat\".My command line looks like that:Are there any parameters I have to use while calling \"wsp.bat\" ?Thanks in advance.Best RegardsStefan", "views": "366", "answers": 2, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-05-20 13:00:00", "resolve": "solution", "uid": "156.1", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3744301", "text": "Ok got it.Simply enter the command: set JAVA_HOME = <Zielpfad>", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:WSP don't starts - Java_HOME is not set", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "156.2", "author": "Gerald Wang", "url": "http://scn.sap.com/thread/3744301", "text": "Hi Stefan,You can set it to the JRE that we include with ESP, ie - set JAVA_HOME=%STREAMING_HOME%\\lib\\jreRegards,Gerald", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:WSP don't starts - Java_HOME is not set", "type": "answer", "tags": "N/A"},
{"date_time": "2015-05-28 14:59:00", "resolve": true, "uid": "157", "title": "suddenly getting \"Error initializing storage\" when trying to start ESP Studio", "url": "http://scn.sap.com/thread/3748288", "text": "I have been running ESP Studio successfully for months. Recently started working with SDK, writing java adapters. That has been working well for a couple of weeks. Suddenly, I can no longer start Studio. I get a popup box (on Linux) saying \"An error has occurred. See log file null.\" (what is log file null?). Then I get the stack trace:esp@hpux:/opt/sybase/ESP-5_1/studio$ streamingstudiojava.lang.RuntimeException: Error initializing storage. at org.eclipse.osgi.internal.framework.EquinoxContainer.<init>(EquinoxContainer.java:77) at org.eclipse.osgi.launch.Equinox.<init>(Equinox.java:31) at org.eclipse.core.runtime.adaptor.EclipseStarter.startup(EclipseStarter.java:297) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:232) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:648) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:603) at org.eclipse.equinox.launcher.Main.run(Main.java:1465) at org.eclipse.equinox.launcher.Main.main(Main.java:1438)Caused by: java.io.FileNotFoundException: /opt/sybase/ESP-5_1/studio/configuration/org.eclipse.osgi/.manager/.fileTableLock (Permission denied) at java.io.RandomAccessFile.open(Native Method) at java.io.RandomAccessFile.<init>(RandomAccessFile.java:241) at org.eclipse.osgi.internal.location.Locker_JavaNio.lock(Locker_JavaNio.java:36) at org.eclipse.osgi.storagemanager.StorageManager.lock(StorageManager.java:388) at org.eclipse.osgi.storagemanager.StorageManager.open(StorageManager.java:701) at org.eclipse.osgi.storage.Storage.getChildStorageManager(Storage.java:1747) at org.eclipse.osgi.storage.Storage.getInfoInputStream(Storage.java:1764) at org.eclipse.osgi.storage.Storage.<init>(Storage.java:124) at org.eclipse.osgi.storage.Storage.createStorage(Storage.java:84) at org.eclipse.osgi.internal.framework.EquinoxContainer.<init>(EquinoxContainer.java:75) ... 11 morebefore this started happening, I did attempt to load a project using SAP example PublisherExample.java when studio was not running, but I think the server was still running (? it had previously been running to start studio). I believe that attempt failed.I have not changed anything relating to studio, or eclipse. I have just been editing and compiling .java code to run in their own processes. I had been able to publish and subscribe to/from SdkExample project previously. Now nothing works, not even studio. Please assist.", "views": "530", "answers": 2, "author": "Juhan Leemet", "upvotes": 1, "type": "question", "tags": "esp_5.1.esp_studio.sps_09"},
{"date_time": "2015-05-28 18:04:00", "resolve": "solution", "uid": "157.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3748288", "text": "Hello,From this line of trace:Caused by: java.io.FileNotFoundException: /opt/sybase/ESP-5_1/studio/configuration/org.eclipse.osgi/.manager/.fileTableLock (Permission denied)There is some sort of new permissioning issue that is going on.Maybe take a look in that directory (ie /opt/sybase/ESP-5_1/studio/configuration/org.eclipse.osgi/.manager/) and see if you can get any hints on what might be going on there?Or maybe permissioning has changed?Maybe you are using a different username/usergroup?Maybe check if there are any processes that are lingering that should be killed?Maybe some process is holding that file and so it is not accessible by ESP studio.You may want to open an incident with support so we can dig into this further if need be.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:suddenly getting \"Error initializing storage\" when trying to start ESP Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "157.2", "author": "Juhan Leemet", "url": "http://scn.sap.com/thread/3748288", "text": "Thx for the coaching, that was exactly the problem, I had logged in with another account, which was also in the group esp, but had not selected that group to be active, hence those lock files were not writeable by the normal user. When I changed owner/group of all those files, studio started up OK.BTW, if all ESP resources are owned by account/group esp/esp, is it possible for multiple users to use ESP studio simultaneously using the same local cluster, as long as they have done a Linux \"newgrp esp\" (so lock files are owned by group \"esp\")? I have not tried that yet, for fear of messing something up. In theory, one should be able to have multiple subscriptions to resources in projects, i.e. window displays in studio? Are there problems with multiple locking? I tried searching in SP09 Studio User Guide but didn't find anything relevant.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:suddenly getting \"Error initializing storage\" when trying to start ESP Studio", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-01 11:05:00", "resolve": false, "uid": "158", "title": "smp 3.0 registration issue", "url": "http://scn.sap.com/thread/3749555", "text": "hi..i am facing problem when i am doing registration in smp serve..i did the following steps... installed JDK,apache ant,node.js, cordova, and set it to environment variable, installed ADT Plugins in Ecllipse. In Management cockpit i did the following steps.. a) Create new application- given ID, Name, and Type of application (Hybrid). b) On selecting application specified Back-End Point and Authentication c) Go to APP SPECIFIC SETTINGS then upload that Myapp zip. d) Deployed it.in command prompt i did the following steps.. a) cordova create <foldername> <application id> <AppName> b) cd <foldername> c) cordova platform add android d)cordova d plugin C:\\SAP\\MobileSDK3\\KapselSDK\\plugins\\logon e) Downloaded register.html from SCN and replaced with index.html in WWW folder and generated apk. f) We are getting error while opening apk on mobile device that is SAP is not defined .After that i Created one folder that is Myapp/android/.  This android folder contains www folder and config.xml file.  Now compressed Myapp folder. In Management cockpit i did this steps a) Create new application- given ID, Name, and Type of application (Hybrid). b) On selecting application specified Back-End Point and Authentication c) Go d password it showing error..An error occurred in index.html(at line #41):uncaught reference Error.sap is not defined", "views": "280", "answers": 1, "author": "lucky kumar", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-03 15:27:00", "resolve": "", "uid": "158.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3749555", "text": "I believe that you've posted this to the wrong SCN space. Did you mean to post it to the SMP space? this is the Streaming Developer Center, focused on HANA smart data streaming and SAP Event Stream Processor.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:smp 3.0 registration issue", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-01 13:57:00", "resolve": false, "uid": "159", "title": "Data is not being sent to DB from ESP", "url": "http://scn.sap.com/thread/3749541", "text": "Hi,I am using ESP 5_1 version SP08 in linux environment.I am sending some data from esp windows to external oracle database using db_out adapter.I can see that there are n number of records there in window but they were not sent to database.in.ccl file-ATTACH OUTPUT ADAPTER AD_mywindows1 TYPE db_out TO H_mywindow1 PROPERTIES service = 'myservice1' ,table = 'mywindow1';log-Connection(AD_mywindows1/H_mywindow1):: DBOutput_Adapter::purgePending() Enteredall the windows has this same log throughout the log file [log level is - 7]Clueless about what went wrong !!One more question - 2015-06-01 11:50:23.855 | 6944 | container | [SP-3-150004] (104.176) sp(6250) Connection(AD_XXXX/H_XXXX):: DBOutput_Adapter::executeUpdateSQL() executeUpdate not successful for [insert into XXXX values( ? , ? , ? , ? )] update count of: 0What is the meaning of the symbol ? in above error log from esp.Is this denotes the null values in the update query ..!!ThanksRegardsAdesh", "views": "451", "answers": 1, "author": "Adesh Sachan", "upvotes": 0, "type": "question", "tags": "esp.esp_5.1.esp_developer.esp_howto.esp_tutorial.esp_faq.esp_studio"},
{"date_time": "2015-06-03 22:22:00", "resolve": "", "uid": "159.1", "author": "Dilip Sarmah", "url": "http://scn.sap.com/thread/3749541", "text": ">>What is the meaning of the symbol ? in above error log from esp.>>Is this denotes the null values in the update query ..!!This means \"data\". It is saying it executed the statement in the database:insert into XXXX values( ? , ? , ? , ? )For security reason table name is put as XXXX and data are shown as ?.It seems you have created a data service called myservice1. Using ESP Studio can you discover this data service. This means, Studio will try to connect database and display some of the tables.Second question is does your windows schema match with the table schema in the database?Thanks.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Data is not being sent to DB from ESP", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-05 16:55:00", "resolve": true, "uid": "160", "title": "Calling the ESP compiler from the SDK", "url": "http://scn.sap.com/thread/3752274", "text": "Hi, My customer has the following question. Can anyone help? Thanks.../DanIm trying to use the ESP SDK to compile the ESP ccls to create the ccx files. I saw the Compiler interface in SDK but could not use it as we do not know about the compiler args needed. Please check the following queries / comments : Need to know about the ESP Compiler interface available in ESP SDK .  It looks like we can create the Compiler in ESP SDK using: Compiler cclCompiler = CompilerFactory.getCompiler(ServerController); Or  Compiler cclCompiler = CompilerFactory.getCompiler(compilerInputStr); Need to know about the compilerInputStr that is used in this.  2. Need to know about the compilerArgs and the CompilerOption  used in ESP SDK to compile the ESP ccls.  Eg : privateMap<Compiler.CompilerOption, String> compilerArgs = newHashMap<>(); CompilationResult compilationResult = cclCompiler.compile( cclFile.getAbsolutePath(),  ccxFile.getAbsolutePath(), compilerArgs);", "views": "378", "answers": 2, "author": "Dan Tarnower", "upvotes": 0, "type": "question", "tags": "esp_5.1.esp_developer.esp_howto.sybase_support"},
{"date_time": "2015-06-05 20:26:00", "resolve": "solution", "uid": "160.1", "author": "Raphael Sutton", "url": "http://scn.sap.com/thread/3752274", "text": "The SDK Compiler interface is meant for internal use and is hence not as well documented as other SDK interfaces. The recommended method of compilation is to use the executable streamingcompiler or studio compilation and we strongly urge our customers to utilize these methods.That said, if there is a legitimate use case requiring the compiler SDK, here are instructions for its use.There are two methods provided by the CompilerFactory to obtain a compiler instance. The first method takes a ServerController as an argument and returns a Compiler instance that runs remotely in the cluster. This is useful if the steaming binaries are not located on the physical device where the client is running.The second method takes a String argument which is the STREAMING_HOME location. This returns a compiler instance that runs locally. If the customer is using this method, it is almost always better to simply call the executable instead.Once the Compiler instance is obtained, the compile method may be called. Note that the arguments to this method are projectName (this is the name of the main ccl file) and projectPath (the local path to the project) and NOT (as above) cclFile and ccxFile. The ccx is returned as part of the compilationResult and it is the responsibility of the caller to save to a file if that is desired. Also note that all included ccl files must be located in the projectPath or one of its subdirectories.As for the CompilerOptions, this parameter has been provided for future use and there are currently no CompilerOptions defined. This value can be passed as null.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Calling the ESP compiler from the SDK", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "160.2", "author": "Dan Tarnower", "url": "http://scn.sap.com/thread/3752274", "text": "Thanks Raphael, this was very informative.And BTW, the client took your advice and is opting to use streamingcompiler, so long as it works with their deployment manager system.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Calling the ESP compiler from the SDK", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-11 19:45:00", "resolve": false, "uid": "161", "title": "CSV input adapter dynamicPath property", "url": "http://scn.sap.com/thread/3755274", "text": "Hi,I'm using the dynamicPath property in a CSV Input adapter to read all CSV files in a specific path: <Property name=\"dynamicMode\">dynamicPath</Property> <Property name=\"file\">.*\\.csv</Property>It works fine (CSV files are loaded and processed), but: How can I control the order on which the different files are loaded? I was expecting it could be based on the file names (lexicographic order) or perhaps the files timestamp, but this does not happens. Is it possible to control this behavior in some way...?Thanks a lot in advance.", "views": "349", "answers": 0, "author": "Ignacio Labrador Pavon", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-11 23:50:00", "resolve": true, "uid": "162", "title": "what to do if group by column contains NULL value", "url": "http://scn.sap.com/thread/3755325", "text": "Dear colleages, CREATE OUTPUT WINDOW Aggr_window PRIMARY KEY DEDUCED AS  SELECT A.userId userId , A.url url, A.cookieId, count ( A.timestamp ) count  FROM Prev_stream A KEEP 24 hours  GROUP BY A.userId , A.url, A.cookieId;However, the value of userId is sometimes NULL, in this case, aggregation is not performed at all.userIdurlcookieIdtimestampNULLhttp://targetPage11120150501NULLhttp://targetPage11120150502customer1http://targetPage99920150501NULLhttp://targetPage22220150601I expect to get:userIdurlcookieIdcountNULLhttp://targetPage1112customer1http://targetPage9991NULLhttp://targetPage2221instead I got only userIdurlcookieIdcountcustomer1http://targetPage9991How do I deal with this situation? Thanks for your help,Tao", "views": "802", "answers": 11, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-12 00:47:00", "resolve": "", "uid": "162.1", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3755325", "text": "I found a post from Jeff: How to change variable (parameter) values in a running projectso I did the following:DECLARE  string unknownId := '$$UNKNOWN$$'; string setVar (string value) { if (isnull(value)) value := unknownId; return value; } END;...CREATE OUTPUT STREAM newStream AS  SELECT  setVar(A.userId) userId, A.url url, A.cookieId, A.timestamp timestamp FROM Prev_stream A CREATE OUTPUT WINDOW Aggr_window PRIMARY KEY DEDUCED AS SELECT A.userId userId , A.url url, A.cookieId, count ( A.timestamp ) count FROM newStream A KEEP 24 hours GROUP BY A.userId , A.url, A.cookieId;I got nowuserIdurlcookieIdcount$$UNKNOWN$$http://targetPage1112customer1http://targetPage9991$$UNKNOWN$$http://targetPage2221If you have better suggestions, please do let me know. Thanks and regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "162.2", "author": "Pauli Gandhi", "url": "http://scn.sap.com/thread/3755325", "text": "This is more efficient as you are avoiding creating another stream and executing unnecessary code on every event.CREATE OUTPUT WINDOW Aggr_window PRIMARY KEY DEDUCED AS SELECT ifnull(A.userId, 'N/A') userId , A.url url, A.cookieId, count ( A.timestamp ) \"count\" FROM newStream A KEEP 24 hours GROUP BY ifnull(A.userId, 'N/A') , A.url, A.cookieId;ThanksPauli", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.3", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3755325", "text": "Hello Pauli,thanks a lot. I tried your solution, however, the NULL userId in the result list have always '1' as value, not the expected dummy value. Do you know why? Thanks and regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.4", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3755325", "text": "Tao,Can you try using 'NA' instead of 'N/A'. I'm curious to see if that will change the output you are getting. Thanks", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.5", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3755325", "text": "Hello Robert,when I replace 'N/A' with other string such as 'NA' or '$$UNKNOWN$$', the NULL userId in the result list have always '1' as value, not the expected dummy value.Regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.6", "author": "Pauli Gandhi", "url": "http://scn.sap.com/thread/3755325", "text": "Can you post your CCL?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.7", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3755325", "text": "CREATE SCHEMA rawEventSchema ( userId string, productId string, piwikId string, timestamp long);CREATE INPUT stream rawEventStreamSCHEMA rawEventSchema;CREATE OUTPUT window aggr1PRIMARY KEY DEDUCED ASSELECT isnull(A.userId, 'NA', A.userId) userId, A.productId productId, A.piwikId piwikId, count ( A.timestamp ) counterFROM rawEventStream A KEEP 24 hoursGROUP by isnull(A.userId, 'NA', A.userId) userId, A.productId, A.piwikId;For me, it seems only the boolean result of isnull() function is outputed. Therefore, when userId has NULL value, the output userId is 0, otherwise, the output userId is 1.Regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.8", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3755325", "text": "You're using isnull() which accepts a single argument and returns 0 or 1. Use ifnull() which is same as firstnonnull() which will return the string if the first argument is null", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.9", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3755325", "text": "Thanks a lot. I mistook isnull as ifnull.interestingly, isnull() takes three arguments as well.Best regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.10", "author": "Pauli Gandhi", "url": "http://scn.sap.com/thread/3755325", "text": "Although it is documented that the isnull function only takes one argument. In realty it can take more than one and returns true (1) if any of the arguments is null.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "162.11", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3755325", "text": "Got it. Thanks.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:what to do if group by column contains NULL value", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-16 14:09:00", "resolve": true, "uid": "163", "title": "question on the ON clause of ESP pattern", "url": "http://scn.sap.com/thread/3757099", "text": "Dear Colleague, I want to define a pattern, which says, in the same session, if a customer did event1, but afterwards not event2 and not event3, then I want to raise alert. CREATE INPUT STREAM rawStream SCHEMA ( eventType string, sessionId string, userId string, productId string);/**@SIMPLEQUERY=FILTER*/CREATE OUTPUT STREAM event1 AS  SELECT A.sessionId , A.userId , A.productId FROM rawStream A  WHERE A.eventType = '1' ; /**@SIMPLEQUERY=FILTER*/CREATE OUTPUT STREAM event2 AS  SELECT A.sessionId , A.userId , A.productId FROM rawStream A  WHERE A.eventType = '2' ;/**@SIMPLEQUERY=FILTER*/CREATE OUTPUT STREAM event3 AS  SELECT A.sessionId , A.userId , A.productId FROM rawStream A  WHERE A.eventType = '3' ;/**@SIMPLEQUERY=PATTERN*/CREATE OUTPUT STREAM alerts AS SELECT event1.sessionId sessionId , event1.userId userId FROM event1 event1,  event2 event2 , event3 event3 MATCHING [ 30 SECONDS : event1 , !event2 , !event3 ] ON event1.sessionId = event2.sessionId AND event1.sessionId = event3.session;This leads to compiler error: event1.sessionId has been specified multiple times in the ON clause of alerts.Did I do it wrong? How shall I express 'in the same session' in this case?another question is: can I leave out the INTERVAL?Thanks and regards,Tao", "views": "286", "answers": 2, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-16 15:46:00", "resolve": "solution", "uid": "163.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3757099", "text": "Change your ON clause to this:ON event1.sessionId = event2.sessionId = event3.sessionId;But you can also further simplify the whole model. You can eliminate the 3 separate filter streams and just do this:CREATE OUTPUT STREAM alertsAS SELECT E1.sessionId sessionId , E1.userId userIdFROM rawStream E1, rawStream E2, rawStream E3MATCHING [ 30 SECONDS : E1 , !E2 , !E3 ]ON E1.eventType = '1' AND E2.eventType = '2' AND E3.eventType = '3';And no, you can't eliminate the interval.", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:question on the ON clause of ESP pattern", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "163.2", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3757099", "text": "Thanks.Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:question on the ON clause of ESP pattern", "type": "answer", "tags": "N/A"},
{"date_time": "2015-05-19 21:47:00", "resolve": false, "uid": "164", "title": "Twitter Adapter - JDBC error 403 - cannot find remote source: proxy", "url": "http://scn.sap.com/thread/3744026", "text": "We are currently exploring SAP HANA Smart Data Streaming and have followed videos on SAP HANA Academy for getting started with the Twitter adapter. When we get to the point to test the connection from creating a new Remote Source we receive the following error:SAP DBTech JDBC: [403]: internal error: Cannot get remote source objects: proxyOur IT Admin had the following comment:If both the HANA and Agent systems are on the same LAN w/o a firewall between then, then there shouldn't be a need for a proxy. My questions:Is there a way to get the Twitter Adapter to work with SAP HANA Smart Data Streaming that does not require a proxy to be setup?If a proxy is required at all times to use this functionality, what is the reasoning.", "views": "794", "answers": 6, "author": "Jonathan Ross", "upvotes": 0, "type": "question", "tags": "hana.adapter.smart_data_streaming.twitter_adapter"},
{"date_time": "2015-05-19 22:27:00", "resolve": "", "uid": "164.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3744026", "text": "HANA smart data streaming does not come with a Twitter adapter. I assume you are using the Twitter adapter for HANA smart data integration and following the HANA academy videos for that. That adapter will let you capture Twitter data in HANA tables, but doesn't currently support HANA smart data streaming.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Twitter Adapter - JDBC error 403 - cannot find remote source: proxy", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "164.2", "author": "Jonathan Ross", "url": "http://scn.sap.com/thread/3744026", "text": "Correct, used the incorrect term. If there is a different blog area for that question please let me know, but in SAP HANA smart data integration for the twitter adapter, is it required that there must be a proxy or can we accomplish this without a proxy?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Twitter Adapter - JDBC error 403 - cannot find remote source: proxy", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "164.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3744026", "text": "Hi Jonathan,I believe that the site for you to use for HANA Smart Data integration questions is SAP HANA Developer Center.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 2, "title": "Re:Twitter Adapter - JDBC error 403 - cannot find remote source: proxy", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "164.4", "author": "Jonathan Ross", "url": "http://scn.sap.com/thread/3744026", "text": "Hi Alice,Have not received any feedback on this in the HANA Developer Center, any ideas?Thanks,Jon", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Twitter Adapter - JDBC error 403 - cannot find remote source: proxy", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "164.5", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3744026", "text": "Hi Jon,The only other idea I can come up with is for you to log an incident with SAP Support. Here is the link: Report an Incident | SAP Support PortalThanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Twitter Adapter - JDBC error 403 - cannot find remote source: proxy", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "164.6", "author": "Jonathan Ross", "url": "http://scn.sap.com/thread/3744026", "text": "Update for resolution(2) steps required to get this working without requiring a proxy1. Change your TWITTER DEV account time-zone to the following setting:(GMT) UTC2. Change the dpagentconfig.ini for the Data Provisioning Agent:The ini file by default has the following:proxyHost=proxyproxyPort=8080proxyType=Changing the ini file with following allowed a successful test connection:proxyHost=proxyPort=proxyType=", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Twitter Adapter - JDBC error 403 - cannot find remote source: proxy", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-24 15:51:00", "resolve": false, "uid": "165", "title": "How to get the difference of sets?", "url": "http://scn.sap.com/thread/3760846", "text": "Hi all,I would like to know how to get the difference set with ESPFor example, I have two windows like below:CREATE INPUT WINDOW A SCHEMA (aa INTEGER) PRIMARY KEY(aa);CREATE INPUT WINDOW B SCHEMA (bb INTEGER) PRIMARY KEY(bb);And I want to get C (=A-B).TIA,JCMessage was edited by: Robert Waywell - Edited variable names for clarity", "views": "504", "answers": 1, "author": "Jung-chan Kim", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-24 19:36:00", "resolve": "", "uid": "165.1", "author": "Pauli Gandhi", "url": "http://scn.sap.com/thread/3760846", "text": "You can do an outer join and filter out all the matching rows.CREATE LOCAL WINDOW ABJoin PRIMARY KEY (Aaa)AS SELECT A.aa Aaa, B.bb Bbb FROM A LEFT JOIN B ON A.aa = B.bb;CREATE OUTPUT WINDOW C PRIMARY KEY DEDUCEDAS SELECT Aaa aa FROM ABJoin WHERE isnull(B.bb);This effectively does what you need.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to get the difference of sets?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-15 16:16:00", "resolve": false, "uid": "166", "title": "Is there escape parameter at input adapter?", "url": "http://scn.sap.com/thread/3756500", "text": "Dear Colleagues, I use JMS_CSV_SERVER_Event_Input to subscribe to a data source. ATTACH INPUT ADAPTER JMS_CSV_SERVER_Event_InputTYPE toolkit_jms_csv_inputTO RawEventstreamPROPERTIES csvExpectStreamNameOpcode = FALSE , connectionFactory = 'ConnectionFactory' , jndiContextFactory = 'org.apache.activemq.jndi.ActiveMQInitialContextFactory' , jndiURL = 'tcp://localhost:61616' , destinationType = 'QUEUE' , destinationName = 'QueueName' , csvDelimiter = ',' , csvHasHeader = FALSE , scanDepth = 100 ;With the default delimiter ',' we ran into problem when for example a description field which contains , in its string. We could think about choosing another delimiter. But, is there an escape parameter we could set at the ESP input adapter? Thanks and best regards,Tao", "views": "373", "answers": 2, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-18 21:34:00", "resolve": "", "uid": "166.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3756500", "text": "Tao,Sorry I didn't see this sooner. Bad news: no, in SP9, the current release, there's no escape to make this work. Good news though, is that this planned to be supported in SP10.In the mean time, you could either:a) choose a different delimiterb) convert \"non-delimiter\" instances of \",\" to some other \"safe\" character and then once the event is in ESP, you can use the CCL replace() function to change the character back to \",\"Jeff", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Is there escape parameter at input adapter?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "166.2", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3756500", "text": "great! just what we need. Thanks.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Is there escape parameter at input adapter?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-26 09:19:00", "resolve": true, "uid": "167", "title": "Not able to connect to ESP 5_1 SP09 at linux vm", "url": "http://scn.sap.com/thread/3762272", "text": "Hi,I have recently installed ESP 5-1 SP09 at linux VM.After installation I am trying to connect esp cluster admin using following command/s(a)$ESP_HOME/bin/esp_cluster_admin --uri=esps://localhost:XXXXX --auth=rsa --key-alias=serverkey --storepass=xxxx --keystore=$ESP_HOME/security/keystore_rsa.jks(b) $ESP_HOME/bin/streamingclusteradmin --uri=esps://localhost:XXXXX --auth=rsa --key-alias=serverkey --storepass=xxxx --keystore=$ESP_HOME/security/keystore_rsa.jks both ways it says-failed to login !!I never had any problem with first command with ESP 5_1 SP08.but with SP09 same command is not working.can some one helpThanksRegardsAdesh", "views": "338", "answers": 1, "author": "Adesh Sachan", "upvotes": 0, "type": "question", "tags": "esp.esp_5.1.esp_developer.esp_howto.sybase_support.esp_faq.sps_09"},
{"date_time": "2015-06-30 15:01:00", "resolve": "solution", "uid": "167.1", "author": "Beverly Duquette", "url": "http://scn.sap.com/thread/3762272", "text": "Adesh,Here are the steps to follow.Since you already have a separate keystore.jks for rsa setup(keystore_rsa.jks) , you probably can skip some of these steps (3-5).1. Step up the server for RSA authentication as listed in thisdocumentation:http://help.sap.com/saphelp_esp_51sp09_cp/helpdata/en/09/545e99e76645e19ddab45f90030746/frameset.htmTo verify that RSA authentication is set up in the server use:2. >streamingclusternode --config cluster.cfg --show3. >keytool -genkey -keyalg RSA -alias selfsigned -keystorekeystore_rsa.jks -storepass password -validity 360 -keysize 20484. >keytool -keystore keystore_rsa.jks -storepass password -list5. >keytool -keystore keystore_rsa.jks -storepass password -changealias -keypass password -destalias johnsmith -alias selfsigned6.>streamingclusteradmin --uri=esps://localhost:19011 --username=SYS_STREAMINGPassword:> deploykey johnsmith keystore_rsa.jks password johnsmithJKS [done]NOTE: the syntax for deploykey is: deploykey<user-name> <keystore> <storepass> <key-alias>[store-type]7. > grant permission all to user johnsmith> quit8. >streamingclusteradmin --uri esps://localhost:19011 --auth=rsa --key-alias=johnsmith --keystore=keystore_rsa.jks--storepass=password > Thanks,Beverly", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Not able to connect to ESP 5_1 SP09 at linux vm", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-16 15:37:00", "resolve": true, "uid": "168", "title": "\"frameworkadapter.log\" is missing", "url": "http://scn.sap.com/thread/3757233", "text": "Hi,I have a local installation of ESP and have a problem with my Hadoop_File_CSV_Output adapter and wanted check in the \"frameworkadapter.log\" what the problem is. But unfurtunally I don't have this log file. I searched a little bit and find that this log file should be located in the same directory where the both log files \"esp_server.log\" and \"stdstreams.log\" are. I tried to reinstall esp and also tried to execute again the \"STREAMING.bat\" in the %STREAMING HOME% directory to set the environment variables. But I still don't have this log file.Does anyone have another idea what I can try to get the \"frameworkadapter.log\"?Thanks in advance.Best RegardsStefan", "views": "698", "answers": 14, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-17 14:10:00", "resolve": "", "uid": "168.1", "author": "Lukas Carullo", "url": "http://scn.sap.com/thread/3757233", "text": "Hi Stefan, are you running ESP on Windows or Linux? Have you checked the log4j.properties, yet? Double check the logging path/file. On Windows you'll find the frameworkadapter.log by default in your workspace folder under <Workspace>/projects/<project_name>/On Linux I found frameworkadapter.log in <ESP_HOME>/cluster/projects/.../projectnameGood luck and regards,Lukas", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.2", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3757233", "text": "Hi Lucas,I running ESP on Windows and also checked the log4j.properties, it looks like this:-------------------------------------------------------------------------------------------------------------------------------------------------# Set root logger level to DEBUG and set appenders to stdout, file and emaillog4j.rootLogger=ALL, stdout, R# stdout appenderlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d{MM-dd-yyyy HH:mm:ss.SSS} %p [%t] (%C{1}.%M) %m%n#log4j.appender.stdout.Threshold=INFO# file appenderlog4j.appender.R=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.R.File=logs/frameworkadapter.loglog4j.appender.R.DatePattern='.'yyyy-MM-ddlog4j.appender.R.layout=org.apache.log4j.PatternLayoutlog4j.appender.R.layout.ConversionPattern=%d{MM-dd-yyyy HH:mm:ss.SSS} %p [%t] (%C{1}.%M) %m%n#log4j.appender.R.Threshold=INFO# email appenderlog4j.appender.email=org.apache.log4j.net.SMTPAppenderlog4j.appender.email.To=your.name@yourcompany.comlog4j.appender.email.From=alert.manager@yourcompany.comlog4j.appender.email.SMTPHost=yourmailhostlog4j.appender.email.BufferSize=1log4j.appender.email.Subject=Framework Adapter Errorlog4j.appender.email.layout=org.apache.log4j.PatternLayoutlog4j.appender.email.layout.ConversionPattern=%d{MM-dd-yyyy HH:mm:ss.SSS} %p [%t] (%C{1}.%M) %m%nlog4j.appender.email.Threshold=ERRORlog4j.logger.com.sybase.esp=INFO-------------------------------------------------------------------------------------------------------------------------------------------------Is there anything wrong or should I edit something at this file?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.3", "author": "Beverly Duquette", "url": "http://scn.sap.com/thread/3757233", "text": "Stefan,Are you running the project in the Studio or outside of the Studio? Thanks,Beverly", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.4", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3757233", "text": "Hi Beverly,I running the project in ESP Studio.Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.5", "author": "Beverly Duquette", "url": "http://scn.sap.com/thread/3757233", "text": "Stefan,Try searching under C:\\Users\\<userid>\\My Documents\\SybaseESP\\5.1\\<workspace>...Thanks,Beverly", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.6", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3757233", "text": "Hi Beverly,I tried it, but there are only the other two log files (I mentioned above). The frameworkadapter.log is not there. I also let my PC search for the log file. But it's no where on my pc.Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.7", "author": "Beverly Duquette", "url": "http://scn.sap.com/thread/3757233", "text": "Stefan,Where is the log4j.properties located? Did you set a adapter_classpath environment variable?Logging - SAP Event Stream Processor: Adapters Guide - SAP LibraryCan you provide your esp_server.log file so that we can review it. If so, can you please upload it to the following location:https://mdocs.sap.com/mcm/public/v1/open?shr=seDQV-msPRQ4KiOJgX2J6cqE0bbNCu5qHozJOEVp_i0   Thanks, Beverly", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.8", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3757233", "text": "Hi Beverly,The log4j.properties I posted above is at %STREAMING HOME%\\adapters\\framework\\config\\log4j.properties locted.I didn't set a adapter_classpath environment untill now.Does I have to use the same path where the log4j.properties are located for the ADAPTER_CLASSPATH environment variable?I also uploaded the esp_server.log at the link you posted.Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.9", "author": "Beverly Duquette", "url": "http://scn.sap.com/thread/3757233", "text": "Stefan,I created a system environment variable as the following:ADAPTER_CLASSPATH=C:\\esp\\ESP-5_1\\adapters\\framework\\configThe folder, C:\\esp\\ESP-5_1\\adapters\\framework\\config, contains the log4j.properties.I was able to see that a frameworkadapter.log file was created under:C:\\SybaseESP\\5.1.9\\workspace\\projects\\default.mynewhadoop.0\\logsDoes that help?Thanks,Beverly", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.10", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3757233", "text": "Hi Beverly,thanks for the information. I tried the same ADAPTER_CLASSPATH and also set the log4j.properties to ALL. But unfortunally I still have no framworkadapter.log file.Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.11", "author": "Beverly Duquette", "url": "http://scn.sap.com/thread/3757233", "text": "Stefan,Can you send in your project and steps to reproduce?You can use the same link as before:https://mdocs.sap.com/mcm/public/v1/open?shr=seDQV-msPRQ4KiOJgX2J6cqE0bbNCu5qHozJOEVp_i0Thanks,Beverly", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.12", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3757233", "text": "Hi Beverly,in my project I simply use the generic input adapter to read datasets from SAP HANA (it worked without any problems). After that I have the hadoop file csv output adapter connected to the input adapter to write the datasets into hadoop.I loaded up the project as zip file on your link.Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "168.13", "author": "Beverly Duquette", "url": "http://scn.sap.com/thread/3757233", "text": "Stefan,I was not able to reproduce your issue using the project that you provided.Here are a few suggestions:1. When you start the studio, right mouse click on the executable and select 'Run As Administrator'.2. Make sure the file and folder have write permissions:%STREAMING_HOME%\\adapters\\framework\\instances\\file_csv_output\\adapter_config.xml%STREAMING_HOME%\\lib\\adapters\\toolkit_file_csv_output.cnxmlThank you.Beverly", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "168.14", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3757233", "text": "Hi Beverly,thanks for your help. After starting ESP studio as admin I got the frameworkadapter.log.Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:\"frameworkadapter.log\" is missing", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-29 13:12:00", "resolve": true, "uid": "169", "title": "Problem with activation of t&d; licence", "url": "http://scn.sap.com/thread/3763237", "text": "Hello,I have a problem with my licences.I started to test ESP 5.1 with an extended test version (90 days). Now we created an test&developement licence.After reinstalling ESP with that t&d licence I still can't start projects and the stdstreams.log says that the licence is expired.Do I have to change something that the t&d licence can work?Also I'm not sure if I used the right information for the licence. For the licence we used the Un-served model and that wants the following information:Host-ID, Host-Name and Amount of licencesFor Host-ID I used the physical address of my pc like here is explained:https://websmp102.sap-ag.de/~sapidb/011000358700001006652011E#30-4For the Host-Name I used the name of the pc.Is this right, or does I have to use other information to get the licence working?Thanks in advance.Best RegardsStefan", "views": "546", "answers": 5, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-29 15:05:00", "resolve": "", "uid": "169.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3763237", "text": "Hi,Are you using SP08 or SP09? There can be some differences in the files.It is hard to tell without the exact complete error trace.So what does the exact flexnet trace look like?It should tell where it looks and what it finds and the full flexnet error.If you change the type of license in an existing installation then you also need to change theesp_license.prop file (..\\ESP-5_1\\sysam\\) For a development and test license the second line should be:LT=DTIf you have development and test license generated as you say then edit the second line of this file as above.Also, in case they are interfering, move out all old no longer valid licences out of the folder ..\\SYSAM-2_0\\licensesBen", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with activation of t&d; licence", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "169.2", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3763237", "text": "Hi Ben,thanks for the fast answer.I use SP09 and also reinstalled ESP with the d&t licence. So the second line is already \"LT=DT\" and also there is only the new licence in the licence-folder.ESP studio tells this error message (waht shows that there is a licence problem):esp_server.log shows this:stdstreams.log shows this:Error: the license has expired2015/06/29 13:20:55 Info (131228): Using licenses from: C:\\Sybase\\SYSAM-2_0\\licenses\\SYBASE.lic2015/06/29 13:20:55 Error (131302): Failed to obtain license(s) for ESP_CORE feature from license file(s) or server(s).2015/06/29 13:20:55 Error (131304): Insufficient ESP_CORE CPU licenses. Sybase Event Stream Processor Engine requires 2 ESP_CORE (\"DT\") CPU licenses for use on this machine but only 1 could be obtained. Check whether additional licenses are available at the Sybase Product Download Center.2015/06/29 13:20:55 Error (0): License feature name: ESP_CORE2015/06/29 13:20:55 Error (0): License search path: C:\\Sybase\\SYSAM-2_0\\licenses\\SYBASE.lic;2015/06/29 13:20:55 Error (0): FLEXnet Licensing error:-73,1252015/06/29 13:20:55 Error (0): For further information, refer to the Sybase Software Asset Management website at http://www.sybase.com/sysamSAP Event Stream Processor Engine 5.1.092.00/20141231.1/SP09 Rev92/winnt/x86_64/64-bit/OPT/Wed, Dec 31, 2014 3:41:47 PMCopyright 2014 SAP AG or an SAP affiliate company. All Rights Reserved.No part of this publication may be reproduced or transmitted in any formor for any purpose without the express permission of SAP AG. Theinformation contained herein may be changed without prior notice.Error: the license has expiredBest RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with activation of t&d; licence", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "169.3", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3763237", "text": "Hi Stefan,The real error is this one: >>>Insufficient ESP_CORE CPU licenses. Sybase Event Stream Processor Engine requires 2 ESP_CORE (\"DT\") CPU licenses for use on this machine but only 1 could be obtained. Check whether additional licenses are available at the Sybase Product Download Center.<<<Apparently your machine requires 2 licenses for 2 CPU's \\ cores (hyperthreading enabled?); or that is what I make of it.Only one license was found instead of the expected two.Not sure why it says expired, maybe because it finds old licenses in its search path or it is just a faulty message. Think you can ignore the expired message. But you need to deal with insufficient licenses message.Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with activation of t&d; licence", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "169.4", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3763237", "text": "Hi Ben,thanks for your help. We created two licences and now it works fine.Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with activation of t&d; licence", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "169.5", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3763237", "text": "Great,Always nice to hear,Best Regards,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Problem with activation of t&d; licence", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-29 20:15:00", "resolve": true, "uid": "170", "title": "How to configure SAP RFC output adapter?", "url": "http://scn.sap.com/thread/3763478", "text": "Dear Colleague,in our esp project, we use SAP RFC output adapter to call abap function in the backend system. We have maintained the field mapping between esp and abap in a mapping xml file, and use a configuration file (xml) to maintain system information and logon credentials, because we want to deliver the ccl file as a sap marketplace download for all customers, any arbitrary information shall be removed from the ccl file.however, we cannot remove the arbitary file path for the configuration file.ATTACH OUTPUT ADAPTER RFC_output TYPE rfcoutplugin TO CreateRFCOutputColumns PROPERTIES config = 'C:/Users/dxxxxx/Documents/SybaseESP/5.1/workspace/project_name/adapter_config/adapter_config.xml' ;I just learned that the best way to do this is not through the configuration files, but the project ccr file. Could someone please give me a detailed description on how to do that? I would be extremely grateful if we could do it together, for example, via online session.Thank you and best regards,Tao", "views": "375", "answers": 3, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-06-30 09:41:00", "resolve": "", "uid": "170.1", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3763478", "text": "Hi Tao,That is something that I had worked out in SP04 or SP08 and it should be similar SP09 or anything later.It can be put into the ccr using a property set.In the ATTACH ADAPTER statement you need to reference a propertyset as in PROPERTIESpropertyset = 'mydbproperties' Here is some copied and pasted ccl code; commented out://ATTACH OUTPUT ADAPTER Adapter1 // TYPE db_out // TO SdkExampleOutputWindow // GROUP dbgroup// PROPERTIES // propertyset = 'dbservice' // ; //ADAPTER START GROUPS dbgroup;//ADAPTER START GROUPS dbgroup NOSTART;In the studio open the ccr file and go to the Project Configurations->Adapter Properties.The ADD button adds a new propertyset, it needs a name for the ccl reference, for example mydbproperties.Then go to the newly created propertyset in the list on the left, might be at the bottom, and Right Click New->Property AddTyping in the property name and the current value, i.e. your file path, and save with <ctrl><S> and you should be done.In the .ccr file it should be there now and in a common editor it should be visible what or where has been put in for the property set. It is supposed to override the ccl so a rubbish value in the ccl and the right value in the ccr should then work in run-time. And once deployed the ccr file can be edited anyway you want.Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to configure SAP RFC output adapter?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "170.2", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3763478", "text": "Hello Ben,thanks a lot for your reply, adding \"propertyset = 'mydbproperties' \" in the ccl ATTACH ADAPTER statement was what I missed. Now everything works.Best regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to configure SAP RFC output adapter?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "170.3", "author": "Ben Pluijm", "url": "http://scn.sap.com/thread/3763478", "text": "OK, Great, Tao,Please mark this one as answered if it's solved now,Best Regards,Ben", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to configure SAP RFC output adapter?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-07-01 16:28:00", "resolve": false, "uid": "171", "title": "File_Hadoop_CSV_Output-Adapter stopped by data throughput", "url": "http://scn.sap.com/thread/3764666", "text": "Hello,I use a local installation of ESP 5.1 SP09 and have an problem with the File_Hadoop_CSV_Output-Adapter.Every time ESP tries to put data through it, it stopped and disconnect the connection.I put the following binaries in the folder: %ESP_HOME%\\adapters\\framework\\libj:hadoop-common-2.2.0.jarhadoop-auth-2.2.0.jarhadoop-hdfs-2.2.0.jarguava-11.0.2.jarprotobuf-java-2.5.0.jarI also checked the user identification and I have no permission problems.I also checked that the path is created on the hdfs.My dir looks like this:hdfs://54.243.87.200:9000/user/hadoop/espThe framworkadapter.log says this:\n07-01-2015 13:44:37.789 INFO [main] (ContextHandler.doStop) Stopped o.e.j.s.ServletContextHandler@7a5c978a{/,null,UNAVAILABLE}\n07-01-2015 13:44:37.805 INFO [main] (AbstractConnector.doStop) Stopped ServerConnector@952942b{HTTP/1.1}{192.168.178.61:19083}\n07-01-2015 13:44:44.181 INFO [main] (Framework.main) start C:\\Sybase\\ESP-5_1/adapters/framework/instances/file_json_output/adapter_config.xml \n07-01-2015 13:44:44.566 INFO [main] (XmlUtils$1.resolveResource) C:\\Sybase\\ESP-5_1/adapters/framework/config/parametersdefine.xsd\n07-01-2015 13:44:44.576 INFO [main] (XmlUtils$1.resolveResource) C:\\Sybase\\ESP-5_1/adapters/framework/config/standard_module_parametersdefine.xsd\n07-01-2015 13:44:45.195 INFO [main] (PortAllocator.allocateFromDataCenter) Trying to get global lock ... \n07-01-2015 13:44:45.198 INFO [main] (PortAllocator.allocateFromDataCenter) Success to get global lock.\n07-01-2015 13:44:45.500 INFO [main] (AdapterController.init) Address 192.168.178.61:19083 is used to accept the control command.\n07-01-2015 13:44:45.523 INFO [main] (AdapterController.sendCommand) start C:\\Sybase\\ESP-5_1\\adapters\\framework\\instances\\file_json_output\\adapter_config.xml\n07-01-2015 13:44:46.642 INFO [main] (Log.initialized) Logging initialized @3463ms\n07-01-2015 13:44:46.705 INFO [Thread-0] (Server.doStart) jetty-9.2.0.v20140526\n07-01-2015 13:44:46.797 INFO [Thread-0] (ContextHandler.doStart) Started o.e.j.s.ServletContextHandler@634984c8{/,null,AVAILABLE}\n07-01-2015 13:44:46.820 INFO [Thread-0] (AbstractConnector.doStart) Started ServerConnector@50e674b9{HTTP/1.1}{192.168.178.61:19083}\n07-01-2015 13:44:46.821 INFO [Thread-0] (Server.doStart) Started @3671ms\n07-01-2015 13:44:47.704 INFO [main] (AdapterController.executeStart) Adapter controller is started.\n07-01-2015 13:44:47.705 INFO [main] (AdapterController.executeStart) Starting adapter\n07-01-2015 13:44:47.754 WARN [main] (AdapterConfig.getAdapterName) The adapter name File/Hadoop JSON Output configured in adapter runtime configuration file is different from the adapter name File_Hadoop_JSON_Output configured in the project. The later one File_Hadoop_JSON_Output will be used as adapter name. \n07-01-2015 13:44:47.778 INFO [main] (EspProjectInfo.connect) Login to default project ...\n07-01-2015 13:44:47.780 INFO [main] (EspProjectInfo.connect) defaultSessionId = LOCAL_b87928d5543f4b9f879b19ec3a195f23_2\n07-01-2015 13:44:47.780 INFO [main] (EspProjectInfo.connect) defaultHostName = localhost\n07-01-2015 13:44:47.781 INFO [main] (EspProjectInfo.connect) defaultPortNumber = 50604\n07-01-2015 13:44:47.781 INFO [main] (EspProjectInfo.connect) defaultSSL = false\n07-01-2015 13:44:47.966 INFO [main] (ModuleWrapper.initQue) Buffer Size for module MyOutStream_Subscriber is 10240.\n07-01-2015 13:44:47.967 INFO [main] (ModuleWrapper.initParallelParameters) Parallel setting of module MyOutStream_Subscriber is true.\n07-01-2015 13:44:47.972 INFO [main] (SubscribeProcesser.init) EspSubscriber is initializing\n07-01-2015 13:44:47.993 INFO [main] (EspProjectInfo.connect) Login to default project ...\n07-01-2015 13:44:47.994 INFO [main] (EspProjectInfo.connect) defaultSessionId = LOCAL_b87928d5543f4b9f879b19ec3a195f23_2\n07-01-2015 13:44:47.994 INFO [main] (EspProjectInfo.connect) defaultHostName = localhost\n07-01-2015 13:44:47.994 INFO [main] (EspProjectInfo.connect) defaultPortNumber = 50604\n07-01-2015 13:44:47.995 INFO [main] (EspProjectInfo.connect) defaultSSL = false\n07-01-2015 13:44:48.032 INFO [main] (ModuleWrapper.initQue) Buffer Size for module FileOutputTransporter is 10240.\n07-01-2015 13:44:48.032 INFO [main] (ModuleWrapper.initParallelParameters) Parallel setting of module FileOutputTransporter is true.\n07-01-2015 13:44:48.033 INFO [main] (TransporterWrapper.init) Before initializing the Transporter module FileOutputTransporter\n07-01-2015 13:44:52.388 WARN [main] (NativeCodeLoader.<clinit>) Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n07-01-2015 13:44:52.404 ERROR [main] (Shell.getWinUtilsPath) Failed to locate the winutils binary in the hadoop binary path\njava.io.IOException: Could not locate executable null\\bin\\winutils.exe in the Hadoop binaries.\n at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:355)\n at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:370)\n at org.apache.hadoop.util.Shell.<clinit>(Shell.java:363)\n at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)\n at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)\n at org.apache.hadoop.security.Groups.<init>(Groups.java:77)\n at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)\n at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)\n at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)\n at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)\n at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)\n at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)\n at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)\n at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)\n at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)\n at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)\n at com.sybase.esp.adapter.transporters.file.FileOutputTransporter.rotateCounterStartAt(Unknown Source)\n at com.sybase.esp.adapter.transporters.file.FileOutputTransporter.init(Unknown Source)\n at com.sybase.esp.adapter.framework.wrappers.TransporterWrapper.init(Unknown Source)\n at com.sybase.esp.adapter.framework.internal.Adapter.init(Unknown Source)\n at com.sybase.esp.adapter.framework.internal.AdapterController.executeStart(Unknown Source)\n at com.sybase.esp.adapter.framework.internal.AdapterController.execute(Unknown Source)\n at com.sybase.esp.adapter.framework.Framework.main(Unknown Source)\n07-01-2015 13:44:56.954 ERROR [main] (TransporterWrapper.init) Exception is thrown\njava.net.ConnectException: Call From E6420-SR/192.168.178.61 to ec2-54-243-87-200.compute-1.amazonaws.com:9000 failed on connection exception: java.net.ConnectException: Connection refused: no further information; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused\n at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n at java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)\n at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)\n at org.apache.hadoop.ipc.Client.call(Client.java:1415)\n at org.apache.hadoop.ipc.Client.call(Client.java:1364)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n at java.lang.reflect.Method.invoke(Method.java:606)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)\n at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)\n at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)\n at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)\n at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)\n at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)\n at com.sybase.esp.adapter.transporters.file.out.DataSinkHDFSAccessory.sanityCheck(Unknown Source)\n at com.sybase.esp.adapter.transporters.file.FileOutputTransporter.init(Unknown Source)\n at com.sybase.esp.adapter.framework.wrappers.TransporterWrapper.init(Unknown Source)\n at com.sybase.esp.adapter.framework.internal.Adapter.init(Unknown Source)\n at com.sybase.esp.adapter.framework.internal.AdapterController.executeStart(Unknown Source)\n at com.sybase.esp.adapter.framework.internal.AdapterController.execute(Unknown Source)\n at com.sybase.esp.adapter.framework.Framework.main(Unknown Source)\nCaused by: java.net.ConnectException: Connection refused: no further information\n at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)\n at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)\n at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)\n at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)\n at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)\n at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)\n at org.apache.hadoop.ipc.Client.call(Client.java:1382)\n ... 24 more\n07-01-2015 13:44:57.173 INFO [main] (ContextHandler.doStop) Stopped o.e.j.s.ServletContextHandler@634984c8{/,null,UNAVAILABLE}\n07-01-2015 13:44:57.189 INFO [main] (AbstractConnector.doStop) Stopped ServerConnector@50e674b9{HTTP/1.1}{192.168.178.61:19083}\nDoes anyone have an idea what I can try to get it working?Thanks in advance.Best RegardsStefan", "views": "390", "answers": 0, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-07-01 23:42:00", "resolve": true, "uid": "172", "title": "Question about ifnull() function", "url": "http://scn.sap.com/thread/3764826", "text": "Dear colleague, I am confused about ifnull() functionAccording to documentation, IFNULL ( expression1, expression2 [ , expression3 ] )Parametersexpression1 The expression to be evaluated. Its value determines whether expression2 or expression3 is returned.expression2 The return value if expression1 is NULL.expression3 The return value if expression1 is not NULL.But when I test with it, if expression1 is not NULL, the returned value is the expression1 itself.Here is my test ccl file:**********************CREATE INPUT STREAM inString SCHEMA (Col1 string);CREATE OUTPUT STREAM outString as select inString.Col1 Col1, ifnull(inString.Col1, 'null value', 'NOT null value') Col2 from inString;CREATE INPUT STREAM inInteger SCHEMA (Col1 integer);CREATE OUTPUT STREAM outInteger as select inInteger.Col1 Col1, ifnull(inInteger.Col1, 0, 2) Col2 from inInteger; **********************It does not seem correct to me:with integer typeCol1Col2500500NULL0 when the expression to be evaluated is not NULL (in this case, 500), the output should be the third expression (2), not the evaluated expression itself.With string type:Col1Col2stringstringNULLnull value when the expression to be evaluated is not NULL (in this case, string), the output should be the third expression (NOT null value), not the evaluated expression itself. Could you please help to clarify?Thanks,Tao", "views": "328", "answers": 3, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-07-02 17:02:00", "resolve": "solution", "uid": "172.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3764826", "text": "Where did you find the documentation for ifnull()? Was it from another product?In CCL, according to the CCL reference guide, ifnull() is an alias for firstnonnull(), which will return the value of the first non-null element in a list of elements.See: http://help.sap.com/saphelp_hana_options_sds_ccl/helpdata/en/e7/8ffc0c6f0f1014a8adf3bc084e371a/content.htmIf this came from the ESP or SDS doc somewhere, then it would seem to be a doc error. I didn't find it, but if it did, and you can point me to it, we can get it corrected.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question about ifnull() function", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "172.2", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3764826", "text": "My mistake. I came across the sybase sql ifnull() function. http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.infocenter.dc38151.1540/doc/html/san1278453057757.htmlThanks. I will use a custom function then.Best regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question about ifnull() function", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "172.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3764826", "text": "No need to write a custom function. Sorry, I should have included this in my reply.... you can achieve this using isnull() and the CASE expression, eg:CREATE INPUT STREAM inIntegerSCHEMA (Col1 integer);CREATE OUTPUT STREAM outIntegeras select inInteger.Col1 Col1, (CASE WHEN isnull(inInteger.Col1) THEN 0 ELSE 2 END) Col2 from inInteger;", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Question about ifnull() function", "type": "answer", "tags": "N/A"},
{"date_time": "2015-07-07 14:41:00", "resolve": true, "uid": "173", "title": "Overwrite HANA Table or Delete old datasets", "url": "http://scn.sap.com/thread/3767234", "text": "Hello,I have a question for the Event Stream Processor:I have an Data Flow that looks like that:With that Data Flow I read data sets from HANA and write all older datasets into an Flat File.But I would like delete all datasets who was outsourced in that flat file from the HANA table.Is it possibly to overwrite an SAP HANA table (with the HANA Outputadapter as example)? Or is there any possibility to delete the old datasets?Thanks in advance.Best RegardsStefan", "views": "840", "answers": 8, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-07-07 14:47:00", "resolve": "", "uid": "173.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3767234", "text": "Yes, you can delete data in HANA from ESP. There are two ways:- In ESP you produce \"Delete events\" - i.e. events with a \"delete\" opcode, and then use the HANA output adapter to write them to a HANA table. A couple of notes: (1) you have to know the keys of the rows you want to delete, (2) keep in mind that deletes on HANA are much slower than inserts.- You can use the CCL getdata() function to execute SQL statements on HANA. Despite the name, you aren't limited to using it to retrieve data - you can run other SQL statements as well. So you could issue a delete statement, run a stored procedure, etc.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Overwrite HANA Table or Delete old datasets", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "173.2", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3767234", "text": "Hi Jeff,thanks for the fast answer. I already read that I can use the opcode \"delete\". But find nothing how to use it and also don't found an parameter where I can set it. Do I have to set it in CCL-View or does it also works in the cclnotation in the data flow?Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Overwrite HANA Table or Delete old datasets", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "173.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3767234", "text": "Good question. So the easy way is: if the incoming data has opcodes, then those will be passed along. So if, for example, you get delete events arriving as input, those can be applied to HANA tables. Also, the results of certain operations will naturally produce delete events, e.g.- rows being removed from a CCL window due to retention policiesBut to manually create a \"synthetic\" delete event, you need to use a Flex operator, and the syntax is not exactly obvious, so here's an example:CREATE INPUT STREAM InputStream1SCHEMA ( Column1 INTEGER , Column2 INTEGER ) ;CREATE FLEX FlexOperator1IN InputStream1 OUTOUTPUT STREAM DeleteEventsSCHEMA ( Column1 INTEGER , Column2 INTEGER )PRIMARY KEY (Column1)BEGIN ON InputStream1 { output setOpcode( [Column1 = InputStream1.Column1; | Column2 = InputStream1.Column2;], delete); } ;END;Also, one final thing to note: when configuring the HANA output adapter, be sure the DataWarehouse mode property is OFF - see this blog post for an explanation: http://scn.sap.com/docs/DOC-40208", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Overwrite HANA Table or Delete old datasets", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "173.4", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3767234", "text": "Hello Jeff,thanks for the example code.I tried your example to create an delete opcode after I filtered my datasets.My data flow for this part looks like that:The code for the delete event looks like that:But unfurtunally I got a lot of errors while trying to compilate my project after writing this command.I also tried alot to change it. But everytime I got some failures.I have the feeling there are some beginners syntax failures in the code. Is the syntax for this right?Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Overwrite HANA Table or Delete old datasets", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "173.5", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3767234", "text": "Looking at your ON method, one thing I see is this:when you construct an output record, you should only use the \"|\" separator once (or not at all, for a stream without keyds). This separates the column or columns that make up the primary key from the others. The key colums are to the left of | and the non-key colums are to the right.I don't immeidately spot other problems. Try that. If there are still problems, please post the CCL as text (or send it to me). Then I can try to compile it myself. With the screen shot I ahve to re-type it, which risks introducing typos or other changes.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Overwrite HANA Table or Delete old datasets", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "173.6", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3767234", "text": "Thanks, now I can compile the project wihtout errors.But unfurtunally after execute the project the filtered datasets were not deleted.My CCL looks like that:\nCREATE INPUT STREAM Sensordata SCHEMA (DATE msdate ,\n MEASURETIME time ,\n SENSORVALUE float );\n/**@SIMPLEQUERY=FILTER*/\nCREATE OUTPUT STREAM DeleteEventFilter AS SELECT * FROM Sensordata WHERE\ntimeToSec ( to_bigdatetime ( Sensordata.DATE ) ) < timeToSec ( now ( ) ) - 86400 ;\n/**@SIMPLEQUERY=FILTER*/\nCREATE OUTPUT STREAM HistoricDataFilter AS SELECT * FROM Sensordata WHERE\ntimeToSec ( to_bigdatetime ( Sensordata.DATE ) ) < timeToSec ( now ( ) ) - 86400 ;\nCREATE FLEX DeleteQuery IN DeleteEventFilter OUT OUTPUT WINDOW DeleteQuery SCHEMA (\n DATE msdate ,\n MEASURETIME time ,\n SENSORVALUE float ) PRIMARY KEY ( DATE )\nBEGIN\n ON DeleteEventFilter {\noutput setOpcode([DATE = DeleteEventFilter.DATE; | MEASURETIME = DeleteEventFilter.MEASURETIME; SENSORVALUE = DeleteEventFilter.SENSORVALUE;] ,delete);\n} ;\nEND\n;\nCREATE OUTPUT WINDOW DeleteEventsWindow SCHEMA (\n DATE msdate ,\n MEASURETIME time ,\n SENSORVALUE float ) PRIMARY KEY DEDUCED AS SELECT * FROM DeleteQuery ;\nATTACH INPUT ADAPTER Generic_DB_Input1 TYPE db_in TO Sensordata PROPERTIES service = 'awshana' ,\n table = 'BRIDGEMODE' ;\nATTACH OUTPUT ADAPTER HANA_Output1 TYPE hana_out TO DeleteEventsWindow PROPERTIES service = 'awshana' ,\n table = 'BRIDGEMODE' ,\n bulkInsertArraySize = 1 ;\nATTACH OUTPUT ADAPTER File_Hadoop_CSV_Output1 TYPE toolkit_file_csv_output TO HistoricDataFilter PROPERTIES dir = 'C:/Sybase' ,\n file = 'test.json' ,\n csvDelimiter = ';' ,\n csvHasHeader = TRUE ;\nCould it be that the reason for not deleting the datasets are the missing keep policy?Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Overwrite HANA Table or Delete old datasets", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "173.7", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3767234", "text": "Stefan,Try the CCL below. The problem was the Window after the DeleteQuery flex. You were writing deletes to an empty Window. But Windows validate opCodes. So what would happen is that the DeleteEventsWindow would receive a \"delete\" event for a row that doesn't exist, so it would reject the event. If you look at the project log you would see that. Also, if you use the EventTracer tool in the run-test perspective you could see that the event wasn't altering the Window (though the event tracer wouldn't tell you why).I just removed the window - it served no purpose that I could tell. I also turned the flex output from a window to a stream - again, you can't write delete events to a window that doesn't have events. Windows don't hold \"events\" they hold rows. So for a Window to emit a delete event it had to have a row to delete (and it would have to have been originally added by an insert event).Also: I removed one of your filters. You had two filters doing exactly the same thing. While that doesn't hurt anything, there's no point in doing it - it's just extra overhead.CREATE INPUT STREAM Sensordata SCHEMA (DATE msdate , MEASURETIME time , SENSORVALUE float ); /**@SIMPLEQUERY=FILTER*/CREATE OUTPUT STREAM DeleteEventFilter AS SELECT * FROM Sensordata WHEREtimeToSec ( to_bigdatetime ( Sensordata.DATE ) ) < timeToSec ( now ( ) ) - 86400 ;CREATE FLEX DeleteQuery IN DeleteEventFilter OUT OUTPUT STREAM DeleteRowsSCHEMA ( DATE msdate , MEASURETIME time , SENSORVALUE float ) PRIMARY KEY ( DATE )BEGIN ON DeleteEventFilter { output setOpcode([DATE = DeleteEventFilter.DATE; | MEASURETIME = DeleteEventFilter.MEASURETIME; SENSORVALUE = DeleteEventFilter.SENSORVALUE;] ,delete);} ;END;", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Overwrite HANA Table or Delete old datasets", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "173.8", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3767234", "text": "Now it worked fine, thank you!I interpreted the window wrong. But now I understand it. Thanks again Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Overwrite HANA Table or Delete old datasets", "type": "answer", "tags": "N/A"},
{"date_time": "2015-07-28 00:42:00", "resolve": false, "uid": "174", "title": "Is there a solution where Smart Data Streaming was Stopped from SAP HANA Studio?", "url": "http://scn.sap.com/thread/3776683", "text": "In the Smart Data Streaming documentation, there is a note stating that you should stop/start HANA Smart Data Streaming using HDB start and HDB stop. Is there a fix as to stopping and starting via HANA Studio?Thanks,Ron", "views": "427", "answers": 1, "author": "Ron Chan", "upvotes": 0, "type": "question", "tags": "smart.data.sds.streaming"},
{"date_time": "2015-07-28 13:00:00", "resolve": "", "uid": "174.1", "author": "Pauli Gandhi", "url": "http://scn.sap.com/thread/3776683", "text": "Yes there is a way.In the Hana studio double click on the system that is hosting SDS.  * On the right side click on the landscape tab.  * You will see a list of services running.  * Right click on the Smart Data Streaming service and say either stop or kill. Note that the service will automatically restart in a minute or so. If it does not, you can click on 'Start missing services' Note that the projects don't automatically restart. You will have to connect to the correct SDS via the SDS Hana Studio Plugin and restart the individual projects.", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:Is there a solution where Smart Data Streaming was Stopped from SAP HANA Studio?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-07-30 17:00:00", "resolve": false, "uid": "175", "title": "Smart Data Streaming not availiable in the marketplace", "url": "http://scn.sap.com/thread/3778389", "text": "Hi,my question sounds a bit ridiculous but I cant find the installation packages for SAP HANA SMART DATA STREAMING.Im following the instructions described in the SDS installation guide but i cant find the packeges.The installation guide shows following paths:But they are not in the marketplace.Does anyone know where i can find them?greetingsjohann Bauer", "views": "373", "answers": 4, "author": "Johann Bauer", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-07-30 17:08:00", "resolve": "", "uid": "175.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3778389", "text": "Looks like there is a mistake in the install guide. Sorry about that. I'll point it out to the doc team. HANA smart data streaming is under \"H\" in the A-Z listing, but not under \"SAP In-Mmeory (SAP HANA)\"Also: I recommend downloading from \"Support Packages and Patches\" rather than \"Installations and Upgrades\" - even for a new install, so you can be sure you are downloading the latest revision.So go to: Support Packages and Patches -> A-Z -> \"H\" -> SAP HANA Smart Data Streaming", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming not availiable in the marketplace", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "175.2", "author": "Johann Bauer", "url": "http://scn.sap.com/thread/3778389", "text": "Hello Jeff,thank you for your fast respond.After following your provided path, I'am still unable to see the SDS installation data.I attached a screenshot of my view.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming not availiable in the marketplace", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "175.3", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3778389", "text": "Then I'm guessing it's an entitlement issue. I suggest you contact customer support. Here's what I see under Support Packages and Patches - H", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming not availiable in the marketplace", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "175.4", "author": "Johann Bauer", "url": "http://scn.sap.com/thread/3778389", "text": "Thank you Jeff.Im opening a Ticket at the Support", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Smart Data Streaming not availiable in the marketplace", "type": "answer", "tags": "N/A"},
{"date_time": "2015-06-09 07:01:00", "resolve": false, "uid": "176", "title": "SAP ESP Studio. Error: \"Failed to create input stream: Real timed out\"", "url": "http://scn.sap.com/thread/3753230", "text": "Hello!When I view the contents of the Oracle schema via ODBC driver the following error exists:Failed to create input stream: Real timed outBut according to the ODBC trace after the issuance of this error the system continues to select schemes, ie selecting of metadata database is underway.In general, it seems that the reading of database objects Oracle does not fit the timeout of reading on ESP side. Where is limitation on timeout configuration ESP hardwired? Can I change it?I hope for your help.Best regards,Arthur.", "views": "622", "answers": 1, "author": "Artur Tsoy", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-08-05 15:36:00", "resolve": "", "uid": "176.1", "author": "Deepak M", "url": "http://scn.sap.com/thread/3753230", "text": "Hello Artur TsoyI too had a similar kind of error while connecting to the HANA.The issue was solved, it was an issue regarding the previleges of my specific ID in the HANA. I tried with SYSTEM and the issue was solved.. Could discover all the schemas in HANA from ESP. You need to have the \"Catalog Read\" privileges, to read all the schemas in HANA.RegardsDeepak", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:SAP ESP Studio. Error: \"Failed to create input stream: Real timed out\"", "type": "answer", "tags": "N/A"},
{"date_time": "2015-08-12 15:24:00", "resolve": true, "uid": "177", "title": "Can ESP Web Service Provider retrieve events via GET request?", "url": "http://scn.sap.com/thread/3784047", "text": "Dear Colleagues, When an ESP project is web service enabled, we can use REST request to publish data to the ESP stream or a window, according to the document, it is POST requesthttp://help.sap.com/saphelp_esp_51sp10_adapt/helpdata/en/e7/8c81876f0f1014b6ce8606de2b809b/content.htmIn the POST request body, there are 2 parts: connectionDetails with credentials, and content with the actual event data.My question is: is it possible to publish data to the input stream or window via GET request? With GET request, there is no request body, the event data that shall be published to ESP will appear as parameters:http://host:9091/espws/restservice/stream/window1?action=insert&workspace=default&project=project1&att1=1&att2=2&...This is a valid use case, because during our research on the web tracking, we found out there is a new way of tracking, so called tracking pixels, a technique to avoid JavaScript in the browser, whereby the tracked data is encoded as URL parameters of the request. So only GET request can be sent in this case. Do you have experience with similar issues? We appreciate greatly your help. Best regards,Tao", "views": "466", "answers": 4, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-08-12 16:03:00", "resolve": "", "uid": "177.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3784047", "text": "Hi Tao,I double checked the documentation including the Streaming Web Service which is new in SPS 10. At this point the only method supported for publishing data to the streaming project is through a POST request. Architecturally the benefit of a POST is that it avoids the limitations on content length that exist with a parameterized GET request.If you need to publish data using a GET request, then you will need to build a custom adapter to do so.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can ESP Web Service Provider retrieve events via GET request?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "177.2", "author": "Dilip Sarmah", "url": "http://scn.sap.com/thread/3784047", "text": "Rob is correct. Currently WSP only supports POST to publish. There is also a security angle to it - using POST you can rely on SSL to encrypt message body. With GET, even if SSL encrypt some of the URL but intermediate server can able to log unencrypted URL.For now you can use a custom adapter and from the adapter you can convert the call to POST.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can ESP Web Service Provider retrieve events via GET request?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "177.3", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3784047", "text": "Hello Dilip,do you have tutorials (video, detailed how-to guide, etc..) on custom adapter developement? We are quite new on ESP, don`t have much java experience either. We would appreciate every bit of help we could get.Thanks and regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can ESP Web Service Provider retrieve events via GET request?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "177.4", "author": "Dilip Sarmah", "url": "http://scn.sap.com/thread/3784047", "text": "Since you will be simply converting from a GET to POST in the middle, you do not need ESP adapter framework. You can easily create a servlet (on Jetty) to convert call from GET to POST and then call to WSP.ESP does not provide a way for you to host your servlet. But we have included Jetty library ($STREAMING_HOME/framework/libj). Using this jetty, you can write a embedded jetty servlet:http://www.eclipse.org/jetty/documentation/9.2.8.v20150217/embedded-examples.htmlsearch for: MinimalServlets.java", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Can ESP Web Service Provider retrieve events via GET request?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-07-20 15:27:00", "resolve": true, "uid": "178", "title": "web service provider deny extern connection - error: invalid connection details", "url": "http://scn.sap.com/thread/3773169", "text": "Hello,I have a curios problem with the local installation of the event stream processor 5.1:I connected the data source from SAP businessobjects design studio with esp to fill dashboards in near realtime.Two weeks before it worked perfect. Last week I had to reinstall esp because of licence problems. Now esp works fine, but every time I try to connect the data source the web service provider from esp says that the connection details are invalid.The wsp looks like that:So it looks like that the credentials are wrong. For the credentials I used \"studio\" as username and the password I changed before starting the localhost cluster. With an selfwritten input adapter I can connect with these credentials. So the questions is, why does the web service provider deny the credentials?I'm also not sure if I will be right in this forum. I already posted an add at the forum for businessobject design studio. Unfurtunally nobody could help me there. I really hope to get some hints what else I can try to get it working again.Thanks in advance.Best RegardsStefan", "views": "495", "answers": 4, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-07-20 16:43:00", "resolve": "", "uid": "178.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3773169", "text": "First off - yes you are in the right spot to be asking about connecting to ESP through the web service provider.Looking at the screenshot you posted, the actual error is \"Invalid connection details\" as opposed to something specific to the user ID or password. Since you have already verified that you can connect from a different adapter using those credentials, the issue is likely with another parameter in the connection details. I would suggest double checking the workspace name, the project name and the stream or window name. It could just be a typo somewhere. I would also suggest verifying that the case of each parameter matches the running project. You can also reconfirm that the project configuration file has the Web service enabled checkbox checked and the value set to true.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:web service provider deny extern connection - error: invalid connection details", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "178.2", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3773169", "text": "Hi Robert,thanks for the fast answer.When I connect from businessobject design studio I only have to type in the host, port and credentials like username and password. After that it gets the current workspace and running projects by itself. So there shouldn't be a problem. I also checked the host and port.I also checked the project configuration file and the checkbox for webservice enabled is checked and the value is true.Any other suggestions what if could be?Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:web service provider deny extern connection - error: invalid connection details", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "178.3", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3773169", "text": "The next couple of things to look at are:1) In the wsp.xml, under the <webSocket ...> section, is <secured> set to true?2) Again in the wsp.xml is are the <Hostname> and <Port> values for the local ESP server correct? I believe that by default the <Port> value is set to 19011 so you would have had to manually edit that value to be 9786 to connect to the local ESP server instance started by ESP Studio.", "views": "N/A", "answers": "N/A", "upvotes": 1, "title": "Re:web service provider deny extern connection - error: invalid connection details", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "178.4", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3773169", "text": "Thank you ver much! I forgot to change the port in the wsp.xml after the reinstallation of esp.Now it worked again.Best RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:web service provider deny extern connection - error: invalid connection details", "type": "answer", "tags": "N/A"},
{"date_time": "2015-08-24 22:35:00", "resolve": true, "uid": "179", "title": "Web Service Provider Configuration", "url": "http://scn.sap.com/thread/3789310", "text": "Hi.! i Have the same problem, but i have not been able to fix the problem", "views": "303", "answers": 6, "author": "Antonio de Jes\u00fas Flores Olivares", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-08-24 22:46:00", "resolve": "solution", "uid": "179.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3789310", "text": "Hi Antonio,It looks like your issue will be a fair bit different from the credentials issue that Stefan encountered, so I have split the discussion. With regards to your issue, the first thing that sticks out is a confusion between the ESP cluster port and the Web Service Provider REST port. These are 2 different ports that will be required and at the moment, you have edited the configuration try and have the project and the Web Service provider both use the same port. To clean that up, you need to do the following:1) Figure out what port your ESP cluster is running on. If you are just starting it from ESP Studio by running a project, then the default port is 9786.2) Remove the Project Binding that you set in the Project Configuration file. 3) In the wsp.xml file, confirm that the REST port is still set to use port 9091:<webService enabled=\"true\"> <soapPort>9090</soapPort> <restPort>9091</restPort> <protocol>http</protocol>4) In the wsp.xml file, set the \"alloworigin\" value to \"*\"<allowOrigin>*</allowOrigin>5) In the <DefaultCluster> section of the wsp.xml file set the port to either 9786 if you are using the default ESP cluster started by Studio, or set it to the port that your ESP cluster is actually using. <DefaultCluster> <Hostname>localhost</Hostname> <Port>9786</Port>Let us know what output you get from the WSP after making those changes.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Web Service Provider Configuration", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "179.2", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3789310", "text": "Hi, Now the error is \"NetworkError\"with default port 9786 the error is \"Error:NotFound\"", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Web Service Provider Configuration", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "179.3", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3789310", "text": "In the configuration section of the screen shot you just posted - what is port 9021 referring to? If that is supposed to be the REST port of the Web Service Provider, then it should be 9091.What tool are you trying to connect to the Web Service Provider from? Is this Design Studio?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Web Service Provider Configuration", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "179.4", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3789310", "text": "Sorry, with the correct port 9091 the error is \"Invalid Connection details\"  , The tool is Design Studiothe wsp.xml is:<webService enabled=\"true\"> <soapPort>9090</soapPort> <restPort>9091</restPort> <protocol>http</protocol><allowOrigin>*</allowOrigin> <DefaultCluster> <Hostname>localhost</Hostname> <Port>9786</Port> <Workspace>default</Workspace> <Authtype>user</Authtype> <SslEnabled>true</SslEnabled>", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Web Service Provider Configuration", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "179.5", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3789310", "text": "If you look at the output from the Web Service Provider, what is the exact error being reported at that level?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Web Service Provider Configuration", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "179.6", "author": "Antonio de Jes\u00fas Flores Olivares", "url": "http://scn.sap.com/thread/3789310", "text": "Hi, RobertNow it works fine, i change the parameter <SslEnabled>false</SslEnabled>Thank you", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Web Service Provider Configuration", "type": "answer", "tags": "N/A"},
{"date_time": "2015-08-28 21:44:00", "resolve": false, "uid": "180", "title": "i cant connect with sql server database", "url": "http://scn.sap.com/thread/3791803", "text": "i have a SQL server database, i am connect to this db with sql server management studio, but from JDBC adapter i can't connecting, this are the messages2015-08-28 14:40:42.086 | 18256 | container | [SP-4-108062] (3.142) sp(17112) GatewayClient::GatewayClient(18256:129) host:[host;52202] has initiated a connection.2015-08-28 14:40:53.465 | 14516 | container | [SP-4-108008] (14.521) sp(17112) GatewayClient(14516:131)::execute() Client closed/dropped connection.2015-08-28 14:40:53.476 | 14516 | container | [SP-4-108001] (14.532) sp(17112) GatewayClient(14516:131)::~GatewayClient() destroyed (auto).2015-08-28 14:40:53.601 | 20924 | container | [SP-4-148003] (14.657) sp(17112) ConnectionReader(InputWindow1) exiting.Regards", "views": "181", "answers": 0, "author": "Antonio de Jes\u00fas Flores Olivares", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-08-31 14:35:00", "resolve": true, "uid": "181", "title": "Cannot publish data to an output adapter through a derived window", "url": "http://scn.sap.com/thread/3792320", "text": "I am trying to mimic the functionality of a temperature monitor as shown in this blog post: HANA Smart Data Streaming in ActionSo basically from an Input Stream, I create an Aggregate Window which computes the average of a temperature field and when that average goes above a certain value then the Derived Window generates an alarm. Now everything is working fine, except when the Derived Window receives an alarm, I am trying to trigger an RFC in a SAP System. The Derived Window event is not triggering the RFC. When I attach the output adapter directly to the Input Stream I am able to trigger the RFC. Which leads me to believe that the system connections are fine but for some reason this Derived Window is not pushing the data down to the RFC output stream. Any leads on what I might be missing? Is there anything else that I should share in this discussion?Thank you in advance.", "views": "150", "answers": 2, "author": "Sateendra Dey", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-08-31 15:31:00", "resolve": "", "uid": "181.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3792320", "text": "Some things you should look at:1. Check the RFC adapter logfile and the project log file. Change the settings on both the project and the adapter to make the logfiles more verbose. See if they provide cludes2. Check the mapping file used by the RFC output adapter. In particular: are there any data type issues? the average calculation, for example, may change the datatype (eg an average across a set of integers will produce a float, etc)3. Or could it be an opCode issue? I don't know how the RFC adapter handles opcodes. If you aren't familiar with OpCodes in SDS, see this post: http://scn.sap.com/docs/DOC-40207. The input stream is emitting all insert events, but the aggregation window will be emitting update events after the first one for each key.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Cannot publish data to an output adapter through a derived window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "181.2", "author": "Sateendra Dey", "url": "http://scn.sap.com/thread/3792320", "text": "I was able to figure out the issue. I had forgotten to change the stream name in the Adapter Config file. Once I changed it to the correct stream name it started working.Thank you Jeff for pointing out the opCode conditions. It helped me avoid another issue that I might have faced.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Cannot publish data to an output adapter through a derived window", "type": "answer", "tags": "N/A"},
{"date_time": "2015-07-31 19:07:00", "resolve": true, "uid": "182", "title": "unable to start ESP cockpit, looking for help", "url": "http://scn.sap.com/thread/3778968", "text": "Hi everyone. I have just done a clean install of ESP 5.1 SP10 on Linux x64. I followed the instructions on the installation guide and everything seems to be going okay. Started up the cluster DB fine, started up the node without errors, but when I try to start up the ESP Cockpit, I get the following error.Failed to start agent: Failed to start RepositoryService. Failed to start Repository Service: Failed to open Repository: while trying to invoke the method com.sybase.ua.util.VersionNumber.compareTo(com.sybase.ua.util.VersionNumber) of a null object loaded from a local variable at slot 4 java.lang.RuntimeException: Failed to open Repository: while trying to invoke the method com.sybase.ua.util.VersionNumber.compareTo(com.sybase.ua.util.VersionNumber) of a null object loaded from a local variable at slot 4 com.sybase.ua.service.AgentServiceException: Failed to start Repository Service: Failed to open Repository: while trying to invoke the method com.sybase.ua.util.VersionNumber.compareTo(com.sybase.ua.util.VersionNumber) of a null object loaded from a local variable at slot 4 java.lang.RuntimeException: Failed to open Repository: while trying to invoke the method com.sybase.ua.util.VersionNumber.compareTo(com.sybase.ua.util.VersionNumber) of a null object loaded from a local variable at slot 4I can't seem to find any information online that helps. Has anyone seen this or have any idea how to resolve this? Thanks!", "views": "392", "answers": 1, "author": "Brian Suk", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-09-02 05:09:00", "resolve": "solution", "uid": "182.1", "author": "Brian Suk", "url": "http://scn.sap.com/thread/3778968", "text": "It turns out that somehow the repository database for the cockpit got corrupted during installation. Removing the repository and log files did the trick. I just moved them with a .bak extension just in case, but it should be fine. The two files are repository.log and repository.db. Starting the cockpit afterwards re-creates the repository database when it can't find it, and all went well.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:unable to start ESP cockpit, looking for help", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-01 15:54:00", "resolve": false, "uid": "183", "title": "How to setup/replicate this table scenario using SDI", "url": "http://scn.sap.com/thread/3792934", "text": "HiIf there is anyone there that is already using SDI, could please explain how I would setup in SDI the replication table below? How can this be translated/setup and done in SDI?We are currenlty replicating in real time the table below using SLT using the below setup for replication:Table: VBRP# of records: 2 billionLTRS rules:Partition HASH#15 (15 partitions)Load type 5, 20 calculation jobs and 20 initial loads jobs for INITIAL LOADAdd two 1 field in the VBRP tables (ztimestamp)Execute a include to populate the new field when replicating.How can this be translated/setup and use in SDI?Regards,Rod Cardenas", "views": "191", "answers": 2, "author": "Chris Strauss", "upvotes": 0, "type": "question", "tags": "hana.replication.slt.ltr.sdi"},
{"date_time": "2015-09-01 17:12:00", "resolve": "", "uid": "183.1", "author": "Jeff Wootton", "url": "http://scn.sap.com/thread/3792934", "text": "I believe you meant to post this to the SDI space. This is the Smart Data Streaming developer center, which isn't monitored by SDI experts.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to setup/replicate this table scenario using SDI", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "183.2", "author": "Chris Strauss", "url": "http://scn.sap.com/thread/3792934", "text": "I've tried to search for \"Smart Data Integration\" or \"SDI\" but nothing comes up. I will then try HANA Developer Center instead.Thanks JeffRod", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:How to setup/replicate this table scenario using SDI", "type": "answer", "tags": "N/A"},
{"date_time": "2015-08-06 22:56:00", "resolve": false, "uid": "184", "title": "HTTP Client Output Adapter: how to deal with Token?", "url": "http://scn.sap.com/thread/3781744", "text": "Dear Colleagues,we want to use HTTP Client Output Adapter to send HTTP Post requests to generate business objects from transformed events. The service it calls requires token:https://<host>:<port>/myservicemethod: GETrequest header: X-Requested-With: XMLHttpRequest X-CSRF-Token:FetchAfterwards, POST requests are sent with this Token always included in the request header:https://<host>:<port>/myservice/ImportObjectsmethod: POSTrequest header: x-csrf-token:eygQM5-3e_UTQ==request body: {...}Is there a way to handle Token with HTTP Client Output Adapter? What are your best practise with such scenario?Your input is greatly appreciated.Thanks and best regards,Tao", "views": "1195", "answers": 2, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-08-13 17:18:00", "resolve": "", "uid": "184.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3781744", "text": "At this time the HTTP Client Output adapter does not support setting the header.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HTTP Client Output Adapter: how to deal with Token?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "184.2", "author": "Tao Zhang", "url": "http://scn.sap.com/thread/3781744", "text": "Hello Robert, just want to follow on this topic: will HTTP Client Output adapter supports request header, especially supports retrieving/setting token on header, in the coming SP11?this is really important for us to send http calls from ESP to our application. Thanks and regards,Tao", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:HTTP Client Output Adapter: how to deal with Token?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-16 15:11:00", "resolve": false, "uid": "185", "title": "ESP WSP, how to configure a user that can only access one project?", "url": "http://scn.sap.com/thread/3800020", "text": "Hello Colleagues, we are implementing a web-tracking project, in which the web events are captured and immediately sent from the web browser to the ESP WSP, via POST request with json format. part of the json payload is the connection credentials:{ \"connectionDetails\": { \"clusterName\": \"mycluster\", \"port\": \"9091\", \"authentication\": { \"type\": \"user\", \"data\": \"user:password\", \"sslEnabled\": \"false\" } }, \"content\": {  \"action_name\": \"Piwik tracking site\", \"idsite\": \"1\", \"rec\": \"1\", \"r\": \"494617\" }}Because this request is sent directly from browser, this credential part is hard-coded on the user browser via code snipert injection. To minimize security risk, how do I create a user which can only access this one project, cannot do anything else with ESP?We have a single node cluster for now. Thanks and best regards,Tao", "views": "72", "answers": 1, "author": "Tao Zhang", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-09-16 21:11:00", "resolve": "", "uid": "185.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3800020", "text": "Hi Tao,Streaming user permissions are managed with the \"streamingclusteradmin\" tool which is documented in the Utilities Guide:streamingclusteradmin - SAP Event Stream Processor: Utilities Guide - SAP LibraryI would suggest working with the streamingclusteradmin tool in Interactive mode while you are figuring out exactly which permissions to grant for your project. Within that section, specifically look at the grant perm <priv> [<privtype>] [on [any] <resourcetype> [<resource>]] to user|role <name>portion. You will need to grant write permissions on the workspace, project, and stream  for the particular stream you are writing to. That will take multiple grant statements. As a starting example, the grant statement to grant write permissions on the workspace could look like this:grant perm write workspace on workspace default to user my_streaming_userThe important thing to note in that example is that \"workspace\" is both a <privtype> and a <resourcetype>. The same will be true for your grant statements for the project and stream as well.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:ESP WSP, how to configure a user that can only access one project?", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-17 10:13:00", "resolve": true, "uid": "186", "title": "Data Service Discovery [CODE:710005]", "url": "http://scn.sap.com/thread/3800379", "text": "Hi Guys,lately im trying to get an SAP ESP 5.1 SPS 09 to work properly.Now im facing an error while i try to discover my Data Service.I added a new Data Service at the localhost:9786 and this one works fine, but when i try to create the same Data Service on the cluster at port 19011I always get the following error msg:[FAILURE:No authorization for requested permission: privilege=execute, privilege-type=service, resource-type=service, resource=discovery][CODE:710005] Best RegardsJohann", "views": "92", "answers": 2, "author": "Johann Bauer", "upvotes": 0, "type": "question", "tags": "sybase.esp.dataservice"},
{"date_time": "2015-09-17 17:45:00", "resolve": "", "uid": "186.1", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3800379", "text": "What user are you connecting to the cluster running on port 19011 as? Does that user have full permissions on the cluster?When you are working with the 'local' cluster that is automatically started by ESP Studio, then the \"studio\" user has full permissions on the 'local' cluster. In contrast, when creating a cluster you also need to grant user permissions on the cluster.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Data Service Discovery [CODE:710005]", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "solution", "uid": "186.2", "author": "Johann Bauer", "url": "http://scn.sap.com/thread/3800379", "text": "Hi Robert, thank you for your response. It looked like it was permission error.I followed the instructions described in the installation guide but they didnt mention the execute priviliege. After i added this privilege to the user, the discovery of the data service worked. I used the streamingclusteradmin to add the privilege to the user.grant perm execute on all to user ****@nullBest regardsJohann", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Data Service Discovery [CODE:710005]", "type": "answer", "tags": "N/A"},
{"date_time": "2015-04-21 14:20:00", "resolve": false, "uid": "187", "title": "Connection problem: Failed to login server", "url": "http://scn.sap.com/thread/3730824", "text": "Hello,I have a problem with the connection to the ESP Server with ESP Studio.Because I read that the ESP Server should not be installed to the same server where SAP HANA is running I tried to install the ESP Server on another server at the amazon cloud. But now when I try to add this server at the SAP ESP Run Test in ESP Studio I can't connect to it.For the host I wrote the ip address of the server where ESP Server is installed on and for the port I used 30026 (like described in the guide).For the authentication I use the credentials that are in the SAP HANA (and yes I also choosed HANA Authentification at the installation of ESP Server).When I next try to connect, I get the following error message:Failed to login server.Does I really need to install the ESP Server on another server or do I have to install it on the same server where SAP HANA is located?I would also be very happy for every hint that can help me to solve the problem.Thanks in advance.RegardsStefan", "views": "736", "answers": 7, "author": "Stefan Rutte", "upvotes": 0, "type": "question", "tags": ""},
{"date_time": "2015-04-21 15:36:00", "resolve": "", "uid": "187.1", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3730824", "text": "Hi Stefan,\"and for the port I used 30026 (like described in the guide).\" - Did you install ESP or Smart Data Streaming? If ESP, you should be referencing the ESP guide and not the SDS guide. The port you chose here leads me to believe you are referencing the SDS guide. What version of the product are you working with?You may want to provide snapshots so we can get more hints.The \"Failed to login server\" error message often suggests that you are using the wrong URI. (Assuming you are using ESP, then please see A Studio Project Does Not Run, Reports Login Failure - SAP Event Stream Processor: Configuration and Administration Guid) What does your URI look like? Is your cluster SSL enabled? We need to understand your installation configuration a bit more to figure this out.Thanks,Alice", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connection problem: Failed to login server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "187.2", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3730824", "text": "Hi Alice,thanks for your fast answer.I tried both. I have a testversion of ESP and of SDS.But with both I get the same error:At the versions I'm not sure for SDS. I loaded the last version yesterday. The version for ESP are 5.1Also if I started the installer for SDS it shows the ESP at the components who will be installed.Does this mean that both installation that I have are the ESP?At the installation I enabled ssl and also used the checkbox for ssl at the connection information.(And on the URI at the screenshot above it also is esps instead of esp, so it should be active)RegardsStefan", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connection problem: Failed to login server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "187.3", "author": "Alice Silverstein", "url": "http://scn.sap.com/thread/3730824", "text": "Which one do you want to use? ESP or SDS? Please choose and then let's work on just getting one or the other working properly.To determine the full version and revision of:ESP or SDS Studio, in Studio, go to Help->About.ESP server, run the command: $STREAMING_HOME/bin/streamingclusternode --versionSDS server, run the command: $STREAMING_HOME/bin/hdbstreamingserver --versionIf you accepted the defaults during the ESP installation, your port number will be 19011 (not 30026 - that is probably what you've set for your SDS server port).", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connection problem: Failed to login server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "187.4", "author": "Stefan Rutte", "url": "http://scn.sap.com/thread/3730824", "text": "I would prefer to use SDS.The version of SDS is 1.0.09.00.SAP HANA is on SP09 Rev 90.At the installation of SDS I don't changed the default ports.But also with the port 19011 (what is also default at the SDS installation) I got the same error while trying to connect.You said that the error message often shows that something goes wrong with ssl, soI will try to insall SDS again without ssl and to connect without ssl just to test if something goes wrong with the ssl part.Is there something other that can go wrong at the installation itself?", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connection problem: Failed to login server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "187.5", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3730824", "text": "A couple notes:1) The default port for the SDS server connection from the HANA Streaming Run-Test perspective is 3XX26 where XX = the instance # of your HANA system. If your HANA system is instance # 00, then the port is 30026. However if the instance # was 45 then the port would be 34526. Check the instance # to make sure you are using the right port. 2) SDS does not use port 19011.3) SDS will always use SSL communications to connect with the HANA server. You don't have the option of disabling. That means you need to be sure to check the SSL checkbox when setting up the server when creating the New Server URL in the Server View of the Run-Test perspective.Question - What user ID are you using to connect to the Streaming server? The SYSTEM user has permissions on the streaming server by default, but if you are using a different user then you will first need to grant them permissions through the \"streamingclusteradmin\" command line tool.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connection problem: Failed to login server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "187.6", "author": "Vinod kumar", "url": "http://scn.sap.com/thread/3730824", "text": "Hi Robert,we are facing the same issue ,we tried different things and even selected the SSL check box still same issue.Please advice US what else needs to be done .Please find the attached screen shots below.I am attaching the SYSTEM landscape as well.i tried with port number 30016 --- seen from landscape  30026 -- from your example still same issue . Please help on this.Should we need to open 30026 port..??Thanks,Vinod.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connection problem: Failed to login server", "type": "answer", "tags": "N/A"},
{"date_time": "2015-09-26 00:00:00", "resolve": "", "uid": "187.7", "author": "Robert Waywell", "url": "http://scn.sap.com/thread/3730824", "text": "The port 3XX16 is used for internal communications between the streaming node and the core HANA node. It is not intended, and should not be used for external connections such as connecting from HANA Studio. The correct port to use when configuring the streaming server connection from the Streaming Run-Test perspective is 3XX26 as described above.The error you are receiving does indicate that the most likely issue is that the port # is incorrect or inaccessible. If the server machine name or the user credentials were wrong then you would be getting a different error. If you do not currently have port 30026 (given that your Instance# is 00) open for TCP traffic, then yes you will need to open that port.", "views": "N/A", "answers": "N/A", "upvotes": 0, "title": "Re:Connection problem: Failed to login server", "type": "answer", "tags": "N/A"}]